{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d745b36-8f92-4c0e-a42b-21d8de06dc8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import warnings\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import statsmodels.api as sm\n",
    "    import sklearn.linear_model as lm\n",
    "    import sklearn.model_selection as skm\n",
    "    import statsmodels.formula.api as smf\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from ISLP.models import ModelSpec as MS\n",
    "    from stargazer.stargazer import Stargazer\n",
    "    from sklearn.tree import (DecisionTreeClassifier as DTC,\n",
    "                          DecisionTreeRegressor as DTR,\n",
    "                          plot_tree,\n",
    "                          export_text)\n",
    "    from sklearn.metrics import (accuracy_score,\n",
    "                             log_loss,\n",
    "                                mean_squared_error)\n",
    "    from sklearn.ensemble import \\\n",
    "     (RandomForestRegressor as RF,\n",
    "      GradientBoostingRegressor as GBR)\n",
    "    from ISLP.bart import BART\n",
    "    import xgboost as xgb\n",
    "    from sklearn.model_selection import cross_val_predict\n",
    "    from sklearn.neural_network import MLPRegressor\n",
    "    #import doubleml as dml\n",
    "    import graphviz\n",
    "    import networkx as nx\n",
    "    import dowhy\n",
    "    from dowhy import CausalModel\n",
    "    \n",
    "\n",
    "except ModuleNotFoundError:\n",
    "    !pip install ISLP -q\n",
    "    !pip install stargazer -q\n",
    "    !pip install xgboost -q\n",
    "    !pip install doubleml -q\n",
    "    !pip install dowhy -q\n",
    "    import warnings\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import statsmodels.api as sm\n",
    "    import sklearn.linear_model as lm\n",
    "    import sklearn.model_selection as skm\n",
    "    import statsmodels.formula.api as smf\n",
    "    import matplotlib.pyplot as plt\n",
    "    from stargazer.stargazer import Stargazer\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from ISLP.models import ModelSpec as MS\n",
    "    from sklearn.tree import (DecisionTreeClassifier as DTC,\n",
    "                          DecisionTreeRegressor as DTR,\n",
    "                          plot_tree,\n",
    "                          export_text)\n",
    "    from sklearn.metrics import (accuracy_score,\n",
    "                             log_loss,\n",
    "                                mean_squared_error)\n",
    "    from sklearn.ensemble import \\\n",
    "     (RandomForestRegressor as RF,\n",
    "      GradientBoostingRegressor as GBR)\n",
    "    from ISLP.bart import BART\n",
    "    import xgboost as xgb\n",
    "    from sklearn.model_selection import cross_val_predict\n",
    "    #import doubleml as dml\n",
    "    import graphviz\n",
    "    import networkx as nx\n",
    "    import dowhy\n",
    "    from dowhy import CausalModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3175a2c0-27be-498a-bae5-6078dd085bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loc = \"spillovers.dta\"\n",
    "\n",
    "data = pd.read_stata(data_loc, iterator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7398c00a-ae54-4b7b-aa65-a93e6eb2b121",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cusip': 'CUSIP',\n",
       " 'year': 'year',\n",
       " 'xrd': 'Expenditure on R&D',\n",
       " 'ppent': 'Net book value of property, plant and equipment',\n",
       " 'spillsic': 'SIC correlation weighted R&D of other firms, 1996 values',\n",
       " 'spillcovsic': '',\n",
       " 'spillmalsic': '',\n",
       " 'spillmalcovsic': '',\n",
       " 'spilltec': 'Patent NClass correlation weighted R&D of other firms, 1996 values',\n",
       " 'spillcovtec': '',\n",
       " 'spillmaltec': '',\n",
       " 'spillmalcovtec': '',\n",
       " 'spilltloc': '',\n",
       " 'spillsloc': '',\n",
       " 'spilltectloc': '',\n",
       " 'spilltecsloc': '',\n",
       " 'spillsicsloc': '',\n",
       " 'spillsictloc': '',\n",
       " 'lstate': '',\n",
       " 'lfirm': '',\n",
       " 'firm_dum': '',\n",
       " 'hxrd': '',\n",
       " 'spillsicIV': '',\n",
       " 'spilltecIV': '',\n",
       " 'spillsicIV_mal': '',\n",
       " 'spilltecIV_mal': '',\n",
       " 'p005': '',\n",
       " 'sales_ind': 'Control variable - Total sales weighted by sic sales matrix',\n",
       " 'sales_ind_ns': 'Control variable - Total Value Shipments in Manufacturing from National Statisti',\n",
       " 'patents_ind': 'Control variable - Total number of patents weighted by tech matrix',\n",
       " 'pat_count': 'Patents per firm applied for that year',\n",
       " 'i': 'Unique firm level indentifier, like cusip but in numeric values',\n",
       " 'tic': 'company ticker',\n",
       " 'comn': 'company name',\n",
       " 'sic': 'primary SIC code (firm)',\n",
       " 'at': 'total assets (firm)',\n",
       " 'sales': 'total sales (firm)',\n",
       " 'oibdp': 'op. income before depr. (firm)',\n",
       " 'ib': 'income before extraord. items (firm)',\n",
       " 'emp': 'employment (firm)',\n",
       " 'dldte': 'data of deletion',\n",
       " 'dlrsn': 'reason of deletion',\n",
       " 'segnum': 'number of business segments',\n",
       " 'invt': 'Total inventories',\n",
       " 'intan': 'Total intangibles',\n",
       " 'ivaeq': 'Investments and advances - equity method',\n",
       " 'ivao': 'Investments and advances - other',\n",
       " 'act': 'Current assets - total',\n",
       " 'ao': 'Assets other',\n",
       " 'oiadp': 'Operating profits before amortization and depreciation',\n",
       " 'gics': '',\n",
       " 'poa': 'profits over assets',\n",
       " 'pos': 'profits over sales',\n",
       " 'mkvaf': 'Market value',\n",
       " 'dt': 'Total debt',\n",
       " 'pstk': 'Preferred Equity Total (par/stated value)',\n",
       " 'xad': 'Advertising expense',\n",
       " 'pi': 'Pre-tax income',\n",
       " 'aqi': '',\n",
       " 'aqs': '',\n",
       " 'ppegt': 'Plant, property and equipment, gross book value',\n",
       " 'capx': 'Capital expenditures',\n",
       " 'capxv': 'Capital expenditure through acquisition as well',\n",
       " 'xrent': '',\n",
       " 'xint': '',\n",
       " 'xintd': '',\n",
       " 'xlr': 'Labour expenses',\n",
       " 'xpr': '',\n",
       " 'xsga': '',\n",
       " 'cogs': '',\n",
       " 'invfg': '',\n",
       " 'invwip': '',\n",
       " 'invo': '',\n",
       " 'invrm': '',\n",
       " 'invval1': '',\n",
       " 'lifr': '',\n",
       " 'dp': '',\n",
       " 'la': 'log10(assets)',\n",
       " 'ls': 'log10(sales)',\n",
       " 'pindex': 'CPI price index used to deflate all variables',\n",
       " 'infl': '',\n",
       " 'inf': '',\n",
       " 'lsic': '',\n",
       " 'lcovsic': '',\n",
       " 'lmalsic': '',\n",
       " 'lmalcovsic': '',\n",
       " 'ltec': '',\n",
       " 'lcovtec': '',\n",
       " 'lmaltec': '',\n",
       " 'lmalcovtec': '',\n",
       " 'ltloc': '',\n",
       " 'lsloc': '',\n",
       " 'ltectloc': '',\n",
       " 'ltecsloc': '',\n",
       " 'lsicsloc': '',\n",
       " 'lsictloc': '',\n",
       " 'ltecIV': '',\n",
       " 'lsicIV': '',\n",
       " 'ltecIV_mal': '',\n",
       " 'lsicIV_mal': '',\n",
       " 'lxrd': 'Log R&D expenditure',\n",
       " 'lpatents_ind': 'Log Total patents in n-class weighted industries (by firm year) - tech shock con',\n",
       " 'lpatents_indt': '',\n",
       " 'lpatents_indm': '',\n",
       " 'ttt': '',\n",
       " 'lpatpat': '',\n",
       " 'lpat_count': 'Log of patent count by year - missing values -1 and missing indicator lpat_count',\n",
       " 'lpat_cite_norm': 'Log of cite weighted patent count by year',\n",
       " 'lsales': 'Log sales',\n",
       " 'lppent': 'Log of ppent - i.e. net tangible fixed assets',\n",
       " 'lemp': 'Log count of employees',\n",
       " 'pat_cite': 'Cites per firm',\n",
       " 'pat_cite_norm': 'Cites per firm, normalized to average 1 per year',\n",
       " 'dsales': '',\n",
       " 'demp': '',\n",
       " 'sales_emp': '',\n",
       " 'ppent_emp': '',\n",
       " 'dy': '',\n",
       " 'dym': '',\n",
       " 'jumpyear': '',\n",
       " 'oldnum': '',\n",
       " 'num': '',\n",
       " 'prob': '',\n",
       " 'dyear': '',\n",
       " 'lxrd1': 'Lag Log R&D expenditure',\n",
       " 'lsales1': 'Lag Log sales',\n",
       " 'sales1': '',\n",
       " 'lppent1': 'Lag Log of ppent - i.e. net tangible fixed assets',\n",
       " 'lemp1': 'Lag Log count of employees',\n",
       " 'lpatents_ind1': 'Lag Log Total patents in n-class weighted industries (by firm year) - tech shock',\n",
       " 'lpatents_ind2': 'Twice Lagged Log Total patents in n-class weighted industries (by firm year) - t',\n",
       " 'lpat_cite_norm1': 'Lag of Log of cite weighted patent count by year',\n",
       " 'lpat_count1': 'Lag of Log of patent count by year - missing values -1 and missing indicator lpa',\n",
       " 'pat_count1': '',\n",
       " 'gpatent': 'Cite weighted and year normalized stock of firm patents',\n",
       " 'gpatent_count': 'Stock of firm patent count',\n",
       " 'kpat_cite': '',\n",
       " 'rxrd': 'Expenditure on R&D, 1996 values',\n",
       " 'grd': 'Stock of R&D expenditures',\n",
       " 'rhxrd': '',\n",
       " 'ghxrd': 'Stock of instrument predicted R&D expenditures',\n",
       " 'rspillsic': '',\n",
       " 'gspillsic': '',\n",
       " 'lgspillsic': 'Log stock of sic weighted R&D (spillovers)',\n",
       " 'lgspillsic1': 'Lagged Log stock of sic weighted R&D (spillovers)',\n",
       " 'rspillcovsic': '',\n",
       " 'gspillcovsic': '',\n",
       " 'lgspillcovsic': '',\n",
       " 'lgspillcovsic1': '',\n",
       " 'rspillmalsic': '',\n",
       " 'gspillmalsic': '',\n",
       " 'lgspillmalsic': '',\n",
       " 'lgspillmalsic1': '',\n",
       " 'rspillmalcovsic': '',\n",
       " 'gspillmalcovsic': '',\n",
       " 'lgspillmalcovsic': '',\n",
       " 'lgspillmalcovsic1': '',\n",
       " 'rspilltec': '',\n",
       " 'gspilltec': '',\n",
       " 'lgspilltec': 'Log stock of tec weighted R&D (spillovers)',\n",
       " 'lgspilltec1': 'Lag Log stock of tec weighted R&D (spillovers)',\n",
       " 'rspillcovtec': '',\n",
       " 'gspillcovtec': '',\n",
       " 'lgspillcovtec': '',\n",
       " 'lgspillcovtec1': '',\n",
       " 'rspillmaltec': '',\n",
       " 'gspillmaltec': '',\n",
       " 'lgspillmaltec': '',\n",
       " 'lgspillmaltec1': '',\n",
       " 'rspillmalcovtec': '',\n",
       " 'gspillmalcovtec': '',\n",
       " 'lgspillmalcovtec': '',\n",
       " 'lgspillmalcovtec1': '',\n",
       " 'rspilltloc': '',\n",
       " 'gspilltloc': '',\n",
       " 'lgspilltloc': 'Log stock of location weighted R&D (spillovers)',\n",
       " 'lgspilltloc1': 'Lagged Log stock of location weighted R&D (spillovers)',\n",
       " 'rspillsloc': '',\n",
       " 'gspillsloc': '',\n",
       " 'lgspillsloc': 'Log stock of sales location weighted R&D (spillovers)',\n",
       " 'lgspillsloc1': 'Lagged Log stock of location weighted R&D (spillovers)',\n",
       " 'rspilltectloc': '',\n",
       " 'gspilltectloc': '',\n",
       " 'lgspilltectloc': '',\n",
       " 'lgspilltectloc1': '',\n",
       " 'rspilltecsloc': '',\n",
       " 'gspilltecsloc': '',\n",
       " 'lgspilltecsloc': '',\n",
       " 'lgspilltecsloc1': '',\n",
       " 'rspillsicsloc': '',\n",
       " 'gspillsicsloc': '',\n",
       " 'lgspillsicsloc': '',\n",
       " 'lgspillsicsloc1': '',\n",
       " 'rspillsictloc': '',\n",
       " 'gspillsictloc': '',\n",
       " 'lgspillsictloc': '',\n",
       " 'lgspillsictloc1': '',\n",
       " 'rspilltecIV': '',\n",
       " 'gspilltecIV': '',\n",
       " 'lgspilltecIV': '',\n",
       " 'lgspilltecIV1': '',\n",
       " 'rspillsicIV': '',\n",
       " 'gspillsicIV': '',\n",
       " 'lgspillsicIV': '',\n",
       " 'lgspillsicIV1': '',\n",
       " 'rspilltecIV_mal': '',\n",
       " 'gspilltecIV_mal': '',\n",
       " 'lgspilltecIV_mal': '',\n",
       " 'lgspilltecIV_mal1': '',\n",
       " 'rspillsicIV_mal': '',\n",
       " 'gspillsicIV_mal': '',\n",
       " 'lgspillsicIV_mal': '',\n",
       " 'lgspillsicIV_mal1': '',\n",
       " 'lkpat_cite': '',\n",
       " 'rppent': 'Net book value of property, plant and equipment in 1996 values',\n",
       " 'rcapx': '',\n",
       " 'kstock': 'Capital stock calculated by the perpetual inventory method from ppent initial va',\n",
       " 'lgrd': 'Log of stock of R&D expenditures',\n",
       " 'lghxrd': 'Log of stock of  instrument predicted R&D expenditures',\n",
       " 'lgpatent': 'Log of Cite weighted and year normalized stock of firm patents',\n",
       " 'lgpatent_count': 'Log Stock of firm patent count',\n",
       " 'lkstock': 'Log of Capital stock calculated by the perpetual inventory method from ppent ini',\n",
       " 'lcogs1': '',\n",
       " 'lgrd1': 'Lag Log of stock of R&D expenditures',\n",
       " 'lghxrd1': '',\n",
       " 'grd1': '',\n",
       " 'lgpatent1': 'Lag Log of Cite weighted and year normalized stock of firm patents',\n",
       " 'lgpatent_count1': 'Lag Log Stock of firm patent count',\n",
       " 'gpatent_count1': '',\n",
       " 'lkstock1': 'Lag Log of Capital stock calculated by the perpetual inventory method from ppent',\n",
       " 'dlsales': '',\n",
       " 'dlemp': '',\n",
       " 'dlppent': '',\n",
       " 'profit': '',\n",
       " 'lprofit': '',\n",
       " 'rmkvaf': '',\n",
       " 'rpstk': '',\n",
       " 'rdt': '',\n",
       " 'rinvt': '',\n",
       " 'rivaeq': '',\n",
       " 'rivao': '',\n",
       " 'rintan': '',\n",
       " 'ract': '',\n",
       " 'value': '',\n",
       " 'value_e': '',\n",
       " 'value_d': '',\n",
       " 'qkstock': '',\n",
       " 'dum_qkstock': \"Some minor numbers missing for kstock in Tobin's q - set to zero when missing\",\n",
       " 'tobinq': \"Tobin's Q calculated following Hall, Jaffe and Trajtenberg, 2000\",\n",
       " 'tobinq_e': \"Equity component of Tobin's Q calculated following Hall, Jaffe and Trajtenberg, \",\n",
       " 'tobinq_d': \"Debt component of Tobin's Q calculated following Hall, Jaffe and Trajtenberg, 20\",\n",
       " 'rawtobinq': '',\n",
       " 'lq': \"Log Tobin's Q\",\n",
       " 'lq_e': \"Log Tobin's Equity Q - tobinq_e\",\n",
       " 'lq_d': \"Log Tobin's Debt Q - tobinq_d\",\n",
       " 'lq1': \"Lag Log Tobin's Q\",\n",
       " 'grd_k': 'R&D stock divided by capital stock',\n",
       " 'gpat_k': 'Patent stock divided by capital stock',\n",
       " 'gpatcount_k': '',\n",
       " 'gtec_k': '',\n",
       " 'gsic_k': '',\n",
       " 'pat_k': '',\n",
       " 'grd_k_dum': 'R&D stock over capital missing dummy',\n",
       " 'grd_k1': 'lagged R&D stock over capital',\n",
       " 'gtec_k1': '',\n",
       " 'gsic_k1': '',\n",
       " 'pat_k1': '',\n",
       " 'grd_k1_dum': 'Lagged R&D stock over capital missing dummy',\n",
       " 'gpat_k1': 'Lagged Patent stock divided by capital stock',\n",
       " 'gpatcount_k1': '',\n",
       " 'gpat_k1_dum': 'Missing value indicator for lagged Patent stock divided by capital stock',\n",
       " 'gpatcount_k1_dum': '',\n",
       " 'gtecxrd_k': '',\n",
       " 'lkpat_cite1': '',\n",
       " 'pat_cite_norm1': '',\n",
       " 'yy12': 'year==  1981.0000',\n",
       " 'yy13': 'year==  1982.0000',\n",
       " 'yy14': 'year==  1983.0000',\n",
       " 'yy15': 'year==  1984.0000',\n",
       " 'yy16': 'year==  1985.0000',\n",
       " 'yy17': 'year==  1986.0000',\n",
       " 'yy18': 'year==  1987.0000',\n",
       " 'yy19': 'year==  1988.0000',\n",
       " 'yy20': 'year==  1989.0000',\n",
       " 'yy21': 'year==  1990.0000',\n",
       " 'yy22': 'year==  1991.0000',\n",
       " 'yy23': 'year==  1992.0000',\n",
       " 'yy24': 'year==  1993.0000',\n",
       " 'yy25': 'year==  1994.0000',\n",
       " 'yy26': 'year==  1995.0000',\n",
       " 'yy27': 'year==  1996.0000',\n",
       " 'yy28': 'year==  1997.0000',\n",
       " 'yy29': 'year==  1998.0000',\n",
       " 'yy30': 'year==  1999.0000',\n",
       " 'yy31': 'year==  2000.0000',\n",
       " 'yy32': 'year==  2001.0000',\n",
       " 'pat_all': 'Total granted patents per firm applied for over 1970-1999',\n",
       " 'ccog': '',\n",
       " 'sic3': 'Three digit SIC code',\n",
       " 'sic2': '',\n",
       " 'indwage': '',\n",
       " 'nwage': '',\n",
       " 'materials': '',\n",
       " 'rati': '',\n",
       " 'lmat1': '',\n",
       " 'grd_kt2': 'R&D stock over capital^2',\n",
       " 'grd_kt3': 'R&D stock over capital^3',\n",
       " 'grd_kt4': 'R&D stock over capital^4',\n",
       " 'grd_kt5': 'R&D stock over capital^5',\n",
       " 'grd_kt6': '',\n",
       " 'gpat_kt2': 'Patent stock over capital^2',\n",
       " 'gpat_kt3': 'Patent stock over capital^3',\n",
       " 'gpat_kt4': 'Patent stock over capital^4',\n",
       " 'gpat_kt5': 'Patent stock over capital^5',\n",
       " 'f_year': '',\n",
       " 'fyear': 'First year using actual data in patents stuff',\n",
       " 'myear': '',\n",
       " 'prior_years': 'Number of years used to make initial conditions',\n",
       " 'riorpat': '',\n",
       " 'riorpat_cite': '',\n",
       " 'riorlgpat': '',\n",
       " 'riorgrd': '',\n",
       " 'riorppent': '',\n",
       " 'riorsales': '',\n",
       " 'riorgspilltec': '',\n",
       " 'riorgspillsic': '',\n",
       " 'riorlq': '',\n",
       " 'riorgtec_k': '',\n",
       " 'riorgsic_k': '',\n",
       " 'riorgrd_k': '',\n",
       " 'riorlsales_ind': '',\n",
       " 'priorpat': '',\n",
       " 'priorpat_cite': '',\n",
       " 'priorlgpat': '',\n",
       " 'priorgrd': '',\n",
       " 'priorppent': '',\n",
       " 'priorsales': '',\n",
       " 'priorgspilltec': '',\n",
       " 'priorgspillsic': '',\n",
       " 'priorlq': '',\n",
       " 'priorgtec_k': '',\n",
       " 'priorgsic_k': '',\n",
       " 'priorgrd_k': '',\n",
       " 'priorlsales_ind': '',\n",
       " 'lsales_ind': 'Logged total sales weighted by SIC matrix',\n",
       " 'lsales_ind_ns': '',\n",
       " 'lsales_ind_ns_dum': '',\n",
       " 'lsales_ind1': 'Lagged Logged total sales weighted by SIC matrix',\n",
       " 'lsales_ind_ns1': '',\n",
       " 'lsales_ind_ns_dum1': '',\n",
       " 'lsales_ind2': 'Twice Lagged Logged total sales weighted by SIC matrix',\n",
       " 'priordum_grd_zero': '',\n",
       " 'lpriorgrd': 'Logged initial conditions stock of R&D (pre-sample values)',\n",
       " 'lpriorppent': 'Logged initial conditions ppent (pre-sample values)',\n",
       " 'lpriorsales': 'Logged initial conditions sales (pre-sample values)',\n",
       " 'lpriorgspilltec': 'Logged initial conditions lgspilltec (pre-sample values)',\n",
       " 'lpriorgspillsic': 'Logged initial conditions lgspillsic (pre-sample values)',\n",
       " 'lpriorpat': 'Logged initial conditions patent count (pre-sample values)',\n",
       " 'lpriorpat_cite': '',\n",
       " 'lpriorgrd_dum': 'Missing indicator for Logged initial conditions stock of R&D (pre-sample values)',\n",
       " 'lpriorgrd1': 'Lagged Logged initial conditions stock of R&D (pre-sample values)',\n",
       " 'lpriorgrd1_dum': 'Missing indicator for lagged Logged initial conditions stock of R&D (pre-sample ',\n",
       " 'lpriorpat_dum': 'Missing indicator for Logged initial conditions patent count (pre-sample values)',\n",
       " 'lpriorpat_cite_dum': '',\n",
       " 'lpriorpat1': 'Lagged Logged initial conditions patent count (pre-sample values)',\n",
       " 'lpriorpat1_dum': 'Missing indicator for Lagged Logged initial conditions patent count (pre-sample ',\n",
       " 'lpind_ind': 'Price index, yearly at 3-digit SIC level',\n",
       " 'pat_cite1': '',\n",
       " 'lpat_cite1': '',\n",
       " 'lpat_cite1_dum': '',\n",
       " 'lpat_cite': '',\n",
       " 'lgrd_dum': 'Missing indicator for Log of stock of R&D expenditures',\n",
       " 'lgrd1_dum': 'Missing indicator for Lag Log of stock of R&D expenditures',\n",
       " 'lpat_count_dum': 'Dummy for missing value of log of patent count by year',\n",
       " 'lpat_count1_dum': 'Dummy for missing value of lag of log of patent count by year',\n",
       " 'lgpatent_dum': 'Missing indicator for Log of Cite weighted and year normalized stock of firm pat',\n",
       " 'lgpatent1_dum': 'Missing indicator for lagged Log of Cite weighted and year normalized stock of f',\n",
       " 'lgpatent_count_dum': 'Missing indicator for Log Stock of firm patent count',\n",
       " 'lgpatent_count1_dum': 'Missing indicator for lagged Log Stock of firm patent count',\n",
       " 'code': 'CUSIP',\n",
       " 'pind_ind': 'Price index, yearly at 3-digit SIC level',\n",
       " 'psmooth': 'Fitted values',\n",
       " 'plin': '',\n",
       " 'pind_indm': '',\n",
       " 'rsales': 'Sales in 1996 values',\n",
       " 'lrsales': 'Log Sales in 1996 values',\n",
       " 'lrsales1': 'Lag Log Sales in 1996 values',\n",
       " 'lqq': '',\n",
       " 'lxrd_sales': '',\n",
       " 'lxrd_sales1': '',\n",
       " 'lfirm_dum': '',\n",
       " 'gfirm': '',\n",
       " 'lgfirm': '',\n",
       " 'lgfirm_dum': '',\n",
       " 'state': '',\n",
       " 'gstate': '',\n",
       " 'lgstate': '',\n",
       " 'lgfirm1': '',\n",
       " 'lgfirm_dum1': '',\n",
       " 'lgstate1': '',\n",
       " 'lfirm1': '',\n",
       " 'lfirm_dum1': '',\n",
       " 'lstate1': '',\n",
       " 'noj': 'Count observations per firm (includes pre-sample patent observations)'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.variable_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caed78af-4e44-4cdf-ad1d-04e70a2b2cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['i', 'year', 'rmkvaf', 'grd', 'grd_k1', 'rxrd', 'gspillsic',\n",
       "       'gspilltec', 'pat_count', 'pat_cite', 'rsales', 'rppent', 'emp',\n",
       "       'gspilltecIV', 'gspillsicIV'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars_of_int = ['i','year','rmkvaf','grd','grd_k1','rxrd','gspillsic','gspilltec','pat_count','pat_cite','rsales',\n",
    "              'rppent','emp','gspilltecIV','gspillsicIV']\n",
    "\n",
    "data = pd.read_stata(data_loc)\n",
    "df = data[vars_of_int]\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faf406bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_196/3340598184.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['year'] = df['year'].astype(str)\n",
      "/tmp/ipykernel_196/3340598184.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['i'] = df['i'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "# convert categorical columns to strings\n",
    "df['year'] = df['year'].astype(str)\n",
    "df['i'] = df['i'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ada76bb-9a0a-461e-b92b-39cfb388358b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmkvaf</th>\n",
       "      <th>gspilltecIV</th>\n",
       "      <th>gspillsicIV</th>\n",
       "      <th>pat_count</th>\n",
       "      <th>rsales</th>\n",
       "      <th>rppent</th>\n",
       "      <th>emp</th>\n",
       "      <th>rxrd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13385.00</td>\n",
       "      <td>13385.00</td>\n",
       "      <td>13385.00</td>\n",
       "      <td>13385.00</td>\n",
       "      <td>13385.00</td>\n",
       "      <td>13385.00</td>\n",
       "      <td>13385.00</td>\n",
       "      <td>13385.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3863.04</td>\n",
       "      <td>21341.64</td>\n",
       "      <td>6164.57</td>\n",
       "      <td>16.85</td>\n",
       "      <td>2852.77</td>\n",
       "      <td>1309.39</td>\n",
       "      <td>18.68</td>\n",
       "      <td>106.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16402.81</td>\n",
       "      <td>16288.44</td>\n",
       "      <td>9019.92</td>\n",
       "      <td>75.96</td>\n",
       "      <td>8782.54</td>\n",
       "      <td>4070.72</td>\n",
       "      <td>53.65</td>\n",
       "      <td>473.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.43</td>\n",
       "      <td>230.28</td>\n",
       "      <td>4.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>88.34</td>\n",
       "      <td>8991.68</td>\n",
       "      <td>607.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>117.32</td>\n",
       "      <td>27.22</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>409.62</td>\n",
       "      <td>17508.95</td>\n",
       "      <td>2067.49</td>\n",
       "      <td>1.00</td>\n",
       "      <td>450.26</td>\n",
       "      <td>121.87</td>\n",
       "      <td>3.85</td>\n",
       "      <td>4.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1990.41</td>\n",
       "      <td>29810.46</td>\n",
       "      <td>7534.20</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1950.00</td>\n",
       "      <td>731.75</td>\n",
       "      <td>14.00</td>\n",
       "      <td>30.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>485566.69</td>\n",
       "      <td>92324.67</td>\n",
       "      <td>55576.60</td>\n",
       "      <td>2405.00</td>\n",
       "      <td>140609.58</td>\n",
       "      <td>72825.98</td>\n",
       "      <td>876.80</td>\n",
       "      <td>8900.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          rmkvaf  gspilltecIV  gspillsicIV  pat_count     rsales    rppent  \\\n",
       "count   13385.00     13385.00     13385.00   13385.00   13385.00  13385.00   \n",
       "mean     3863.04     21341.64      6164.57      16.85    2852.77   1309.39   \n",
       "std     16402.81     16288.44      9019.92      75.96    8782.54   4070.72   \n",
       "min         0.43       230.28         4.31       0.00       1.08      0.91   \n",
       "25%        88.34      8991.68       607.00       0.00     117.32     27.22   \n",
       "50%       409.62     17508.95      2067.49       1.00     450.26    121.87   \n",
       "75%      1990.41     29810.46      7534.20       5.00    1950.00    731.75   \n",
       "max    485566.69     92324.67     55576.60    2405.00  140609.58  72825.98   \n",
       "\n",
       "            emp      rxrd  \n",
       "count  13385.00  13385.00  \n",
       "mean      18.68    106.59  \n",
       "std       53.65    473.90  \n",
       "min        0.10      0.00  \n",
       "25%        1.09      0.00  \n",
       "50%        3.85      4.68  \n",
       "75%       14.00     30.19  \n",
       "max      876.80   8900.00  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_of_int_noindex = ['rmkvaf','gspilltecIV','gspillsicIV','pat_count','rsales','rppent','emp','rxrd']\n",
    "\n",
    "# filter dataframe to variables of interest\n",
    "df = df.drop(columns=['grd','grd_k1','pat_cite','gspilltec','gspillsic'])\n",
    "\n",
    "# delete NaN values\n",
    "df = df.dropna(axis=0)\n",
    "\n",
    "#for i in range(0, len(var_of_int_noindex)):\n",
    "#    df = df[df[var_of_int_noindex[i]].isna() == False]\n",
    "\n",
    "#df = df.loc[df['rmkvaf'].isna() == False]\n",
    "\n",
    "df_sum_stats = df[var_of_int_noindex].describe()\n",
    "df_sum_stats = df_sum_stats.round(2)\n",
    "df_sum_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7521d293-0372-4623-b152-86df3a5fb4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrr}\n",
      "\\toprule\n",
      " & count & mean & std & min & 25% & 50% & 75% & max \\\\\n",
      "\\midrule\n",
      "rmkvaf & 13385.000000 & 3863.040000 & 16402.810000 & 0.430000 & 88.340000 & 409.620000 & 1990.410000 & 485566.690000 \\\\\n",
      "gspilltecIV & 13385.000000 & 21341.640000 & 16288.440000 & 230.280000 & 8991.680000 & 17508.950000 & 29810.460000 & 92324.670000 \\\\\n",
      "gspillsicIV & 13385.000000 & 6164.570000 & 9019.920000 & 4.310000 & 607.000000 & 2067.490000 & 7534.200000 & 55576.600000 \\\\\n",
      "pat_count & 13385.000000 & 16.850000 & 75.960000 & 0.000000 & 0.000000 & 1.000000 & 5.000000 & 2405.000000 \\\\\n",
      "rsales & 13385.000000 & 2852.770000 & 8782.540000 & 1.080000 & 117.320000 & 450.260000 & 1950.000000 & 140609.580000 \\\\\n",
      "rppent & 13385.000000 & 1309.390000 & 4070.720000 & 0.910000 & 27.220000 & 121.870000 & 731.750000 & 72825.980000 \\\\\n",
      "emp & 13385.000000 & 18.680000 & 53.650000 & 0.100000 & 1.090000 & 3.850000 & 14.000000 & 876.800000 \\\\\n",
      "rxrd & 13385.000000 & 106.590000 & 473.900000 & 0.000000 & 0.000000 & 4.680000 & 30.190000 & 8900.000000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#df_sum_stats.T.to_excel(\"sum_stats.xlsx\") # export summary statistics\n",
    "print(df_sum_stats.T.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbee5bf3",
   "metadata": {},
   "source": [
    "# OLS Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2734b2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run linear model\n",
    "# gen fixed effects\n",
    "time_effects = pd.get_dummies(df['year'])\n",
    "#time_effects.columns = time_effects.columns.astype(str)\n",
    "firm_effects = pd.get_dummies(df['i'])\n",
    "#time_effects.columns = time_effects.columns.astype(str)\n",
    "\n",
    "\n",
    "df = pd.merge(df, time_effects, left_on=df.index, right_on=time_effects.index, how='left')\n",
    "\n",
    "df = df.rename(columns={'key_0': 'old_key'})\n",
    "\n",
    "df = pd.merge(df, firm_effects, left_on=df['old_key'], right_on=firm_effects.index, how='left')\n",
    "\n",
    "fixed_effects = list(time_effects.columns.values)\n",
    "for col in firm_effects.columns.values:\n",
    "    fixed_effects.append(col)\n",
    "    \n",
    "# remove ref categories\n",
    "fixed_effects.remove('9999.0')\n",
    "fixed_effects.remove('1980')\n",
    "\n",
    "y_var = df['rmkvaf']\n",
    "\n",
    "# get df for x vars + fixed effects\n",
    "x_vars = ['gspilltecIV','gspillsicIV','pat_count','rsales','rppent','emp','rxrd']\n",
    "for col in fixed_effects:\n",
    "    x_vars.append(col)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8119f9ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>rmkvaf</td>      <th>  R-squared:         </th>  <td>   0.665</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.645</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   33.22</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 18 Oct 2024</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:53:18</td>     <th>  Log-Likelihood:    </th> <td>-1.4157e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 13385</td>      <th>  AIC:               </th>  <td>2.847e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 12629</td>      <th>  BIC:               </th>  <td>2.903e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>   755</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>       <td>-9940.5765</td> <td> 2385.347</td> <td>   -4.167</td> <td> 0.000</td> <td>-1.46e+04</td> <td>-5264.935</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gspilltecIV</th> <td>    0.1002</td> <td>    0.027</td> <td>    3.746</td> <td> 0.000</td> <td>    0.048</td> <td>    0.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gspillsicIV</th> <td>    0.3399</td> <td>    0.049</td> <td>    6.902</td> <td> 0.000</td> <td>    0.243</td> <td>    0.436</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pat_count</th>   <td>  -30.6018</td> <td>    1.838</td> <td>  -16.652</td> <td> 0.000</td> <td>  -34.204</td> <td>  -26.999</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rsales</th>      <td>    0.7812</td> <td>    0.037</td> <td>   21.055</td> <td> 0.000</td> <td>    0.708</td> <td>    0.854</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rppent</th>      <td>    0.6108</td> <td>    0.084</td> <td>    7.234</td> <td> 0.000</td> <td>    0.445</td> <td>    0.776</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>emp</th>         <td>   18.0641</td> <td>    7.147</td> <td>    2.527</td> <td> 0.012</td> <td>    4.054</td> <td>   32.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rxrd</th>        <td>   18.5941</td> <td>    0.614</td> <td>   30.295</td> <td> 0.000</td> <td>   17.391</td> <td>   19.797</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1981</th>        <td> -425.5119</td> <td>  618.180</td> <td>   -0.688</td> <td> 0.491</td> <td>-1637.239</td> <td>  786.215</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1982</th>        <td> -295.2372</td> <td>  616.239</td> <td>   -0.479</td> <td> 0.632</td> <td>-1503.159</td> <td>  912.685</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1983</th>        <td> -294.1870</td> <td>  609.557</td> <td>   -0.483</td> <td> 0.629</td> <td>-1489.011</td> <td>  900.637</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1984</th>        <td> -812.2257</td> <td>  607.964</td> <td>   -1.336</td> <td> 0.182</td> <td>-2003.927</td> <td>  379.476</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1985</th>        <td> -929.1950</td> <td>  609.921</td> <td>   -1.523</td> <td> 0.128</td> <td>-2124.732</td> <td>  266.343</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1986</th>        <td>-1184.5891</td> <td>  607.667</td> <td>   -1.949</td> <td> 0.051</td> <td>-2375.708</td> <td>    6.530</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1987</th>        <td>-1372.3041</td> <td>  607.937</td> <td>   -2.257</td> <td> 0.024</td> <td>-2563.953</td> <td> -180.655</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1988</th>        <td>-1686.4878</td> <td>  609.953</td> <td>   -2.765</td> <td> 0.006</td> <td>-2882.088</td> <td> -490.888</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1989</th>        <td>-1550.4891</td> <td>  610.972</td> <td>   -2.538</td> <td> 0.011</td> <td>-2748.088</td> <td> -352.891</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1990</th>        <td>-2052.0735</td> <td>  612.118</td> <td>   -3.352</td> <td> 0.001</td> <td>-3251.918</td> <td> -852.228</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1991</th>        <td>-1629.8854</td> <td>  614.732</td> <td>   -2.651</td> <td> 0.008</td> <td>-2834.854</td> <td> -424.917</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1992</th>        <td>-1754.6866</td> <td>  617.583</td> <td>   -2.841</td> <td> 0.005</td> <td>-2965.243</td> <td> -544.130</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1993</th>        <td>-1685.0176</td> <td>  621.230</td> <td>   -2.712</td> <td> 0.007</td> <td>-2902.723</td> <td> -467.312</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1994</th>        <td>-1916.7490</td> <td>  627.407</td> <td>   -3.055</td> <td> 0.002</td> <td>-3146.563</td> <td> -686.935</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1995</th>        <td>-1380.6021</td> <td>  636.986</td> <td>   -2.167</td> <td> 0.030</td> <td>-2629.191</td> <td> -132.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1996</th>        <td>-1098.4502</td> <td>  651.099</td> <td>   -1.687</td> <td> 0.092</td> <td>-2374.702</td> <td>  177.802</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1997</th>        <td> -692.3174</td> <td>  667.994</td> <td>   -1.036</td> <td> 0.300</td> <td>-2001.686</td> <td>  617.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1998</th>        <td> -575.0406</td> <td>  687.698</td> <td>   -0.836</td> <td> 0.403</td> <td>-1923.033</td> <td>  772.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1999</th>        <td>  142.3167</td> <td>  710.226</td> <td>    0.200</td> <td> 0.841</td> <td>-1249.835</td> <td> 1534.468</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2000</th>        <td> -207.4580</td> <td>  738.322</td> <td>   -0.281</td> <td> 0.779</td> <td>-1654.682</td> <td> 1239.766</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2001</th>        <td>-2283.3834</td> <td>  768.945</td> <td>   -2.970</td> <td> 0.003</td> <td>-3790.633</td> <td> -776.134</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10005.0</th>     <td> 8596.1312</td> <td> 3076.471</td> <td>    2.794</td> <td> 0.005</td> <td> 2565.781</td> <td> 1.46e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10006.0</th>     <td> 8240.3993</td> <td> 3516.122</td> <td>    2.344</td> <td> 0.019</td> <td> 1348.266</td> <td> 1.51e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10008.0</th>     <td> 7558.3544</td> <td> 3040.531</td> <td>    2.486</td> <td> 0.013</td> <td> 1598.452</td> <td> 1.35e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10016.0</th>     <td> 8488.3062</td> <td> 3060.494</td> <td>    2.774</td> <td> 0.006</td> <td> 2489.273</td> <td> 1.45e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10030.0</th>     <td> 9963.3568</td> <td> 3135.789</td> <td>    3.177</td> <td> 0.001</td> <td> 3816.734</td> <td> 1.61e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1004.0</th>      <td> 9403.1634</td> <td> 3133.966</td> <td>    3.000</td> <td> 0.003</td> <td> 3260.115</td> <td> 1.55e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10056.0</th>     <td> 7589.4824</td> <td> 3061.708</td> <td>    2.479</td> <td> 0.013</td> <td> 1588.069</td> <td> 1.36e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10085.0</th>     <td> 4090.3185</td> <td> 2997.861</td> <td>    1.364</td> <td> 0.172</td> <td>-1785.945</td> <td> 9966.582</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10092.0</th>     <td> 9204.1913</td> <td> 5393.483</td> <td>    1.707</td> <td> 0.088</td> <td>-1367.854</td> <td> 1.98e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10097.0</th>     <td> 2206.4047</td> <td> 2993.452</td> <td>    0.737</td> <td> 0.461</td> <td>-3661.215</td> <td> 8074.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1010.0</th>      <td> 8207.1099</td> <td> 5379.135</td> <td>    1.526</td> <td> 0.127</td> <td>-2336.812</td> <td> 1.88e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10109.0</th>     <td> 1.097e+04</td> <td> 3193.217</td> <td>    3.436</td> <td> 0.001</td> <td> 4711.604</td> <td> 1.72e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10115.0</th>     <td> 7957.3563</td> <td> 3058.537</td> <td>    2.602</td> <td> 0.009</td> <td> 1962.159</td> <td>  1.4e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10124.0</th>     <td>  1.11e+04</td> <td> 3199.490</td> <td>    3.470</td> <td> 0.001</td> <td> 4829.168</td> <td> 1.74e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1013.0</th>      <td> 4769.1715</td> <td> 2983.003</td> <td>    1.599</td> <td> 0.110</td> <td>-1077.968</td> <td> 1.06e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10150.0</th>     <td> 3170.2099</td> <td> 3465.956</td> <td>    0.915</td> <td> 0.360</td> <td>-3623.590</td> <td> 9964.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10159.0</th>     <td> 3378.9006</td> <td> 4384.246</td> <td>    0.771</td> <td> 0.441</td> <td>-5214.887</td> <td>  1.2e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10174.0</th>     <td> 1.021e+04</td> <td> 3389.760</td> <td>    3.012</td> <td> 0.003</td> <td> 3565.375</td> <td> 1.69e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10185.0</th>     <td> 8313.1068</td> <td> 3338.064</td> <td>    2.490</td> <td> 0.013</td> <td> 1769.995</td> <td> 1.49e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10195.0</th>     <td> 2593.7222</td> <td> 3141.189</td> <td>    0.826</td> <td> 0.409</td> <td>-3563.486</td> <td> 8750.931</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10198.0</th>     <td> 9933.5369</td> <td> 3131.022</td> <td>    3.173</td> <td> 0.002</td> <td> 3796.259</td> <td> 1.61e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10215.0</th>     <td>  1.08e+04</td> <td> 3193.341</td> <td>    3.381</td> <td> 0.001</td> <td> 4537.838</td> <td> 1.71e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10232.0</th>     <td> 6925.4903</td> <td> 3326.104</td> <td>    2.082</td> <td> 0.037</td> <td>  405.821</td> <td> 1.34e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10236.0</th>     <td> 9750.4628</td> <td> 3137.458</td> <td>    3.108</td> <td> 0.002</td> <td> 3600.569</td> <td> 1.59e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10286.0</th>     <td> 8274.2845</td> <td> 3121.219</td> <td>    2.651</td> <td> 0.008</td> <td> 2156.221</td> <td> 1.44e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10301.0</th>     <td>-1.476e+04</td> <td> 3014.308</td> <td>   -4.895</td> <td> 0.000</td> <td>-2.07e+04</td> <td>-8846.626</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10312.0</th>     <td> 9198.1294</td> <td> 3124.523</td> <td>    2.944</td> <td> 0.003</td> <td> 3073.591</td> <td> 1.53e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10332.0</th>     <td> 3868.1997</td> <td> 4061.176</td> <td>    0.952</td> <td> 0.341</td> <td>-4092.322</td> <td> 1.18e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1036.0</th>      <td> 7245.0618</td> <td> 3261.623</td> <td>    2.221</td> <td> 0.026</td> <td>  851.786</td> <td> 1.36e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10374.0</th>     <td> 8066.1980</td> <td> 3065.104</td> <td>    2.632</td> <td> 0.009</td> <td> 2058.129</td> <td> 1.41e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10386.0</th>     <td> 4140.6626</td> <td> 2986.789</td> <td>    1.386</td> <td> 0.166</td> <td>-1713.897</td> <td> 9995.222</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10391.0</th>     <td> 1064.5542</td> <td> 3026.844</td> <td>    0.352</td> <td> 0.725</td> <td>-4868.521</td> <td> 6997.629</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10407.0</th>     <td> 4895.6611</td> <td> 3017.572</td> <td>    1.622</td> <td> 0.105</td> <td>-1019.237</td> <td> 1.08e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10420.0</th>     <td> 8765.7651</td> <td> 3082.897</td> <td>    2.843</td> <td> 0.004</td> <td> 2722.820</td> <td> 1.48e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10422.0</th>     <td> 6959.5604</td> <td> 3252.126</td> <td>    2.140</td> <td> 0.032</td> <td>  584.899</td> <td> 1.33e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10426.0</th>     <td> 9660.2255</td> <td> 3299.137</td> <td>    2.928</td> <td> 0.003</td> <td> 3193.415</td> <td> 1.61e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10441.0</th>     <td> 1.026e+04</td> <td> 3164.254</td> <td>    3.241</td> <td> 0.001</td> <td> 4053.796</td> <td> 1.65e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1045.0</th>      <td>-1654.6262</td> <td> 3243.965</td> <td>   -0.510</td> <td> 0.610</td> <td>-8013.291</td> <td> 4704.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10453.0</th>     <td> 4005.2538</td> <td> 2991.151</td> <td>    1.339</td> <td> 0.181</td> <td>-1857.856</td> <td> 9868.364</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10482.0</th>     <td> -1.46e+04</td> <td> 3475.563</td> <td>   -4.201</td> <td> 0.000</td> <td>-2.14e+04</td> <td>-7789.183</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10498.0</th>     <td> 9301.1887</td> <td> 3158.846</td> <td>    2.944</td> <td> 0.003</td> <td> 3109.370</td> <td> 1.55e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10499.0</th>     <td>  290.8155</td> <td> 3069.162</td> <td>    0.095</td> <td> 0.925</td> <td>-5725.207</td> <td> 6306.838</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10511.0</th>     <td> 1.071e+04</td> <td> 3287.724</td> <td>    3.258</td> <td> 0.001</td> <td> 4268.117</td> <td> 1.72e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10519.0</th>     <td>-5675.1567</td> <td> 2981.921</td> <td>   -1.903</td> <td> 0.057</td> <td>-1.15e+04</td> <td>  169.862</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10530.0</th>     <td> 5301.0836</td> <td> 3009.281</td> <td>    1.762</td> <td> 0.078</td> <td> -597.565</td> <td> 1.12e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10537.0</th>     <td> 6186.0975</td> <td> 3392.545</td> <td>    1.823</td> <td> 0.068</td> <td> -463.806</td> <td> 1.28e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10540.0</th>     <td> 7576.5476</td> <td> 3032.964</td> <td>    2.498</td> <td> 0.012</td> <td> 1631.477</td> <td> 1.35e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10541.0</th>     <td> 8964.6580</td> <td> 3229.126</td> <td>    2.776</td> <td> 0.006</td> <td> 2635.080</td> <td> 1.53e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10550.0</th>     <td> 6593.4131</td> <td> 6048.079</td> <td>    1.090</td> <td> 0.276</td> <td>-5261.741</td> <td> 1.84e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10553.0</th>     <td> 3851.8113</td> <td> 3153.072</td> <td>    1.222</td> <td> 0.222</td> <td>-2328.689</td> <td>    1e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10565.0</th>     <td> 1.053e+04</td> <td> 3138.295</td> <td>    3.355</td> <td> 0.001</td> <td> 4378.941</td> <td> 1.67e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10580.0</th>     <td>  1.08e+04</td> <td> 3213.498</td> <td>    3.360</td> <td> 0.001</td> <td> 4498.657</td> <td> 1.71e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10581.0</th>     <td> 7665.2631</td> <td> 3106.263</td> <td>    2.468</td> <td> 0.014</td> <td> 1576.515</td> <td> 1.38e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10588.0</th>     <td> 1176.5368</td> <td> 2963.147</td> <td>    0.397</td> <td> 0.691</td> <td>-4631.681</td> <td> 6984.754</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10597.0</th>     <td> 8900.5001</td> <td> 3128.719</td> <td>    2.845</td> <td> 0.004</td> <td> 2767.736</td> <td>  1.5e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10599.0</th>     <td> 9271.0496</td> <td> 3139.906</td> <td>    2.953</td> <td> 0.003</td> <td> 3116.357</td> <td> 1.54e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10618.0</th>     <td> 8556.4419</td> <td> 3093.780</td> <td>    2.766</td> <td> 0.006</td> <td> 2492.162</td> <td> 1.46e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10656.0</th>     <td> 8664.1385</td> <td> 3068.114</td> <td>    2.824</td> <td> 0.005</td> <td> 2650.168</td> <td> 1.47e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10658.0</th>     <td> 8540.1624</td> <td> 3064.938</td> <td>    2.786</td> <td> 0.005</td> <td> 2532.418</td> <td> 1.45e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10726.0</th>     <td> 1.264e+04</td> <td> 3268.775</td> <td>    3.866</td> <td> 0.000</td> <td> 6231.058</td> <td>  1.9e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10734.0</th>     <td> 8389.8503</td> <td> 3727.109</td> <td>    2.251</td> <td> 0.024</td> <td> 1084.150</td> <td> 1.57e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10735.0</th>     <td> 1.002e+04</td> <td> 3173.342</td> <td>    3.159</td> <td> 0.002</td> <td> 3803.931</td> <td> 1.62e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10764.0</th>     <td> 1.051e+04</td> <td> 3276.657</td> <td>    3.207</td> <td> 0.001</td> <td> 4084.421</td> <td> 1.69e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10777.0</th>     <td> 8530.3531</td> <td> 3067.334</td> <td>    2.781</td> <td> 0.005</td> <td> 2517.913</td> <td> 1.45e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1078.0</th>      <td> 5453.6061</td> <td> 3082.313</td> <td>    1.769</td> <td> 0.077</td> <td> -588.196</td> <td> 1.15e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10793.0</th>     <td> 8093.7684</td> <td> 3137.200</td> <td>    2.580</td> <td> 0.010</td> <td> 1944.380</td> <td> 1.42e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10816.0</th>     <td> 7496.2748</td> <td> 3087.546</td> <td>    2.428</td> <td> 0.015</td> <td> 1444.216</td> <td> 1.35e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10839.0</th>     <td> 9481.3260</td> <td> 3097.020</td> <td>    3.061</td> <td> 0.002</td> <td> 3410.697</td> <td> 1.56e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10857.0</th>     <td>-2182.7305</td> <td> 3058.140</td> <td>   -0.714</td> <td> 0.475</td> <td>-8177.148</td> <td> 3811.687</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10867.0</th>     <td> 4643.9565</td> <td> 3339.296</td> <td>    1.391</td> <td> 0.164</td> <td>-1901.571</td> <td> 1.12e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10906.0</th>     <td> 8932.4951</td> <td> 3098.783</td> <td>    2.883</td> <td> 0.004</td> <td> 2858.410</td> <td>  1.5e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10950.0</th>     <td> 9034.0200</td> <td> 4140.834</td> <td>    2.182</td> <td> 0.029</td> <td>  917.357</td> <td> 1.72e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10983.0</th>     <td>-2.383e+04</td> <td> 3227.575</td> <td>   -7.383</td> <td> 0.000</td> <td>-3.02e+04</td> <td>-1.75e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1099.0</th>      <td> 8536.2893</td> <td> 3106.895</td> <td>    2.748</td> <td> 0.006</td> <td> 2446.304</td> <td> 1.46e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10991.0</th>     <td> 6926.2901</td> <td> 3614.928</td> <td>    1.916</td> <td> 0.055</td> <td> -159.519</td> <td>  1.4e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11012.0</th>     <td> 7880.6911</td> <td> 3137.824</td> <td>    2.512</td> <td> 0.012</td> <td> 1730.080</td> <td>  1.4e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11038.0</th>     <td> 3251.3206</td> <td> 3219.125</td> <td>    1.010</td> <td> 0.313</td> <td>-3058.654</td> <td> 9561.295</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1104.0</th>      <td> 9488.5996</td> <td> 3138.344</td> <td>    3.023</td> <td> 0.003</td> <td> 3336.969</td> <td> 1.56e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11060.0</th>     <td> 9235.2591</td> <td> 3132.146</td> <td>    2.949</td> <td> 0.003</td> <td> 3095.777</td> <td> 1.54e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11094.0</th>     <td> 8684.5592</td> <td> 3089.265</td> <td>    2.811</td> <td> 0.005</td> <td> 2629.130</td> <td> 1.47e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11096.0</th>     <td> 6740.1208</td> <td> 3028.318</td> <td>    2.226</td> <td> 0.026</td> <td>  804.158</td> <td> 1.27e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11113.0</th>     <td> 9316.9328</td> <td> 3367.569</td> <td>    2.767</td> <td> 0.006</td> <td> 2715.986</td> <td> 1.59e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1115.0</th>      <td> 7875.2019</td> <td> 3125.463</td> <td>    2.520</td> <td> 0.012</td> <td> 1748.819</td> <td>  1.4e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11161.0</th>     <td> 6631.5622</td> <td> 3048.603</td> <td>    2.175</td> <td> 0.030</td> <td>  655.838</td> <td> 1.26e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11225.0</th>     <td> 1.031e+04</td> <td> 3223.600</td> <td>    3.198</td> <td> 0.001</td> <td> 3991.623</td> <td> 1.66e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11228.0</th>     <td> 1.001e+04</td> <td> 3111.122</td> <td>    3.217</td> <td> 0.001</td> <td> 3909.102</td> <td> 1.61e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11236.0</th>     <td> 4820.4345</td> <td> 4564.449</td> <td>    1.056</td> <td> 0.291</td> <td>-4126.579</td> <td> 1.38e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11288.0</th>     <td>  726.5183</td> <td> 3139.333</td> <td>    0.231</td> <td> 0.817</td> <td>-5427.050</td> <td> 6880.087</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11312.0</th>     <td>  624.6433</td> <td> 3085.276</td> <td>    0.202</td> <td> 0.840</td> <td>-5422.965</td> <td> 6672.252</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11361.0</th>     <td> 8139.1393</td> <td> 3054.443</td> <td>    2.665</td> <td> 0.008</td> <td> 2151.966</td> <td> 1.41e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11399.0</th>     <td> 1883.4788</td> <td> 2984.861</td> <td>    0.631</td> <td> 0.528</td> <td>-3967.302</td> <td> 7734.260</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>114303.0</th>    <td>-8981.4766</td> <td> 5402.255</td> <td>   -1.663</td> <td> 0.096</td> <td>-1.96e+04</td> <td> 1607.764</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11456.0</th>     <td> 3026.3818</td> <td> 3078.672</td> <td>    0.983</td> <td> 0.326</td> <td>-3008.282</td> <td> 9061.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11465.0</th>     <td> 4113.0085</td> <td> 3092.455</td> <td>    1.330</td> <td> 0.184</td> <td>-1948.673</td> <td> 1.02e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11502.0</th>     <td> 9343.9264</td> <td> 3174.590</td> <td>    2.943</td> <td> 0.003</td> <td> 3121.249</td> <td> 1.56e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11506.0</th>     <td> 4190.2588</td> <td> 3073.981</td> <td>    1.363</td> <td> 0.173</td> <td>-1835.210</td> <td> 1.02e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11537.0</th>     <td> 9104.8465</td> <td> 3090.809</td> <td>    2.946</td> <td> 0.003</td> <td> 3046.392</td> <td> 1.52e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11566.0</th>     <td> 1.069e+04</td> <td> 3188.150</td> <td>    3.352</td> <td> 0.001</td> <td> 4436.526</td> <td> 1.69e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11573.0</th>     <td> 8122.9750</td> <td> 3053.915</td> <td>    2.660</td> <td> 0.008</td> <td> 2136.837</td> <td> 1.41e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11580.0</th>     <td> 4660.7676</td> <td> 3401.528</td> <td>    1.370</td> <td> 0.171</td> <td>-2006.744</td> <td> 1.13e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11600.0</th>     <td> 9955.4797</td> <td> 3181.578</td> <td>    3.129</td> <td> 0.002</td> <td> 3719.104</td> <td> 1.62e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11609.0</th>     <td> 1.339e+04</td> <td> 3141.316</td> <td>    4.263</td> <td> 0.000</td> <td> 7234.942</td> <td> 1.95e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1161.0</th>      <td>-1142.7795</td> <td> 2963.636</td> <td>   -0.386</td> <td> 0.700</td> <td>-6951.956</td> <td> 4666.397</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11636.0</th>     <td>-1.033e+04</td> <td> 3195.420</td> <td>   -3.234</td> <td> 0.001</td> <td>-1.66e+04</td> <td>-4069.451</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11670.0</th>     <td> 1.045e+04</td> <td> 3195.585</td> <td>    3.270</td> <td> 0.001</td> <td> 4186.263</td> <td> 1.67e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11678.0</th>     <td> -172.3965</td> <td> 3111.159</td> <td>   -0.055</td> <td> 0.956</td> <td>-6270.740</td> <td> 5925.947</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11682.0</th>     <td> 8157.6451</td> <td> 3195.335</td> <td>    2.553</td> <td> 0.011</td> <td> 1894.303</td> <td> 1.44e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11694.0</th>     <td> 9735.1845</td> <td> 3265.189</td> <td>    2.982</td> <td> 0.003</td> <td> 3334.919</td> <td> 1.61e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11720.0</th>     <td> 2342.1807</td> <td> 3978.963</td> <td>    0.589</td> <td> 0.556</td> <td>-5457.192</td> <td> 1.01e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11721.0</th>     <td>-3708.6926</td> <td> 3442.247</td> <td>   -1.077</td> <td> 0.281</td> <td>-1.05e+04</td> <td> 3038.635</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11722.0</th>     <td> 7939.5465</td> <td> 3308.424</td> <td>    2.400</td> <td> 0.016</td> <td> 1454.532</td> <td> 1.44e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11793.0</th>     <td> 6392.4048</td> <td> 6063.166</td> <td>    1.054</td> <td> 0.292</td> <td>-5492.321</td> <td> 1.83e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11797.0</th>     <td> 1.098e+04</td> <td> 3552.518</td> <td>    3.091</td> <td> 0.002</td> <td> 4015.910</td> <td> 1.79e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11914.0</th>     <td> 9253.8306</td> <td> 3755.065</td> <td>    2.464</td> <td> 0.014</td> <td> 1893.333</td> <td> 1.66e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1209.0</th>      <td> 6916.3882</td> <td> 3021.090</td> <td>    2.289</td> <td> 0.022</td> <td>  994.593</td> <td> 1.28e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>12136.0</th>     <td>-5842.3430</td> <td> 3290.133</td> <td>   -1.776</td> <td> 0.076</td> <td>-1.23e+04</td> <td>  606.816</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>12141.0</th>     <td> 8.981e+04</td> <td> 3291.619</td> <td>   27.284</td> <td> 0.000</td> <td> 8.34e+04</td> <td> 9.63e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>12181.0</th>     <td> 6468.7957</td> <td> 4281.785</td> <td>    1.511</td> <td> 0.131</td> <td>-1924.153</td> <td> 1.49e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>12215.0</th>     <td> -753.1168</td> <td> 3219.104</td> <td>   -0.234</td> <td> 0.815</td> <td>-7063.050</td> <td> 5556.816</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>12216.0</th>     <td> 3866.8554</td> <td> 3252.277</td> <td>    1.189</td> <td> 0.234</td> <td>-2508.101</td> <td> 1.02e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>12256.0</th>     <td> 2682.4219</td> <td> 3240.915</td> <td>    0.828</td> <td> 0.408</td> <td>-3670.264</td> <td> 9035.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>12262.0</th>     <td> 9564.5090</td> <td> 3423.360</td> <td>    2.794</td> <td> 0.005</td> <td> 2854.203</td> <td> 1.63e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>12389.0</th>     <td> 8986.4050</td> <td> 3304.204</td> <td>    2.720</td> <td> 0.007</td> <td> 2509.663</td> <td> 1.55e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1239.0</th>      <td> 6577.3859</td> <td> 3030.471</td> <td>    2.170</td> <td> 0.030</td> <td>  637.203</td> <td> 1.25e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>12390.0</th>     <td> 7461.3813</td> <td> 3602.948</td> <td>    2.071</td> <td> 0.038</td> <td>  399.057</td> <td> 1.45e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>12397.0</th>     <td> 6292.8548</td> <td> 5345.675</td> <td>    1.177</td> <td> 0.239</td> <td>-4185.481</td> <td> 1.68e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1243.0</th>      <td> 4184.8534</td> <td> 3158.124</td> <td>    1.325</td> <td> 0.185</td> <td>-2005.548</td> <td> 1.04e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>12548.0</th>     <td> 9038.3456</td> <td> 3632.299</td> <td>    2.488</td> <td> 0.013</td> <td> 1918.488</td> <td> 1.62e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>12570.0</th>     <td> 8969.7124</td> <td> 3499.499</td> <td>    2.563</td> <td> 0.010</td> <td> 2110.162</td> <td> 1.58e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>12581.0</th>     <td> 6220.9585</td> <td> 3679.891</td> <td>    1.691</td> <td> 0.091</td> <td> -992.187</td> <td> 1.34e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>12592.0</th>     <td> 7907.3965</td> <td> 3465.117</td> <td>    2.282</td> <td> 0.023</td> <td> 1115.241</td> <td> 1.47e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>12604.0</th>     <td> 7117.2488</td> <td> 6104.480</td> <td>    1.166</td> <td> 0.244</td> <td>-4848.459</td> <td> 1.91e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>12656.0</th>     <td> 1.071e+04</td> <td> 3513.018</td> <td>    3.048</td> <td> 0.002</td> <td> 3822.505</td> <td> 1.76e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>12679.0</th>     <td>-8243.1620</td> <td> 3377.006</td> <td>   -2.441</td> <td> 0.015</td> <td>-1.49e+04</td> <td>-1623.718</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1278.0</th>      <td> 9559.3089</td> <td> 3276.729</td> <td>    2.917</td> <td> 0.004</td> <td> 3136.423</td> <td>  1.6e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>12788.0</th>     <td>-2571.9810</td> <td> 3720.888</td> <td>   -0.691</td> <td> 0.489</td> <td>-9865.486</td> <td> 4721.524</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1283.0</th>      <td> 9778.5694</td> <td> 3188.479</td> <td>    3.067</td> <td> 0.002</td> <td> 3528.666</td> <td>  1.6e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1297.0</th>      <td> 8851.0971</td> <td> 3160.094</td> <td>    2.801</td> <td> 0.005</td> <td> 2656.833</td> <td>  1.5e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>12992.0</th>     <td> 1.022e+04</td> <td> 3469.470</td> <td>    2.945</td> <td> 0.003</td> <td> 3415.928</td> <td>  1.7e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>13135.0</th>     <td> 5736.5602</td> <td> 3444.412</td> <td>    1.665</td> <td> 0.096</td> <td>-1015.010</td> <td> 1.25e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1327.0</th>      <td> 2830.7666</td> <td> 3184.260</td> <td>    0.889</td> <td> 0.374</td> <td>-3410.866</td> <td> 9072.399</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>13282.0</th>     <td> 3707.5355</td> <td> 5340.406</td> <td>    0.694</td> <td> 0.488</td> <td>-6760.470</td> <td> 1.42e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1334.0</th>      <td> 1959.2153</td> <td> 3392.421</td> <td>    0.578</td> <td> 0.564</td> <td>-4690.446</td> <td> 8608.876</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>13351.0</th>     <td> 3934.9513</td> <td> 3942.379</td> <td>    0.998</td> <td> 0.318</td> <td>-3792.710</td> <td> 1.17e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>13365.0</th>     <td>-7664.6310</td> <td> 3538.787</td> <td>   -2.166</td> <td> 0.030</td> <td>-1.46e+04</td> <td> -728.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>13369.0</th>     <td> 6192.2784</td> <td> 3353.245</td> <td>    1.847</td> <td> 0.065</td> <td> -380.592</td> <td> 1.28e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>13406.0</th>     <td> 9511.9068</td> <td> 3422.019</td> <td>    2.780</td> <td> 0.005</td> <td> 2804.230</td> <td> 1.62e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>13407.0</th>     <td> 3435.2039</td> <td> 3325.530</td> <td>    1.033</td> <td> 0.302</td> <td>-3083.341</td> <td> 9953.749</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>13417.0</th>     <td> 1.054e+04</td> <td> 3627.974</td> <td>    2.906</td> <td> 0.004</td> <td> 3431.229</td> <td> 1.77e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>13525.0</th>     <td> 2730.9588</td> <td> 3557.222</td> <td>    0.768</td> <td> 0.443</td> <td>-4241.736</td> <td> 9703.654</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>13554.0</th>     <td>  1.11e+04</td> <td> 3515.274</td> <td>    3.158</td> <td> 0.002</td> <td> 4209.150</td> <td>  1.8e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1359.0</th>      <td>  231.6921</td> <td> 3271.221</td> <td>    0.071</td> <td> 0.944</td> <td>-6180.398</td> <td> 6643.783</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>13623.0</th>     <td> 7757.8946</td> <td> 3398.861</td> <td>    2.282</td> <td> 0.022</td> <td> 1095.611</td> <td> 1.44e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1372.0</th>      <td> 2969.1064</td> <td> 3094.408</td> <td>    0.960</td> <td> 0.337</td> <td>-3096.404</td> <td> 9034.616</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1380.0</th>      <td> 2428.4690</td> <td> 3086.422</td> <td>    0.787</td> <td> 0.431</td> <td>-3621.386</td> <td> 8478.324</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>13923.0</th>     <td> 9004.3585</td> <td> 3723.204</td> <td>    2.418</td> <td> 0.016</td> <td> 1706.314</td> <td> 1.63e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>13932.0</th>     <td> 9906.5945</td> <td> 4225.421</td> <td>    2.345</td> <td> 0.019</td> <td> 1624.127</td> <td> 1.82e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>13941.0</th>     <td> -775.7343</td> <td> 3345.291</td> <td>   -0.232</td> <td> 0.817</td> <td>-7333.012</td> <td> 5781.544</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1397.0</th>      <td> 7611.2849</td> <td> 3344.240</td> <td>    2.276</td> <td> 0.023</td> <td> 1056.066</td> <td> 1.42e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>14064.0</th>     <td> 7822.3534</td> <td> 3374.212</td> <td>    2.318</td> <td> 0.020</td> <td> 1208.386</td> <td> 1.44e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>14084.0</th>     <td> 7161.9191</td> <td> 3367.382</td> <td>    2.127</td> <td> 0.033</td> <td>  561.340</td> <td> 1.38e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>14324.0</th>     <td> 2450.1067</td> <td> 3416.939</td> <td>    0.717</td> <td> 0.473</td> <td>-4247.612</td> <td> 9147.825</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>14462.0</th>     <td> 5896.9695</td> <td> 3424.853</td> <td>    1.722</td> <td> 0.085</td> <td> -816.263</td> <td> 1.26e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1447.0</th>      <td> 1.291e+04</td> <td> 4617.436</td> <td>    2.796</td> <td> 0.005</td> <td> 3861.195</td> <td>  2.2e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>14531.0</th>     <td> 6013.3098</td> <td>    1e+04</td> <td>    0.600</td> <td> 0.549</td> <td>-1.36e+04</td> <td> 2.57e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>14593.0</th>     <td> 9717.6801</td> <td> 3546.928</td> <td>    2.740</td> <td> 0.006</td> <td> 2765.162</td> <td> 1.67e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>14622.0</th>     <td> 8494.5972</td> <td> 7256.705</td> <td>    1.171</td> <td> 0.242</td> <td>-5729.646</td> <td> 2.27e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1465.0</th>      <td> 9293.7357</td> <td> 3759.137</td> <td>    2.472</td> <td> 0.013</td> <td> 1925.257</td> <td> 1.67e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1468.0</th>      <td> 9813.2527</td> <td> 3591.620</td> <td>    2.732</td> <td> 0.006</td> <td> 2773.133</td> <td> 1.69e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>14897.0</th>     <td> 8912.7989</td> <td> 5404.388</td> <td>    1.649</td> <td> 0.099</td> <td>-1680.623</td> <td> 1.95e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>14954.0</th>     <td> 9310.1232</td> <td> 3588.857</td> <td>    2.594</td> <td> 0.009</td> <td> 2275.418</td> <td> 1.63e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1496.0</th>      <td> 1.018e+04</td> <td> 3142.118</td> <td>    3.241</td> <td> 0.001</td> <td> 4023.346</td> <td> 1.63e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>15267.0</th>     <td> 8561.1899</td> <td> 3545.299</td> <td>    2.415</td> <td> 0.016</td> <td> 1611.865</td> <td> 1.55e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>15354.0</th>     <td> 3951.6292</td> <td> 3545.461</td> <td>    1.115</td> <td> 0.265</td> <td>-2998.013</td> <td> 1.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1542.0</th>      <td> 8274.0285</td> <td> 3128.411</td> <td>    2.645</td> <td> 0.008</td> <td> 2141.867</td> <td> 1.44e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>15459.0</th>     <td> 4755.0666</td> <td> 3491.964</td> <td>    1.362</td> <td> 0.173</td> <td>-2089.713</td> <td> 1.16e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1554.0</th>      <td> 1.008e+04</td> <td> 3139.681</td> <td>    3.211</td> <td> 0.001</td> <td> 3928.295</td> <td> 1.62e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>15708.0</th>     <td>-8685.5979</td> <td> 3678.105</td> <td>   -2.361</td> <td> 0.018</td> <td>-1.59e+04</td> <td>-1475.954</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>15711.0</th>     <td> 7018.0335</td> <td> 3521.077</td> <td>    1.993</td> <td> 0.046</td> <td>  116.187</td> <td> 1.39e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>15761.0</th>     <td> 9603.3202</td> <td> 4161.317</td> <td>    2.308</td> <td> 0.021</td> <td> 1446.507</td> <td> 1.78e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1581.0</th>      <td>-2.338e+04</td> <td> 4066.536</td> <td>   -5.750</td> <td> 0.000</td> <td>-3.14e+04</td> <td>-1.54e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1593.0</th>      <td> 7360.1914</td> <td> 3039.605</td> <td>    2.421</td> <td> 0.015</td> <td> 1402.105</td> <td> 1.33e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1602.0</th>      <td> 1.541e+04</td> <td> 3144.958</td> <td>    4.899</td> <td> 0.000</td> <td> 9241.495</td> <td> 2.16e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1613.0</th>      <td> 9518.7977</td> <td> 3135.907</td> <td>    3.035</td> <td> 0.002</td> <td> 3371.944</td> <td> 1.57e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>16188.0</th>     <td> 6141.7233</td> <td> 3600.100</td> <td>    1.706</td> <td> 0.088</td> <td> -915.020</td> <td> 1.32e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1632.0</th>      <td> 2730.6569</td> <td> 2967.596</td> <td>    0.920</td> <td> 0.358</td> <td>-3086.281</td> <td> 8547.595</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1633.0</th>      <td> 7645.1535</td> <td> 3073.458</td> <td>    2.487</td> <td> 0.013</td> <td> 1620.710</td> <td> 1.37e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1635.0</th>      <td>-2279.6622</td> <td> 3207.382</td> <td>   -0.711</td> <td> 0.477</td> <td>-8566.618</td> <td> 4007.294</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>16401.0</th>     <td>-2106.7953</td> <td> 3535.255</td> <td>   -0.596</td> <td> 0.551</td> <td>-9036.432</td> <td> 4822.842</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>16437.0</th>     <td> 2453.7358</td> <td> 4040.565</td> <td>    0.607</td> <td> 0.544</td> <td>-5466.386</td> <td> 1.04e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1651.0</th>      <td> 5550.2093</td> <td> 3015.031</td> <td>    1.841</td> <td> 0.066</td> <td> -359.709</td> <td> 1.15e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1655.0</th>      <td> 9615.4742</td> <td> 3116.290</td> <td>    3.086</td> <td> 0.002</td> <td> 3507.073</td> <td> 1.57e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1663.0</th>      <td> 1.375e+04</td> <td> 3117.223</td> <td>    4.412</td> <td> 0.000</td> <td> 7643.430</td> <td> 1.99e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>16710.0</th>     <td> 4741.7051</td> <td> 3561.723</td> <td>    1.331</td> <td> 0.183</td> <td>-2239.813</td> <td> 1.17e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>16729.0</th>     <td> 4221.0150</td> <td> 3488.991</td> <td>    1.210</td> <td> 0.226</td> <td>-2617.938</td> <td> 1.11e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1690.0</th>      <td>-9476.8601</td> <td> 3052.010</td> <td>   -3.105</td> <td> 0.002</td> <td>-1.55e+04</td> <td>-3494.457</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1703.0</th>      <td> 7131.1531</td> <td> 3145.834</td> <td>    2.267</td> <td> 0.023</td> <td>  964.841</td> <td> 1.33e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>17101.0</th>     <td>-1.039e+04</td> <td> 1.02e+04</td> <td>   -1.021</td> <td> 0.307</td> <td>-3.04e+04</td> <td> 9567.672</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>17202.0</th>     <td> 8565.2847</td> <td> 3580.793</td> <td>    2.392</td> <td> 0.017</td> <td> 1546.386</td> <td> 1.56e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1722.0</th>      <td> 7635.3384</td> <td> 3120.097</td> <td>    2.447</td> <td> 0.014</td> <td> 1519.474</td> <td> 1.38e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1728.0</th>      <td> 9786.0208</td> <td> 3133.400</td> <td>    3.123</td> <td> 0.002</td> <td> 3644.082</td> <td> 1.59e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1743.0</th>      <td> 9206.6002</td> <td> 4065.126</td> <td>    2.265</td> <td> 0.024</td> <td> 1238.335</td> <td> 1.72e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1754.0</th>      <td> 9356.9783</td> <td> 3245.442</td> <td>    2.883</td> <td> 0.004</td> <td> 2995.419</td> <td> 1.57e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1762.0</th>      <td> 3530.4584</td> <td> 3070.682</td> <td>    1.150</td> <td> 0.250</td> <td>-2488.544</td> <td> 9549.461</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1773.0</th>      <td> 9383.6572</td> <td> 3200.790</td> <td>    2.932</td> <td> 0.003</td> <td> 3109.623</td> <td> 1.57e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1786.0</th>      <td>-2446.1653</td> <td> 3027.221</td> <td>   -0.808</td> <td> 0.419</td> <td>-8379.979</td> <td> 3487.648</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>18100.0</th>     <td> 7610.5863</td> <td> 3547.409</td> <td>    2.145</td> <td> 0.032</td> <td>  657.126</td> <td> 1.46e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1820.0</th>      <td> 7035.3148</td> <td> 3094.333</td> <td>    2.274</td> <td> 0.023</td> <td>  969.953</td> <td> 1.31e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1848.0</th>      <td>-1341.5977</td> <td> 3489.590</td> <td>   -0.384</td> <td> 0.701</td> <td>-8181.724</td> <td> 5498.529</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>18654.0</th>     <td> 9308.6209</td> <td> 4398.704</td> <td>    2.116</td> <td> 0.034</td> <td>  686.493</td> <td> 1.79e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1875.0</th>      <td> 5422.0706</td> <td> 4559.415</td> <td>    1.189</td> <td> 0.234</td> <td>-3515.075</td> <td> 1.44e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1884.0</th>      <td> 9556.3065</td> <td> 3257.766</td> <td>    2.933</td> <td> 0.003</td> <td> 3170.590</td> <td> 1.59e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1913.0</th>      <td> 5067.5445</td> <td> 3013.058</td> <td>    1.682</td> <td> 0.093</td> <td> -838.507</td> <td>  1.1e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1919.0</th>      <td> 8460.0632</td> <td> 3225.767</td> <td>    2.623</td> <td> 0.009</td> <td> 2137.070</td> <td> 1.48e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1920.0</th>      <td> 5677.3684</td> <td> 2997.340</td> <td>    1.894</td> <td> 0.058</td> <td> -197.872</td> <td> 1.16e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1968.0</th>      <td> 7609.1915</td> <td> 3040.834</td> <td>    2.502</td> <td> 0.012</td> <td> 1648.695</td> <td> 1.36e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1976.0</th>      <td> 1.067e+04</td> <td> 3116.261</td> <td>    3.425</td> <td> 0.001</td> <td> 4565.380</td> <td> 1.68e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1981.0</th>      <td> 9170.2560</td> <td> 3119.840</td> <td>    2.939</td> <td> 0.003</td> <td> 3054.895</td> <td> 1.53e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1988.0</th>      <td>   67.7686</td> <td> 3946.416</td> <td>    0.017</td> <td> 0.986</td> <td>-7667.806</td> <td> 7803.344</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1992.0</th>      <td> 7764.2033</td> <td> 3046.140</td> <td>    2.549</td> <td> 0.011</td> <td> 1793.305</td> <td> 1.37e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2008.0</th>      <td> 8115.3533</td> <td> 3045.881</td> <td>    2.664</td> <td> 0.008</td> <td> 2144.965</td> <td> 1.41e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2033.0</th>      <td> 9191.5623</td> <td> 3578.712</td> <td>    2.568</td> <td> 0.010</td> <td> 2176.744</td> <td> 1.62e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2044.0</th>      <td> 7375.6500</td> <td> 3054.171</td> <td>    2.415</td> <td> 0.016</td> <td> 1389.011</td> <td> 1.34e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2049.0</th>      <td> 7958.9282</td> <td> 3057.521</td> <td>    2.603</td> <td> 0.009</td> <td> 1965.724</td> <td>  1.4e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2061.0</th>      <td> 1.067e+04</td> <td> 3184.425</td> <td>    3.350</td> <td> 0.001</td> <td> 4425.887</td> <td> 1.69e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>20779.0</th>     <td> 5.298e+04</td> <td> 3626.010</td> <td>   14.611</td> <td> 0.000</td> <td> 4.59e+04</td> <td> 6.01e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2085.0</th>      <td>-2797.9037</td> <td> 3091.351</td> <td>   -0.905</td> <td> 0.365</td> <td>-8857.420</td> <td> 3261.613</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2086.0</th>      <td> 6298.7693</td> <td> 3040.273</td> <td>    2.072</td> <td> 0.038</td> <td>  339.373</td> <td> 1.23e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2111.0</th>      <td> 7111.0506</td> <td> 3027.347</td> <td>    2.349</td> <td> 0.019</td> <td> 1176.992</td> <td>  1.3e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>21204.0</th>     <td> 5065.4342</td> <td> 3773.658</td> <td>    1.342</td> <td> 0.180</td> <td>-2331.508</td> <td> 1.25e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>21238.0</th>     <td> 9630.2308</td> <td> 3715.731</td> <td>    2.592</td> <td> 0.010</td> <td> 2346.833</td> <td> 1.69e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2124.0</th>      <td> 7814.7292</td> <td> 3156.973</td> <td>    2.475</td> <td> 0.013</td> <td> 1626.582</td> <td>  1.4e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2146.0</th>      <td> 1.782e+04</td> <td> 3967.047</td> <td>    4.493</td> <td> 0.000</td> <td>    1e+04</td> <td> 2.56e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>21496.0</th>     <td>-9707.4783</td> <td> 3795.661</td> <td>   -2.558</td> <td> 0.011</td> <td>-1.71e+04</td> <td>-2267.406</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2154.0</th>      <td> 8531.2191</td> <td> 3092.395</td> <td>    2.759</td> <td> 0.006</td> <td> 2469.654</td> <td> 1.46e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2176.0</th>      <td> 4.917e+04</td> <td> 3655.506</td> <td>   13.450</td> <td> 0.000</td> <td>  4.2e+04</td> <td> 5.63e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2188.0</th>      <td> 1.064e+04</td> <td> 3272.692</td> <td>    3.252</td> <td> 0.001</td> <td> 4229.171</td> <td> 1.71e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2189.0</th>      <td> 1987.7047</td> <td> 3044.824</td> <td>    0.653</td> <td> 0.514</td> <td>-3980.612</td> <td> 7956.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2220.0</th>      <td> 8121.7655</td> <td> 3066.803</td> <td>    2.648</td> <td> 0.008</td> <td> 2110.366</td> <td> 1.41e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>22205.0</th>     <td> 1.097e+04</td> <td> 3742.158</td> <td>    2.932</td> <td> 0.003</td> <td> 3635.194</td> <td> 1.83e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2226.0</th>      <td> 6564.1694</td> <td> 6056.783</td> <td>    1.084</td> <td> 0.278</td> <td>-5308.045</td> <td> 1.84e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2230.0</th>      <td> 9663.4059</td> <td> 3448.942</td> <td>    2.802</td> <td> 0.005</td> <td> 2902.955</td> <td> 1.64e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>22325.0</th>     <td> 2036.3731</td> <td> 3623.720</td> <td>    0.562</td> <td> 0.574</td> <td>-5066.669</td> <td> 9139.415</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2255.0</th>      <td> 7276.8607</td> <td> 3077.041</td> <td>    2.365</td> <td> 0.018</td> <td> 1245.393</td> <td> 1.33e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>22619.0</th>     <td> 9459.5788</td> <td> 3864.126</td> <td>    2.448</td> <td> 0.014</td> <td> 1885.306</td> <td>  1.7e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2267.0</th>      <td> 1604.9439</td> <td> 3063.270</td> <td>    0.524</td> <td> 0.600</td> <td>-4399.530</td> <td> 7609.418</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>22815.0</th>     <td> 4875.5667</td> <td> 3570.634</td> <td>    1.365</td> <td> 0.172</td> <td>-2123.419</td> <td> 1.19e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2285.0</th>      <td>-2.061e+04</td> <td> 3176.312</td> <td>   -6.490</td> <td> 0.000</td> <td>-2.68e+04</td> <td>-1.44e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2290.0</th>      <td> 4219.0616</td> <td> 3064.579</td> <td>    1.377</td> <td> 0.169</td> <td>-1787.979</td> <td> 1.02e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2295.0</th>      <td>  1.02e+04</td> <td> 4631.605</td> <td>    2.202</td> <td> 0.028</td> <td> 1118.124</td> <td> 1.93e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2316.0</th>      <td> 3932.7481</td> <td> 3268.816</td> <td>    1.203</td> <td> 0.229</td> <td>-2474.628</td> <td> 1.03e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>23220.0</th>     <td> 7708.2043</td> <td> 3613.811</td> <td>    2.133</td> <td> 0.033</td> <td>  624.587</td> <td> 1.48e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>23224.0</th>     <td>-1416.5488</td> <td> 3999.474</td> <td>   -0.354</td> <td> 0.723</td> <td>-9256.124</td> <td> 6423.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2343.0</th>      <td>  371.2913</td> <td> 5445.150</td> <td>    0.068</td> <td> 0.946</td> <td>-1.03e+04</td> <td>  1.1e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2352.0</th>      <td> 7033.5174</td> <td> 3195.255</td> <td>    2.201</td> <td> 0.028</td> <td>  770.332</td> <td> 1.33e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>23700.0</th>     <td>-4104.2067</td> <td> 4540.832</td> <td>   -0.904</td> <td> 0.366</td> <td> -1.3e+04</td> <td> 4796.514</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2390.0</th>      <td> 1.022e+04</td> <td> 3146.886</td> <td>    3.249</td> <td> 0.001</td> <td> 4054.843</td> <td> 1.64e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2393.0</th>      <td> 5256.7276</td> <td> 3021.333</td> <td>    1.740</td> <td> 0.082</td> <td> -665.543</td> <td> 1.12e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2403.0</th>      <td> 1.544e+04</td> <td> 3116.842</td> <td>    4.954</td> <td> 0.000</td> <td> 9331.361</td> <td> 2.16e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2435.0</th>      <td> 1.204e+04</td> <td> 3215.430</td> <td>    3.744</td> <td> 0.000</td> <td> 5734.523</td> <td> 1.83e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2444.0</th>      <td> 5543.3070</td> <td> 3031.522</td> <td>    1.829</td> <td> 0.067</td> <td> -398.936</td> <td> 1.15e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2448.0</th>      <td> 7626.0071</td> <td> 3053.285</td> <td>    2.498</td> <td> 0.013</td> <td> 1641.104</td> <td> 1.36e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2469.0</th>      <td> 9427.6259</td> <td> 4407.154</td> <td>    2.139</td> <td> 0.032</td> <td>  788.935</td> <td> 1.81e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>24720.0</th>     <td> 8470.8001</td> <td> 3726.615</td> <td>    2.273</td> <td> 0.023</td> <td> 1166.069</td> <td> 1.58e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>24800.0</th>     <td> 2679.9470</td> <td> 3896.093</td> <td>    0.688</td> <td> 0.492</td> <td>-4956.987</td> <td> 1.03e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2482.0</th>      <td> 1.036e+04</td> <td> 3154.774</td> <td>    3.283</td> <td> 0.001</td> <td> 4172.094</td> <td> 1.65e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>24969.0</th>     <td>  1.01e+04</td> <td> 4399.409</td> <td>    2.296</td> <td> 0.022</td> <td> 1476.724</td> <td> 1.87e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2498.0</th>      <td> 2822.1067</td> <td> 3205.564</td> <td>    0.880</td> <td> 0.379</td> <td>-3461.286</td> <td> 9105.499</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2504.0</th>      <td>-5740.6155</td> <td> 3125.446</td> <td>   -1.837</td> <td> 0.066</td> <td>-1.19e+04</td> <td>  385.734</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2508.0</th>      <td> 9551.1213</td> <td> 3313.820</td> <td>    2.882</td> <td> 0.004</td> <td> 3055.530</td> <td>  1.6e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>25124.0</th>     <td> 8839.2099</td> <td> 3850.901</td> <td>    2.295</td> <td> 0.022</td> <td> 1290.860</td> <td> 1.64e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2518.0</th>      <td> 9462.2606</td> <td> 3118.179</td> <td>    3.035</td> <td> 0.002</td> <td> 3350.156</td> <td> 1.56e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>25224.0</th>     <td> 9181.2871</td> <td> 7262.529</td> <td>    1.264</td> <td> 0.206</td> <td>-5054.373</td> <td> 2.34e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>25279.0</th>     <td> 8309.3827</td> <td> 3823.370</td> <td>    2.173</td> <td> 0.030</td> <td>  814.996</td> <td> 1.58e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2537.0</th>      <td>-1331.6614</td> <td> 3141.364</td> <td>   -0.424</td> <td> 0.672</td> <td>-7489.212</td> <td> 4825.889</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2538.0</th>      <td> 1.059e+04</td> <td> 4051.182</td> <td>    2.615</td> <td> 0.009</td> <td> 2653.302</td> <td> 1.85e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>25389.0</th>     <td> 1.016e+04</td> <td> 6108.961</td> <td>    1.663</td> <td> 0.096</td> <td>-1815.943</td> <td> 2.21e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2547.0</th>      <td> 1402.5130</td> <td> 3210.761</td> <td>    0.437</td> <td> 0.662</td> <td>-4891.066</td> <td> 7696.092</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2553.0</th>      <td> 9104.4999</td> <td> 3154.705</td> <td>    2.886</td> <td> 0.004</td> <td> 2920.799</td> <td> 1.53e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2574.0</th>      <td> 2817.6652</td> <td> 3621.446</td> <td>    0.778</td> <td> 0.437</td> <td>-4280.919</td> <td> 9916.249</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>25747.0</th>     <td> 8887.4249</td> <td> 3853.652</td> <td>    2.306</td> <td> 0.021</td> <td> 1333.682</td> <td> 1.64e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2577.0</th>      <td> 7333.8930</td> <td> 3033.785</td> <td>    2.417</td> <td> 0.016</td> <td> 1387.213</td> <td> 1.33e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2593.0</th>      <td> 7608.5207</td> <td> 3056.291</td> <td>    2.489</td> <td> 0.013</td> <td> 1617.727</td> <td> 1.36e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2596.0</th>      <td> 7104.2843</td> <td> 3165.531</td> <td>    2.244</td> <td> 0.025</td> <td>  899.363</td> <td> 1.33e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2663.0</th>      <td> 1.201e+04</td> <td> 3109.709</td> <td>    3.862</td> <td> 0.000</td> <td> 5914.315</td> <td> 1.81e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2771.0</th>      <td> 7170.4426</td> <td> 3157.640</td> <td>    2.271</td> <td> 0.023</td> <td>  980.989</td> <td> 1.34e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2787.0</th>      <td> 8843.2302</td> <td> 3108.248</td> <td>    2.845</td> <td> 0.004</td> <td> 2750.591</td> <td> 1.49e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2797.0</th>      <td>-1136.7600</td> <td> 3047.444</td> <td>   -0.373</td> <td> 0.709</td> <td>-7110.213</td> <td> 4836.693</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2802.0</th>      <td> 9981.2391</td> <td> 3145.382</td> <td>    3.173</td> <td> 0.002</td> <td> 3815.813</td> <td> 1.61e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2817.0</th>      <td>-2423.3733</td> <td> 3105.183</td> <td>   -0.780</td> <td> 0.435</td> <td>-8510.003</td> <td> 3663.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>28678.0</th>     <td>-6800.8821</td> <td> 3938.721</td> <td>   -1.727</td> <td> 0.084</td> <td>-1.45e+04</td> <td>  919.610</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>28701.0</th>     <td> 7289.6069</td> <td> 3122.789</td> <td>    2.334</td> <td> 0.020</td> <td> 1168.466</td> <td> 1.34e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>28742.0</th>     <td>-4379.2282</td> <td> 4023.812</td> <td>   -1.088</td> <td> 0.276</td> <td>-1.23e+04</td> <td> 3508.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2888.0</th>      <td> 8333.3928</td> <td> 3213.797</td> <td>    2.593</td> <td> 0.010</td> <td> 2033.862</td> <td> 1.46e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2897.0</th>      <td> 9522.3975</td> <td> 3838.939</td> <td>    2.480</td> <td> 0.013</td> <td> 1997.494</td> <td>  1.7e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2917.0</th>      <td> 4179.7509</td> <td> 3174.337</td> <td>    1.317</td> <td> 0.188</td> <td>-2042.431</td> <td> 1.04e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>29392.0</th>     <td>-4484.0845</td> <td> 3895.740</td> <td>   -1.151</td> <td> 0.250</td> <td>-1.21e+04</td> <td> 3152.158</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2950.0</th>      <td>-8939.5631</td> <td> 4197.529</td> <td>   -2.130</td> <td> 0.033</td> <td>-1.72e+04</td> <td> -711.769</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2951.0</th>      <td> 1.053e+04</td> <td> 3554.152</td> <td>    2.964</td> <td> 0.003</td> <td> 3567.561</td> <td> 1.75e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2953.0</th>      <td> 8670.7332</td> <td> 3081.692</td> <td>    2.814</td> <td> 0.005</td> <td> 2630.148</td> <td> 1.47e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2960.0</th>      <td> 6927.1661</td> <td> 3807.516</td> <td>    1.819</td> <td> 0.069</td> <td> -536.143</td> <td> 1.44e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2975.0</th>      <td> 4129.9550</td> <td> 3074.147</td> <td>    1.343</td> <td> 0.179</td> <td>-1895.841</td> <td> 1.02e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2982.0</th>      <td> 8607.4496</td> <td> 3114.061</td> <td>    2.764</td> <td> 0.006</td> <td> 2503.416</td> <td> 1.47e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2991.0</th>      <td>-2091.3592</td> <td> 3611.129</td> <td>   -0.579</td> <td> 0.563</td> <td>-9169.721</td> <td> 4987.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3011.0</th>      <td>  352.0291</td> <td> 3228.393</td> <td>    0.109</td> <td> 0.913</td> <td>-5976.112</td> <td> 6680.170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3015.0</th>      <td> 1.066e+04</td> <td> 3189.868</td> <td>    3.341</td> <td> 0.001</td> <td> 4404.847</td> <td> 1.69e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3026.0</th>      <td> 8297.5216</td> <td> 3114.849</td> <td>    2.664</td> <td> 0.008</td> <td> 2191.944</td> <td> 1.44e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3031.0</th>      <td>-7156.8279</td> <td> 3963.813</td> <td>   -1.806</td> <td> 0.071</td> <td>-1.49e+04</td> <td>  612.847</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3062.0</th>      <td> 1.013e+04</td> <td> 3216.055</td> <td>    3.150</td> <td> 0.002</td> <td> 3827.484</td> <td> 1.64e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3093.0</th>      <td> 4614.1396</td> <td> 3380.925</td> <td>    1.365</td> <td> 0.172</td> <td>-2012.986</td> <td> 1.12e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3107.0</th>      <td> 8261.4341</td> <td> 4593.460</td> <td>    1.799</td> <td> 0.072</td> <td> -742.444</td> <td> 1.73e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3121.0</th>      <td> 1.075e+04</td> <td> 3100.529</td> <td>    3.467</td> <td> 0.001</td> <td> 4670.905</td> <td> 1.68e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3126.0</th>      <td> 8639.8575</td> <td> 3074.886</td> <td>    2.810</td> <td> 0.005</td> <td> 2612.613</td> <td> 1.47e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3144.0</th>      <td> 6.167e+04</td> <td> 3143.112</td> <td>   19.622</td> <td> 0.000</td> <td> 5.55e+04</td> <td> 6.78e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3156.0</th>      <td> 9057.0292</td> <td> 3556.046</td> <td>    2.547</td> <td> 0.011</td> <td> 2086.640</td> <td>  1.6e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3157.0</th>      <td> 8487.6305</td> <td> 3086.887</td> <td>    2.750</td> <td> 0.006</td> <td> 2436.864</td> <td> 1.45e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3170.0</th>      <td> 1.112e+04</td> <td> 3070.843</td> <td>    3.621</td> <td> 0.000</td> <td> 5098.953</td> <td> 1.71e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3178.0</th>      <td> 4719.2301</td> <td> 3279.399</td> <td>    1.439</td> <td> 0.150</td> <td>-1708.889</td> <td> 1.11e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3206.0</th>      <td> 5242.4391</td> <td> 3326.387</td> <td>    1.576</td> <td> 0.115</td> <td>-1277.785</td> <td> 1.18e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3229.0</th>      <td> 6940.2745</td> <td> 3201.204</td> <td>    2.168</td> <td> 0.030</td> <td>  665.428</td> <td> 1.32e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3235.0</th>      <td> 8557.6434</td> <td> 3259.016</td> <td>    2.626</td> <td> 0.009</td> <td> 2169.477</td> <td> 1.49e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3246.0</th>      <td> 8959.3648</td> <td> 3141.052</td> <td>    2.852</td> <td> 0.004</td> <td> 2802.426</td> <td> 1.51e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3248.0</th>      <td> 8795.1454</td> <td> 3144.903</td> <td>    2.797</td> <td> 0.005</td> <td> 2630.657</td> <td>  1.5e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3282.0</th>      <td>-1.882e+04</td> <td> 3179.239</td> <td>   -5.919</td> <td> 0.000</td> <td> -2.5e+04</td> <td>-1.26e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3362.0</th>      <td> 1467.2473</td> <td> 3430.530</td> <td>    0.428</td> <td> 0.669</td> <td>-5257.112</td> <td> 8191.606</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3372.0</th>      <td> 8967.9006</td> <td> 3615.991</td> <td>    2.480</td> <td> 0.013</td> <td> 1880.009</td> <td> 1.61e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3422.0</th>      <td> 8150.3780</td> <td> 3116.503</td> <td>    2.615</td> <td> 0.009</td> <td> 2041.559</td> <td> 1.43e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3497.0</th>      <td> 3305.8909</td> <td> 3020.187</td> <td>    1.095</td> <td> 0.274</td> <td>-2614.134</td> <td> 9225.916</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3502.0</th>      <td> 4413.0364</td> <td> 3019.260</td> <td>    1.462</td> <td> 0.144</td> <td>-1505.172</td> <td> 1.03e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3504.0</th>      <td> 7330.3624</td> <td> 3693.007</td> <td>    1.985</td> <td> 0.047</td> <td>   91.508</td> <td> 1.46e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3505.0</th>      <td> 6509.4875</td> <td> 3039.592</td> <td>    2.142</td> <td> 0.032</td> <td>  551.425</td> <td> 1.25e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3532.0</th>      <td> 9367.0102</td> <td> 3036.064</td> <td>    3.085</td> <td> 0.002</td> <td> 3415.864</td> <td> 1.53e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3574.0</th>      <td> 9567.2283</td> <td> 4941.074</td> <td>    1.936</td> <td> 0.053</td> <td> -118.027</td> <td> 1.93e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3580.0</th>      <td> 5668.8773</td> <td> 3023.668</td> <td>    1.875</td> <td> 0.061</td> <td> -257.971</td> <td> 1.16e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3612.0</th>      <td> 1.077e+04</td> <td> 3190.707</td> <td>    3.376</td> <td> 0.001</td> <td> 4518.562</td> <td>  1.7e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3619.0</th>      <td> 7583.6331</td> <td> 3125.470</td> <td>    2.426</td> <td> 0.015</td> <td> 1457.238</td> <td> 1.37e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3622.0</th>      <td> 1.024e+04</td> <td> 3247.561</td> <td>    3.154</td> <td> 0.002</td> <td> 3877.236</td> <td> 1.66e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3639.0</th>      <td>  701.7362</td> <td> 2978.785</td> <td>    0.236</td> <td> 0.814</td> <td>-5137.134</td> <td> 6540.606</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3650.0</th>      <td>  -56.5141</td> <td> 3013.203</td> <td>   -0.019</td> <td> 0.985</td> <td>-5962.849</td> <td> 5849.821</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3662.0</th>      <td> 6515.3615</td> <td> 3036.473</td> <td>    2.146</td> <td> 0.032</td> <td>  563.413</td> <td> 1.25e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3734.0</th>      <td>-4540.5498</td> <td> 3009.478</td> <td>   -1.509</td> <td> 0.131</td> <td>-1.04e+04</td> <td> 1358.485</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3735.0</th>      <td> 5998.0243</td> <td> 3363.381</td> <td>    1.783</td> <td> 0.075</td> <td> -594.714</td> <td> 1.26e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3761.0</th>      <td> 4676.2483</td> <td> 3019.021</td> <td>    1.549</td> <td> 0.121</td> <td>-1241.491</td> <td> 1.06e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3779.0</th>      <td>-1115.3957</td> <td> 3351.604</td> <td>   -0.333</td> <td> 0.739</td> <td>-7685.049</td> <td> 5454.258</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3781.0</th>      <td> 3388.6729</td> <td> 3657.813</td> <td>    0.926</td> <td> 0.354</td> <td>-3781.196</td> <td> 1.06e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3782.0</th>      <td> -945.5519</td> <td> 3097.134</td> <td>   -0.305</td> <td> 0.760</td> <td>-7016.405</td> <td> 5125.302</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3786.0</th>      <td> 8059.2754</td> <td> 3095.380</td> <td>    2.604</td> <td> 0.009</td> <td> 1991.860</td> <td> 1.41e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3796.0</th>      <td>-1921.4741</td> <td> 3437.318</td> <td>   -0.559</td> <td> 0.576</td> <td>-8659.140</td> <td> 4816.192</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3821.0</th>      <td> 9374.5415</td> <td> 3182.442</td> <td>    2.946</td> <td> 0.003</td> <td> 3136.471</td> <td> 1.56e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3835.0</th>      <td> 1623.3259</td> <td> 3068.940</td> <td>    0.529</td> <td> 0.597</td> <td>-4392.263</td> <td> 7638.914</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3839.0</th>      <td> 5038.7123</td> <td> 3787.676</td> <td>    1.330</td> <td> 0.183</td> <td>-2385.707</td> <td> 1.25e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3840.0</th>      <td> 3096.0560</td> <td> 3106.065</td> <td>    0.997</td> <td> 0.319</td> <td>-2992.302</td> <td> 9184.414</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3895.0</th>      <td> 9436.3688</td> <td> 3115.660</td> <td>    3.029</td> <td> 0.002</td> <td> 3329.202</td> <td> 1.55e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3908.0</th>      <td> 6499.5003</td> <td> 4150.425</td> <td>    1.566</td> <td> 0.117</td> <td>-1635.964</td> <td> 1.46e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3911.0</th>      <td> 3978.4256</td> <td> 3062.447</td> <td>    1.299</td> <td> 0.194</td> <td>-2024.435</td> <td> 9981.286</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3917.0</th>      <td> 9644.8467</td> <td> 3201.184</td> <td>    3.013</td> <td> 0.003</td> <td> 3370.040</td> <td> 1.59e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3946.0</th>      <td>  1.02e+04</td> <td> 3163.781</td> <td>    3.224</td> <td> 0.001</td> <td> 3997.651</td> <td> 1.64e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3971.0</th>      <td> 8857.9912</td> <td> 3190.900</td> <td>    2.776</td> <td> 0.006</td> <td> 2603.342</td> <td> 1.51e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3980.0</th>      <td> 1.889e+04</td> <td> 3114.804</td> <td>    6.066</td> <td> 0.000</td> <td> 1.28e+04</td> <td>  2.5e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4034.0</th>      <td> 5433.4828</td> <td> 3023.927</td> <td>    1.797</td> <td> 0.072</td> <td> -493.873</td> <td> 1.14e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4036.0</th>      <td> 1.006e+04</td> <td> 3132.064</td> <td>    3.210</td> <td> 0.001</td> <td> 3915.798</td> <td> 1.62e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4040.0</th>      <td> 4402.5134</td> <td> 3085.061</td> <td>    1.427</td> <td> 0.154</td> <td>-1644.674</td> <td> 1.04e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4058.0</th>      <td> 8496.1476</td> <td> 3074.049</td> <td>    2.764</td> <td> 0.006</td> <td> 2470.545</td> <td> 1.45e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4060.0</th>      <td>-8502.7681</td> <td> 3085.688</td> <td>   -2.756</td> <td> 0.006</td> <td>-1.46e+04</td> <td>-2454.351</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4062.0</th>      <td> 1.245e+04</td> <td> 3186.197</td> <td>    3.906</td> <td> 0.000</td> <td> 6200.250</td> <td> 1.87e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4077.0</th>      <td> 8049.1131</td> <td> 4325.812</td> <td>    1.861</td> <td> 0.063</td> <td> -430.135</td> <td> 1.65e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4087.0</th>      <td>-1.922e+04</td> <td> 3417.870</td> <td>   -5.622</td> <td> 0.000</td> <td>-2.59e+04</td> <td>-1.25e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4091.0</th>      <td> 7764.4934</td> <td> 3536.914</td> <td>    2.195</td> <td> 0.028</td> <td>  831.604</td> <td> 1.47e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4127.0</th>      <td> 3991.2384</td> <td> 2983.946</td> <td>    1.338</td> <td> 0.181</td> <td>-1857.749</td> <td> 9840.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4138.0</th>      <td> 1.012e+04</td> <td> 3751.511</td> <td>    2.696</td> <td> 0.007</td> <td> 2761.757</td> <td> 1.75e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4162.0</th>      <td> 8848.7229</td> <td> 3711.438</td> <td>    2.384</td> <td> 0.017</td> <td> 1573.741</td> <td> 1.61e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4186.0</th>      <td> 1.029e+04</td> <td> 3147.338</td> <td>    3.271</td> <td> 0.001</td> <td> 4124.177</td> <td> 1.65e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4194.0</th>      <td> -206.5396</td> <td> 3254.206</td> <td>   -0.063</td> <td> 0.949</td> <td>-6585.277</td> <td> 6172.197</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4199.0</th>      <td>-3080.7950</td> <td> 2986.731</td> <td>   -1.031</td> <td> 0.302</td> <td>-8935.242</td> <td> 2773.652</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4213.0</th>      <td> 9040.9619</td> <td> 3063.929</td> <td>    2.951</td> <td> 0.003</td> <td> 3035.197</td> <td>  1.5e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4222.0</th>      <td> -427.7763</td> <td> 3036.691</td> <td>   -0.141</td> <td> 0.888</td> <td>-6380.151</td> <td> 5524.598</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4223.0</th>      <td> 8795.2266</td> <td> 3075.179</td> <td>    2.860</td> <td> 0.004</td> <td> 2767.409</td> <td> 1.48e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4251.0</th>      <td> 9920.6121</td> <td> 3135.291</td> <td>    3.164</td> <td> 0.002</td> <td> 3774.966</td> <td> 1.61e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4265.0</th>      <td> 8311.0668</td> <td> 3331.549</td> <td>    2.495</td> <td> 0.013</td> <td> 1780.724</td> <td> 1.48e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4274.0</th>      <td> 7457.4585</td> <td> 3194.105</td> <td>    2.335</td> <td> 0.020</td> <td> 1196.528</td> <td> 1.37e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4321.0</th>      <td> 5939.8774</td> <td> 3058.043</td> <td>    1.942</td> <td> 0.052</td> <td>  -54.352</td> <td> 1.19e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4335.0</th>      <td> 7276.7703</td> <td> 4582.157</td> <td>    1.588</td> <td> 0.112</td> <td>-1704.953</td> <td> 1.63e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4340.0</th>      <td> 6243.3898</td> <td> 3049.262</td> <td>    2.048</td> <td> 0.041</td> <td>  266.372</td> <td> 1.22e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4371.0</th>      <td> 6746.0318</td> <td> 3081.412</td> <td>    2.189</td> <td> 0.029</td> <td>  705.997</td> <td> 1.28e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4415.0</th>      <td> 9237.0407</td> <td> 3230.539</td> <td>    2.859</td> <td> 0.004</td> <td> 2904.693</td> <td> 1.56e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4450.0</th>      <td> 7979.6767</td> <td> 3101.329</td> <td>    2.573</td> <td> 0.010</td> <td> 1900.602</td> <td> 1.41e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4476.0</th>      <td>  675.3081</td> <td> 3174.296</td> <td>    0.213</td> <td> 0.832</td> <td>-5546.793</td> <td> 6897.409</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4510.0</th>      <td> 2475.6995</td> <td> 3026.171</td> <td>    0.818</td> <td> 0.413</td> <td>-3456.054</td> <td> 8407.453</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4520.0</th>      <td> 7980.2863</td> <td> 3051.589</td> <td>    2.615</td> <td> 0.009</td> <td> 1998.708</td> <td>  1.4e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4551.0</th>      <td> 8011.4429</td> <td> 7270.601</td> <td>    1.102</td> <td> 0.271</td> <td>-6240.039</td> <td> 2.23e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4568.0</th>      <td> 8842.8576</td> <td> 3229.403</td> <td>    2.738</td> <td> 0.006</td> <td> 2512.738</td> <td> 1.52e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4579.0</th>      <td> 1.065e+04</td> <td> 3189.762</td> <td>    3.338</td> <td> 0.001</td> <td> 4393.423</td> <td> 1.69e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4585.0</th>      <td> 1.003e+04</td> <td> 3206.938</td> <td>    3.129</td> <td> 0.002</td> <td> 3747.041</td> <td> 1.63e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4595.0</th>      <td> 6865.7401</td> <td> 3039.451</td> <td>    2.259</td> <td> 0.024</td> <td>  907.954</td> <td> 1.28e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4600.0</th>      <td> 1012.0246</td> <td> 3200.037</td> <td>    0.316</td> <td> 0.752</td> <td>-5260.535</td> <td> 7284.584</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4607.0</th>      <td> 9896.4315</td> <td> 3136.909</td> <td>    3.155</td> <td> 0.002</td> <td> 3747.613</td> <td>  1.6e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4608.0</th>      <td> 1926.7708</td> <td> 3084.280</td> <td>    0.625</td> <td> 0.532</td> <td>-4118.886</td> <td> 7972.428</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4622.0</th>      <td> 5050.9157</td> <td> 3012.296</td> <td>    1.677</td> <td> 0.094</td> <td> -853.642</td> <td>  1.1e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4623.0</th>      <td> 9205.2343</td> <td> 3264.415</td> <td>    2.820</td> <td> 0.005</td> <td> 2806.486</td> <td> 1.56e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4768.0</th>      <td> 8149.0733</td> <td> 3123.950</td> <td>    2.609</td> <td> 0.009</td> <td> 2025.657</td> <td> 1.43e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4771.0</th>      <td>  1.02e+04</td> <td> 3154.399</td> <td>    3.233</td> <td> 0.001</td> <td> 4014.036</td> <td> 1.64e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4800.0</th>      <td> 8510.9355</td> <td> 3222.793</td> <td>    2.641</td> <td> 0.008</td> <td> 2193.771</td> <td> 1.48e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4802.0</th>      <td> 9756.0632</td> <td> 3122.659</td> <td>    3.124</td> <td> 0.002</td> <td> 3635.177</td> <td> 1.59e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4807.0</th>      <td> 9311.2841</td> <td> 3209.003</td> <td>    2.902</td> <td> 0.004</td> <td> 3021.150</td> <td> 1.56e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4839.0</th>      <td> -1.39e+05</td> <td> 4400.348</td> <td>  -31.598</td> <td> 0.000</td> <td>-1.48e+05</td> <td> -1.3e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4843.0</th>      <td> -155.0920</td> <td> 3300.774</td> <td>   -0.047</td> <td> 0.963</td> <td>-6625.111</td> <td> 6314.927</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4881.0</th>      <td> 7349.9526</td> <td> 3033.927</td> <td>    2.423</td> <td> 0.015</td> <td> 1402.995</td> <td> 1.33e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4900.0</th>      <td> 8056.7145</td> <td> 3130.004</td> <td>    2.574</td> <td> 0.010</td> <td> 1921.431</td> <td> 1.42e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4926.0</th>      <td> 6951.4250</td> <td> 3036.486</td> <td>    2.289</td> <td> 0.022</td> <td>  999.451</td> <td> 1.29e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4941.0</th>      <td> 7701.0234</td> <td> 3119.428</td> <td>    2.469</td> <td> 0.014</td> <td> 1586.472</td> <td> 1.38e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4961.0</th>      <td>-6713.3878</td> <td> 3845.668</td> <td>   -1.746</td> <td> 0.081</td> <td>-1.43e+04</td> <td>  824.706</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4988.0</th>      <td> 1.555e+04</td> <td> 3152.418</td> <td>    4.932</td> <td> 0.000</td> <td> 9368.460</td> <td> 2.17e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4993.0</th>      <td> 1.078e+04</td> <td> 3191.719</td> <td>    3.379</td> <td> 0.001</td> <td> 4527.925</td> <td>  1.7e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5018.0</th>      <td> 2756.6116</td> <td> 3051.145</td> <td>    0.903</td> <td> 0.366</td> <td>-3224.095</td> <td> 8737.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5020.0</th>      <td> 1703.6436</td> <td> 3206.794</td> <td>    0.531</td> <td> 0.595</td> <td>-4582.160</td> <td> 7989.448</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5027.0</th>      <td> 5583.6057</td> <td> 3073.165</td> <td>    1.817</td> <td> 0.069</td> <td> -440.265</td> <td> 1.16e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5032.0</th>      <td> 8848.7731</td> <td> 3093.419</td> <td>    2.861</td> <td> 0.004</td> <td> 2785.202</td> <td> 1.49e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5043.0</th>      <td> 5765.7251</td> <td> 3056.378</td> <td>    1.886</td> <td> 0.059</td> <td> -225.240</td> <td> 1.18e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5046.0</th>      <td>-3742.7011</td> <td> 3008.827</td> <td>   -1.244</td> <td> 0.214</td> <td>-9640.459</td> <td> 2155.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5047.0</th>      <td> 4.951e+04</td> <td> 3945.666</td> <td>   12.549</td> <td> 0.000</td> <td> 4.18e+04</td> <td> 5.72e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5065.0</th>      <td> 9943.6682</td> <td> 3565.116</td> <td>    2.789</td> <td> 0.005</td> <td> 2955.499</td> <td> 1.69e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5071.0</th>      <td> 8402.8199</td> <td> 3506.244</td> <td>    2.397</td> <td> 0.017</td> <td> 1530.049</td> <td> 1.53e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5073.0</th>      <td> -2.03e+05</td> <td> 6327.061</td> <td>  -32.087</td> <td> 0.000</td> <td>-2.15e+05</td> <td>-1.91e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5087.0</th>      <td> 4808.3060</td> <td> 3031.181</td> <td>    1.586</td> <td> 0.113</td> <td>-1133.268</td> <td> 1.07e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5109.0</th>      <td>     1e+04</td> <td> 3156.702</td> <td>    3.169</td> <td> 0.002</td> <td> 3815.966</td> <td> 1.62e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5116.0</th>      <td>  331.7479</td> <td> 3230.260</td> <td>    0.103</td> <td> 0.918</td> <td>-6000.052</td> <td> 6663.548</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5122.0</th>      <td> 5093.7234</td> <td> 3033.485</td> <td>    1.679</td> <td> 0.093</td> <td> -852.368</td> <td>  1.1e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5134.0</th>      <td> 1619.9886</td> <td> 3164.783</td> <td>    0.512</td> <td> 0.609</td> <td>-4583.467</td> <td> 7823.444</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5142.0</th>      <td> 6629.5952</td> <td> 3817.878</td> <td>    1.736</td> <td> 0.083</td> <td> -854.026</td> <td> 1.41e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5165.0</th>      <td> 7201.9002</td> <td> 3418.120</td> <td>    2.107</td> <td> 0.035</td> <td>  501.866</td> <td> 1.39e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5169.0</th>      <td> 1.921e+04</td> <td> 3111.749</td> <td>    6.173</td> <td> 0.000</td> <td> 1.31e+04</td> <td> 2.53e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5174.0</th>      <td> 6861.1596</td> <td> 3315.866</td> <td>    2.069</td> <td> 0.039</td> <td>  361.558</td> <td> 1.34e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5179.0</th>      <td> 9522.8653</td> <td> 3123.992</td> <td>    3.048</td> <td> 0.002</td> <td> 3399.366</td> <td> 1.56e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5181.0</th>      <td> 1.022e+04</td> <td> 3247.843</td> <td>    3.148</td> <td> 0.002</td> <td> 3857.092</td> <td> 1.66e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5187.0</th>      <td> 1.051e+04</td> <td> 3595.928</td> <td>    2.924</td> <td> 0.003</td> <td> 3466.116</td> <td> 1.76e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5229.0</th>      <td> 1832.7007</td> <td> 2976.839</td> <td>    0.616</td> <td> 0.538</td> <td>-4002.356</td> <td> 7667.757</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5234.0</th>      <td>-5223.8465</td> <td> 3133.458</td> <td>   -1.667</td> <td> 0.096</td> <td>-1.14e+04</td> <td>  918.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5237.0</th>      <td> 9043.0280</td> <td> 3101.586</td> <td>    2.916</td> <td> 0.004</td> <td> 2963.448</td> <td> 1.51e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5252.0</th>      <td> 8212.2020</td> <td> 3060.018</td> <td>    2.684</td> <td> 0.007</td> <td> 2214.102</td> <td> 1.42e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5254.0</th>      <td> 8446.7502</td> <td> 3097.320</td> <td>    2.727</td> <td> 0.006</td> <td> 2375.532</td> <td> 1.45e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5306.0</th>      <td> 6465.5650</td> <td> 3027.709</td> <td>    2.135</td> <td> 0.033</td> <td>  530.795</td> <td> 1.24e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5338.0</th>      <td> 9319.2221</td> <td> 3098.305</td> <td>    3.008</td> <td> 0.003</td> <td> 3246.074</td> <td> 1.54e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5377.0</th>      <td> 1.009e+04</td> <td> 3165.731</td> <td>    3.188</td> <td> 0.001</td> <td> 3885.677</td> <td> 1.63e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5439.0</th>      <td> 7334.3884</td> <td> 3132.147</td> <td>    2.342</td> <td> 0.019</td> <td> 1194.905</td> <td> 1.35e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5456.0</th>      <td> 1.067e+04</td> <td> 3219.404</td> <td>    3.313</td> <td> 0.001</td> <td> 4356.183</td> <td>  1.7e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5464.0</th>      <td> 8046.9137</td> <td> 3717.507</td> <td>    2.165</td> <td> 0.030</td> <td>  760.036</td> <td> 1.53e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5476.0</th>      <td> 1.038e+04</td> <td> 3188.810</td> <td>    3.254</td> <td> 0.001</td> <td> 4125.428</td> <td> 1.66e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5492.0</th>      <td>-7692.0384</td> <td> 3028.409</td> <td>   -2.540</td> <td> 0.011</td> <td>-1.36e+04</td> <td>-1755.897</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5496.0</th>      <td> 8328.8408</td> <td> 3078.327</td> <td>    2.706</td> <td> 0.007</td> <td> 2294.852</td> <td> 1.44e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5505.0</th>      <td> 9584.8474</td> <td> 3145.488</td> <td>    3.047</td> <td> 0.002</td> <td> 3419.213</td> <td> 1.58e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5518.0</th>      <td> 8040.5569</td> <td> 3394.234</td> <td>    2.369</td> <td> 0.018</td> <td> 1387.343</td> <td> 1.47e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5520.0</th>      <td> 7141.4059</td> <td> 3085.889</td> <td>    2.314</td> <td> 0.021</td> <td> 1092.595</td> <td> 1.32e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5545.0</th>      <td> 9850.2695</td> <td> 3257.198</td> <td>    3.024</td> <td> 0.002</td> <td> 3465.667</td> <td> 1.62e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5568.0</th>      <td>   1.2e+04</td> <td> 3131.140</td> <td>    3.834</td> <td> 0.000</td> <td> 5866.525</td> <td> 1.81e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5569.0</th>      <td> 1.006e+04</td> <td> 3173.656</td> <td>    3.171</td> <td> 0.002</td> <td> 3841.616</td> <td> 1.63e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5578.0</th>      <td> 9572.4372</td> <td> 3115.964</td> <td>    3.072</td> <td> 0.002</td> <td> 3464.675</td> <td> 1.57e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5581.0</th>      <td> 9414.8809</td> <td> 3097.341</td> <td>    3.040</td> <td> 0.002</td> <td> 3343.622</td> <td> 1.55e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5589.0</th>      <td> 2400.9953</td> <td> 2973.079</td> <td>    0.808</td> <td> 0.419</td> <td>-3426.690</td> <td> 8228.681</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5597.0</th>      <td>  1.13e+04</td> <td> 3648.090</td> <td>    3.097</td> <td> 0.002</td> <td> 4145.936</td> <td> 1.84e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5606.0</th>      <td>-2.745e+04</td> <td> 3152.384</td> <td>   -8.709</td> <td> 0.000</td> <td>-3.36e+04</td> <td>-2.13e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5639.0</th>      <td> 1.082e+04</td> <td> 3159.665</td> <td>    3.425</td> <td> 0.001</td> <td> 4628.029</td> <td>  1.7e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5667.0</th>      <td> 7446.7098</td> <td> 3218.672</td> <td>    2.314</td> <td> 0.021</td> <td> 1137.624</td> <td> 1.38e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5690.0</th>      <td> 9706.2182</td> <td> 3117.215</td> <td>    3.114</td> <td> 0.002</td> <td> 3596.004</td> <td> 1.58e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5709.0</th>      <td> 9020.8914</td> <td> 3130.883</td> <td>    2.881</td> <td> 0.004</td> <td> 2883.886</td> <td> 1.52e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5726.0</th>      <td> 9123.8740</td> <td> 3144.647</td> <td>    2.901</td> <td> 0.004</td> <td> 2959.887</td> <td> 1.53e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5764.0</th>      <td> 7723.0628</td> <td> 3018.519</td> <td>    2.559</td> <td> 0.011</td> <td> 1806.306</td> <td> 1.36e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5772.0</th>      <td> 8901.7882</td> <td> 3086.811</td> <td>    2.884</td> <td> 0.004</td> <td> 2851.170</td> <td>  1.5e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5860.0</th>      <td>-1.948e+04</td> <td> 3110.857</td> <td>   -6.261</td> <td> 0.000</td> <td>-2.56e+04</td> <td>-1.34e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5878.0</th>      <td> 1.119e+04</td> <td> 3037.648</td> <td>    3.682</td> <td> 0.000</td> <td> 5231.276</td> <td> 1.71e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5903.0</th>      <td> 4917.5431</td> <td> 3123.826</td> <td>    1.574</td> <td> 0.115</td> <td>-1205.631</td> <td>  1.1e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5905.0</th>      <td> 6472.3316</td> <td> 3072.948</td> <td>    2.106</td> <td> 0.035</td> <td>  448.886</td> <td> 1.25e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5959.0</th>      <td> 4032.3371</td> <td> 3074.491</td> <td>    1.312</td> <td> 0.190</td> <td>-1994.131</td> <td> 1.01e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6008.0</th>      <td> 2.842e+04</td> <td> 3030.015</td> <td>    9.380</td> <td> 0.000</td> <td> 2.25e+04</td> <td> 3.44e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6034.0</th>      <td> 5915.9539</td> <td> 3166.969</td> <td>    1.868</td> <td> 0.062</td> <td> -291.787</td> <td> 1.21e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6035.0</th>      <td> 4321.0088</td> <td> 3624.230</td> <td>    1.192</td> <td> 0.233</td> <td>-2783.033</td> <td> 1.14e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6036.0</th>      <td>  672.3068</td> <td> 2994.346</td> <td>    0.225</td> <td> 0.822</td> <td>-5197.066</td> <td> 6541.680</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6039.0</th>      <td> 9107.9457</td> <td> 3133.532</td> <td>    2.907</td> <td> 0.004</td> <td> 2965.747</td> <td> 1.53e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6044.0</th>      <td> 1.053e+04</td> <td> 3386.931</td> <td>    3.110</td> <td> 0.002</td> <td> 3894.343</td> <td> 1.72e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6066.0</th>      <td> -2.49e+04</td> <td> 4424.278</td> <td>   -5.629</td> <td> 0.000</td> <td>-3.36e+04</td> <td>-1.62e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6078.0</th>      <td> 9970.6042</td> <td> 3077.931</td> <td>    3.239</td> <td> 0.001</td> <td> 3937.391</td> <td>  1.6e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6081.0</th>      <td>-8372.7134</td> <td> 2993.920</td> <td>   -2.797</td> <td> 0.005</td> <td>-1.42e+04</td> <td>-2504.175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>60893.0</th>     <td>-4392.3442</td> <td> 4603.659</td> <td>   -0.954</td> <td> 0.340</td> <td>-1.34e+04</td> <td> 4631.526</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6097.0</th>      <td> 1.012e+04</td> <td> 3186.388</td> <td>    3.177</td> <td> 0.001</td> <td> 3876.500</td> <td> 1.64e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6102.0</th>      <td> 8471.8648</td> <td> 3120.976</td> <td>    2.714</td> <td> 0.007</td> <td> 2354.277</td> <td> 1.46e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6104.0</th>      <td>-1015.6692</td> <td> 3148.374</td> <td>   -0.323</td> <td> 0.747</td> <td>-7186.960</td> <td> 5155.622</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6109.0</th>      <td> 1845.7093</td> <td> 2960.815</td> <td>    0.623</td> <td> 0.533</td> <td>-3957.937</td> <td> 7649.356</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6127.0</th>      <td> 3170.7530</td> <td> 3399.610</td> <td>    0.933</td> <td> 0.351</td> <td>-3492.999</td> <td> 9834.505</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>61552.0</th>     <td>-3744.5941</td> <td> 4251.815</td> <td>   -0.881</td> <td> 0.378</td> <td>-1.21e+04</td> <td> 4589.610</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6158.0</th>      <td> 6412.2005</td> <td> 3180.992</td> <td>    2.016</td> <td> 0.044</td> <td>  176.973</td> <td> 1.26e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6171.0</th>      <td> 9057.6581</td> <td> 3095.055</td> <td>    2.926</td> <td> 0.003</td> <td> 2990.880</td> <td> 1.51e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>61780.0</th>     <td> 7728.4892</td> <td> 4929.729</td> <td>    1.568</td> <td> 0.117</td> <td>-1934.529</td> <td> 1.74e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6207.0</th>      <td> 9047.4137</td> <td> 3117.371</td> <td>    2.902</td> <td> 0.004</td> <td> 2936.893</td> <td> 1.52e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6214.0</th>      <td> 9507.7433</td> <td> 3104.135</td> <td>    3.063</td> <td> 0.002</td> <td> 3423.167</td> <td> 1.56e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6216.0</th>      <td> 9878.3520</td> <td> 3184.210</td> <td>    3.102</td> <td> 0.002</td> <td> 3636.816</td> <td> 1.61e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>62221.0</th>     <td> 9234.8611</td> <td> 4394.723</td> <td>    2.101</td> <td> 0.036</td> <td>  620.537</td> <td> 1.78e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6259.0</th>      <td> 5439.7175</td> <td> 3440.702</td> <td>    1.581</td> <td> 0.114</td> <td>-1304.581</td> <td> 1.22e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>62599.0</th>     <td>-2.283e+04</td> <td> 4958.737</td> <td>   -4.603</td> <td> 0.000</td> <td>-3.25e+04</td> <td>-1.31e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6266.0</th>      <td> 9238.7331</td> <td> 3091.436</td> <td>    2.988</td> <td> 0.003</td> <td> 3179.048</td> <td> 1.53e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6268.0</th>      <td> 1962.6459</td> <td> 3058.799</td> <td>    0.642</td> <td> 0.521</td> <td>-4033.064</td> <td> 7958.356</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6288.0</th>      <td> 8168.8157</td> <td> 3114.238</td> <td>    2.623</td> <td> 0.009</td> <td> 2064.437</td> <td> 1.43e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6297.0</th>      <td> 9274.3327</td> <td> 3198.409</td> <td>    2.900</td> <td> 0.004</td> <td> 3004.965</td> <td> 1.55e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6307.0</th>      <td>-1.469e+04</td> <td> 3698.147</td> <td>   -3.973</td> <td> 0.000</td> <td>-2.19e+04</td> <td>-7443.955</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6313.0</th>      <td> 8992.0347</td> <td> 4390.677</td> <td>    2.048</td> <td> 0.041</td> <td>  385.640</td> <td> 1.76e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6314.0</th>      <td> 9736.1987</td> <td> 3151.801</td> <td>    3.089</td> <td> 0.002</td> <td> 3558.191</td> <td> 1.59e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6326.0</th>      <td> 3826.7169</td> <td> 2984.925</td> <td>    1.282</td> <td> 0.200</td> <td>-2024.190</td> <td> 9677.624</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6349.0</th>      <td> 8643.9164</td> <td> 3087.391</td> <td>    2.800</td> <td> 0.005</td> <td> 2592.161</td> <td> 1.47e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6357.0</th>      <td> 1.032e+04</td> <td> 3297.883</td> <td>    3.130</td> <td> 0.002</td> <td> 3857.899</td> <td> 1.68e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6375.0</th>      <td> 1.413e+04</td> <td> 3134.685</td> <td>    4.507</td> <td> 0.000</td> <td> 7984.330</td> <td> 2.03e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6376.0</th>      <td> 9471.0692</td> <td> 3147.599</td> <td>    3.009</td> <td> 0.003</td> <td> 3301.297</td> <td> 1.56e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6379.0</th>      <td>-3775.7784</td> <td> 6131.764</td> <td>   -0.616</td> <td> 0.538</td> <td>-1.58e+04</td> <td> 8243.410</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6386.0</th>      <td> 9629.8217</td> <td> 3110.678</td> <td>    3.096</td> <td> 0.002</td> <td> 3532.421</td> <td> 1.57e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6403.0</th>      <td> 5780.6448</td> <td> 3183.328</td> <td>    1.816</td> <td> 0.069</td> <td> -459.161</td> <td>  1.2e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6410.0</th>      <td> 1.062e+04</td> <td> 3209.167</td> <td>    3.309</td> <td> 0.001</td> <td> 4327.639</td> <td> 1.69e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6416.0</th>      <td> 4480.9728</td> <td> 3166.668</td> <td>    1.415</td> <td> 0.157</td> <td>-1726.177</td> <td> 1.07e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6424.0</th>      <td> 9498.0653</td> <td> 3132.089</td> <td>    3.033</td> <td> 0.002</td> <td> 3358.695</td> <td> 1.56e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6433.0</th>      <td> 9589.1419</td> <td> 3170.423</td> <td>    3.025</td> <td> 0.002</td> <td> 3374.632</td> <td> 1.58e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6435.0</th>      <td> 9723.4153</td> <td> 3042.211</td> <td>    3.196</td> <td> 0.001</td> <td> 3760.220</td> <td> 1.57e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6492.0</th>      <td> 6260.6289</td> <td> 3090.244</td> <td>    2.026</td> <td> 0.043</td> <td>  203.281</td> <td> 1.23e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6497.0</th>      <td> 2903.0101</td> <td> 3215.604</td> <td>    0.903</td> <td> 0.367</td> <td>-3400.062</td> <td> 9206.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6500.0</th>      <td> 8402.1659</td> <td> 7302.670</td> <td>    1.151</td> <td> 0.250</td> <td>-5912.176</td> <td> 2.27e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6509.0</th>      <td> 8464.7557</td> <td> 3077.538</td> <td>    2.750</td> <td> 0.006</td> <td> 2432.313</td> <td> 1.45e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6527.0</th>      <td> 1.055e+04</td> <td> 3417.715</td> <td>    3.086</td> <td> 0.002</td> <td> 3848.357</td> <td> 1.72e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6528.0</th>      <td> 8661.1370</td> <td> 3343.926</td> <td>    2.590</td> <td> 0.010</td> <td> 2106.534</td> <td> 1.52e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6531.0</th>      <td>  -25.9974</td> <td> 3078.405</td> <td>   -0.008</td> <td> 0.993</td> <td>-6060.139</td> <td> 6008.144</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6532.0</th>      <td> 5885.9647</td> <td> 3095.765</td> <td>    1.901</td> <td> 0.057</td> <td> -182.205</td> <td>  1.2e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6543.0</th>      <td> 9929.9352</td> <td> 3144.078</td> <td>    3.158</td> <td> 0.002</td> <td> 3767.065</td> <td> 1.61e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6548.0</th>      <td> 9593.2367</td> <td> 3169.925</td> <td>    3.026</td> <td> 0.002</td> <td> 3379.702</td> <td> 1.58e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6550.0</th>      <td> 9616.0676</td> <td> 3359.843</td> <td>    2.862</td> <td> 0.004</td> <td> 3030.264</td> <td> 1.62e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6552.0</th>      <td> 9638.8646</td> <td> 3275.149</td> <td>    2.943</td> <td> 0.003</td> <td> 3219.075</td> <td> 1.61e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6565.0</th>      <td> 4782.1084</td> <td> 3198.665</td> <td>    1.495</td> <td> 0.135</td> <td>-1487.761</td> <td> 1.11e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6571.0</th>      <td> 9305.0305</td> <td> 3110.487</td> <td>    2.992</td> <td> 0.003</td> <td> 3208.004</td> <td> 1.54e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6573.0</th>      <td> 9082.6070</td> <td> 3092.638</td> <td>    2.937</td> <td> 0.003</td> <td> 3020.566</td> <td> 1.51e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6641.0</th>      <td> 7749.3873</td> <td> 5382.286</td> <td>    1.440</td> <td> 0.150</td> <td>-2800.711</td> <td> 1.83e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6649.0</th>      <td> 1.053e+04</td> <td> 3159.208</td> <td>    3.335</td> <td> 0.001</td> <td> 4342.190</td> <td> 1.67e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6730.0</th>      <td> 8500.3738</td> <td> 3089.775</td> <td>    2.751</td> <td> 0.006</td> <td> 2443.946</td> <td> 1.46e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6731.0</th>      <td> 6466.6645</td> <td> 3134.642</td> <td>    2.063</td> <td> 0.039</td> <td>  322.291</td> <td> 1.26e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6742.0</th>      <td> 9550.9622</td> <td> 4649.788</td> <td>    2.054</td> <td> 0.040</td> <td>  436.672</td> <td> 1.87e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6745.0</th>      <td> 1.009e+04</td> <td> 3200.253</td> <td>    3.154</td> <td> 0.002</td> <td> 3820.559</td> <td> 1.64e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6756.0</th>      <td> 9834.8380</td> <td> 3160.429</td> <td>    3.112</td> <td> 0.002</td> <td> 3639.917</td> <td>  1.6e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6765.0</th>      <td>-4414.1271</td> <td> 3022.513</td> <td>   -1.460</td> <td> 0.144</td> <td>-1.03e+04</td> <td> 1510.458</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6768.0</th>      <td> 1.156e+04</td> <td> 3234.772</td> <td>    3.575</td> <td> 0.000</td> <td> 5223.749</td> <td> 1.79e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6774.0</th>      <td> -1.45e+04</td> <td> 3423.679</td> <td>   -4.235</td> <td> 0.000</td> <td>-2.12e+04</td> <td>-7789.918</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6797.0</th>      <td> 1.062e+04</td> <td> 3560.156</td> <td>    2.982</td> <td> 0.003</td> <td> 3636.640</td> <td> 1.76e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6803.0</th>      <td> 9790.5158</td> <td> 3152.629</td> <td>    3.106</td> <td> 0.002</td> <td> 3610.883</td> <td>  1.6e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6821.0</th>      <td> 8916.7458</td> <td> 3111.850</td> <td>    2.865</td> <td> 0.004</td> <td> 2817.047</td> <td>  1.5e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6830.0</th>      <td> 8333.4226</td> <td> 3124.559</td> <td>    2.667</td> <td> 0.008</td> <td> 2208.812</td> <td> 1.45e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6845.0</th>      <td> 6582.6117</td> <td> 3033.170</td> <td>    2.170</td> <td> 0.030</td> <td>  637.138</td> <td> 1.25e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6848.0</th>      <td> 9265.8494</td> <td> 3380.966</td> <td>    2.741</td> <td> 0.006</td> <td> 2638.642</td> <td> 1.59e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6873.0</th>      <td> 5262.2493</td> <td> 3710.128</td> <td>    1.418</td> <td> 0.156</td> <td>-2010.164</td> <td> 1.25e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6900.0</th>      <td> 7470.5391</td> <td> 3040.133</td> <td>    2.457</td> <td> 0.014</td> <td> 1511.417</td> <td> 1.34e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6908.0</th>      <td> 7574.9222</td> <td> 3037.300</td> <td>    2.494</td> <td> 0.013</td> <td> 1621.353</td> <td> 1.35e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6994.0</th>      <td> 8255.8589</td> <td> 3119.283</td> <td>    2.647</td> <td> 0.008</td> <td> 2141.590</td> <td> 1.44e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7045.0</th>      <td> 1844.4045</td> <td> 3736.226</td> <td>    0.494</td> <td> 0.622</td> <td>-5479.167</td> <td> 9167.976</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7065.0</th>      <td> 1.408e+04</td> <td> 3067.167</td> <td>    4.591</td> <td> 0.000</td> <td> 8070.340</td> <td> 2.01e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7085.0</th>      <td>  1.13e+04</td> <td> 3081.095</td> <td>    3.669</td> <td> 0.000</td> <td> 5264.878</td> <td> 1.73e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7107.0</th>      <td> 8052.7198</td> <td> 3211.390</td> <td>    2.508</td> <td> 0.012</td> <td> 1757.908</td> <td> 1.43e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7116.0</th>      <td> 1.032e+04</td> <td> 3179.999</td> <td>    3.245</td> <td> 0.001</td> <td> 4086.849</td> <td> 1.66e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7117.0</th>      <td> 1.055e+04</td> <td> 3949.975</td> <td>    2.671</td> <td> 0.008</td> <td> 2809.099</td> <td> 1.83e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7121.0</th>      <td> 8775.8315</td> <td> 3133.720</td> <td>    2.800</td> <td> 0.005</td> <td> 2633.264</td> <td> 1.49e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7127.0</th>      <td> 6420.8313</td> <td> 3243.158</td> <td>    1.980</td> <td> 0.048</td> <td>   63.750</td> <td> 1.28e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7139.0</th>      <td> 8727.2476</td> <td> 3099.294</td> <td>    2.816</td> <td> 0.005</td> <td> 2652.161</td> <td> 1.48e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7146.0</th>      <td> 9720.1875</td> <td> 3126.664</td> <td>    3.109</td> <td> 0.002</td> <td> 3591.451</td> <td> 1.58e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7163.0</th>      <td> 1.279e+04</td> <td> 3134.484</td> <td>    4.081</td> <td> 0.000</td> <td> 6646.405</td> <td> 1.89e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7180.0</th>      <td> 6160.9922</td> <td> 3087.312</td> <td>    1.996</td> <td> 0.046</td> <td>  109.392</td> <td> 1.22e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7183.0</th>      <td> 6762.3251</td> <td> 3128.386</td> <td>    2.162</td> <td> 0.031</td> <td>  630.214</td> <td> 1.29e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7228.0</th>      <td> 1.764e+04</td> <td> 3168.523</td> <td>    5.567</td> <td> 0.000</td> <td> 1.14e+04</td> <td> 2.38e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7232.0</th>      <td> 8154.6539</td> <td> 4154.025</td> <td>    1.963</td> <td> 0.050</td> <td>   12.134</td> <td> 1.63e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7250.0</th>      <td> 6766.0899</td> <td> 3377.887</td> <td>    2.003</td> <td> 0.045</td> <td>  144.918</td> <td> 1.34e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7257.0</th>      <td> 2.971e+04</td> <td> 3115.326</td> <td>    9.536</td> <td> 0.000</td> <td> 2.36e+04</td> <td> 3.58e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7260.0</th>      <td> 9150.8519</td> <td> 3085.180</td> <td>    2.966</td> <td> 0.003</td> <td> 3103.431</td> <td> 1.52e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7267.0</th>      <td> 8865.9508</td> <td> 3234.107</td> <td>    2.741</td> <td> 0.006</td> <td> 2526.610</td> <td> 1.52e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7268.0</th>      <td> 1505.3236</td> <td> 3301.821</td> <td>    0.456</td> <td> 0.648</td> <td>-4966.748</td> <td> 7977.395</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7281.0</th>      <td> 9732.5905</td> <td> 3991.005</td> <td>    2.439</td> <td> 0.015</td> <td> 1909.615</td> <td> 1.76e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7291.0</th>      <td> 7456.0581</td> <td> 3068.111</td> <td>    2.430</td> <td> 0.015</td> <td> 1442.096</td> <td> 1.35e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7343.0</th>      <td> 4436.4667</td> <td> 3573.654</td> <td>    1.241</td> <td> 0.214</td> <td>-2568.438</td> <td> 1.14e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7346.0</th>      <td> 3238.1303</td> <td> 3079.092</td> <td>    1.052</td> <td> 0.293</td> <td>-2797.357</td> <td> 9273.617</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7401.0</th>      <td> 9349.7327</td> <td> 3138.244</td> <td>    2.979</td> <td> 0.003</td> <td> 3198.297</td> <td> 1.55e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7409.0</th>      <td> 8457.9972</td> <td> 3066.239</td> <td>    2.758</td> <td> 0.006</td> <td> 2447.702</td> <td> 1.45e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7420.0</th>      <td> 6215.9290</td> <td> 3018.667</td> <td>    2.059</td> <td> 0.039</td> <td>  298.884</td> <td> 1.21e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7435.0</th>      <td> 6751.7467</td> <td> 3158.717</td> <td>    2.137</td> <td> 0.033</td> <td>  560.181</td> <td> 1.29e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7466.0</th>      <td> 8553.9161</td> <td> 3269.146</td> <td>    2.617</td> <td> 0.009</td> <td> 2145.893</td> <td>  1.5e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7486.0</th>      <td> 1723.3876</td> <td> 3152.520</td> <td>    0.547</td> <td> 0.585</td> <td>-4456.030</td> <td> 7902.805</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7503.0</th>      <td> 9067.0759</td> <td> 4579.905</td> <td>    1.980</td> <td> 0.048</td> <td>   89.767</td> <td>  1.8e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7506.0</th>      <td> 9819.2990</td> <td> 3057.813</td> <td>    3.211</td> <td> 0.001</td> <td> 3825.522</td> <td> 1.58e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7537.0</th>      <td> 9430.8825</td> <td> 3170.373</td> <td>    2.975</td> <td> 0.003</td> <td> 3216.470</td> <td> 1.56e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7549.0</th>      <td> 7273.1684</td> <td> 3042.817</td> <td>    2.390</td> <td> 0.017</td> <td> 1308.786</td> <td> 1.32e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7554.0</th>      <td> 8897.8883</td> <td> 3135.083</td> <td>    2.838</td> <td> 0.005</td> <td> 2752.650</td> <td>  1.5e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7557.0</th>      <td> 6931.8955</td> <td> 3136.896</td> <td>    2.210</td> <td> 0.027</td> <td>  783.102</td> <td> 1.31e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7585.0</th>      <td>-1.495e+04</td> <td> 3233.948</td> <td>   -4.624</td> <td> 0.000</td> <td>-2.13e+04</td> <td>-8613.193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7602.0</th>      <td> 8923.7108</td> <td> 3107.157</td> <td>    2.872</td> <td> 0.004</td> <td> 2833.211</td> <td>  1.5e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7620.0</th>      <td> 7129.5037</td> <td> 3384.544</td> <td>    2.106</td> <td> 0.035</td> <td>  495.283</td> <td> 1.38e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7636.0</th>      <td> 9304.1976</td> <td> 3123.447</td> <td>    2.979</td> <td> 0.003</td> <td> 3181.767</td> <td> 1.54e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7646.0</th>      <td> 9393.7191</td> <td> 3155.786</td> <td>    2.977</td> <td> 0.003</td> <td> 3207.900</td> <td> 1.56e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7658.0</th>      <td> 6253.3200</td> <td> 3022.501</td> <td>    2.069</td> <td> 0.039</td> <td>  328.759</td> <td> 1.22e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7683.0</th>      <td> 1.026e+04</td> <td> 3321.592</td> <td>    3.090</td> <td> 0.002</td> <td> 3753.317</td> <td> 1.68e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7685.0</th>      <td> 8767.4758</td> <td> 3234.267</td> <td>    2.711</td> <td> 0.007</td> <td> 2427.821</td> <td> 1.51e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7692.0</th>      <td> 5012.1399</td> <td> 3004.385</td> <td>    1.668</td> <td> 0.095</td> <td> -876.911</td> <td> 1.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7762.0</th>      <td> 9366.4810</td> <td> 3091.150</td> <td>    3.030</td> <td> 0.002</td> <td> 3307.357</td> <td> 1.54e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7772.0</th>      <td>-2443.1777</td> <td> 3001.938</td> <td>   -0.814</td> <td> 0.416</td> <td>-8327.432</td> <td> 3441.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7773.0</th>      <td> 8790.9387</td> <td> 3128.430</td> <td>    2.810</td> <td> 0.005</td> <td> 2658.740</td> <td> 1.49e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7777.0</th>      <td> 5620.5173</td> <td> 3072.543</td> <td>    1.829</td> <td> 0.067</td> <td> -402.134</td> <td> 1.16e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7835.0</th>      <td> 9969.7493</td> <td> 3156.641</td> <td>    3.158</td> <td> 0.002</td> <td> 3782.253</td> <td> 1.62e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7873.0</th>      <td> 1753.2079</td> <td> 3096.978</td> <td>    0.566</td> <td> 0.571</td> <td>-4317.340</td> <td> 7823.755</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7883.0</th>      <td> 6648.1472</td> <td> 3032.795</td> <td>    2.192</td> <td> 0.028</td> <td>  703.409</td> <td> 1.26e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7904.0</th>      <td> 5757.8853</td> <td> 3042.665</td> <td>    1.892</td> <td> 0.058</td> <td> -206.199</td> <td> 1.17e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7906.0</th>      <td>  1.24e+04</td> <td> 3192.708</td> <td>    3.884</td> <td> 0.000</td> <td> 6143.287</td> <td> 1.87e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7921.0</th>      <td> 9521.8682</td> <td> 3078.497</td> <td>    3.093</td> <td> 0.002</td> <td> 3487.546</td> <td> 1.56e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7923.0</th>      <td> 8424.9184</td> <td> 3204.025</td> <td>    2.629</td> <td> 0.009</td> <td> 2144.542</td> <td> 1.47e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7935.0</th>      <td> 6955.2953</td> <td> 3049.615</td> <td>    2.281</td> <td> 0.023</td> <td>  977.586</td> <td> 1.29e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7938.0</th>      <td> 7442.0282</td> <td> 3074.413</td> <td>    2.421</td> <td> 0.016</td> <td> 1415.711</td> <td> 1.35e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7985.0</th>      <td>-1.012e+04</td> <td> 2991.410</td> <td>   -3.382</td> <td> 0.001</td> <td> -1.6e+04</td> <td>-4253.115</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8014.0</th>      <td> 8157.1933</td> <td> 3199.316</td> <td>    2.550</td> <td> 0.011</td> <td> 1886.047</td> <td> 1.44e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8030.0</th>      <td> 1.069e+04</td> <td> 3172.643</td> <td>    3.370</td> <td> 0.001</td> <td> 4474.298</td> <td> 1.69e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8046.0</th>      <td> 2100.8383</td> <td> 3150.625</td> <td>    0.667</td> <td> 0.505</td> <td>-4074.865</td> <td> 8276.542</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8047.0</th>      <td> 8930.9265</td> <td> 3638.445</td> <td>    2.455</td> <td> 0.014</td> <td> 1799.022</td> <td> 1.61e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8062.0</th>      <td> 7656.2181</td> <td> 3156.951</td> <td>    2.425</td> <td> 0.015</td> <td> 1468.115</td> <td> 1.38e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8068.0</th>      <td>-6316.9730</td> <td> 3342.935</td> <td>   -1.890</td> <td> 0.059</td> <td>-1.29e+04</td> <td>  235.687</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8087.0</th>      <td>-1486.8453</td> <td> 3165.038</td> <td>   -0.470</td> <td> 0.639</td> <td>-7690.801</td> <td> 4717.110</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8095.0</th>      <td> 9092.3282</td> <td> 3091.617</td> <td>    2.941</td> <td> 0.003</td> <td> 3032.289</td> <td> 1.52e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8096.0</th>      <td> 9888.7824</td> <td> 3156.253</td> <td>    3.133</td> <td> 0.002</td> <td> 3702.048</td> <td> 1.61e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8109.0</th>      <td> 9592.9423</td> <td> 3114.281</td> <td>    3.080</td> <td> 0.002</td> <td> 3488.479</td> <td> 1.57e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8123.0</th>      <td> 5332.5335</td> <td> 3050.740</td> <td>    1.748</td> <td> 0.080</td> <td> -647.380</td> <td> 1.13e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8150.0</th>      <td> 1.002e+04</td> <td> 3143.649</td> <td>    3.186</td> <td> 0.001</td> <td> 3854.817</td> <td> 1.62e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8163.0</th>      <td> 7135.9390</td> <td> 3109.533</td> <td>    2.295</td> <td> 0.022</td> <td> 1040.782</td> <td> 1.32e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8176.0</th>      <td> 5907.8263</td> <td> 3555.339</td> <td>    1.662</td> <td> 0.097</td> <td>-1061.178</td> <td> 1.29e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8202.0</th>      <td> 7093.7298</td> <td> 3180.484</td> <td>    2.230</td> <td> 0.026</td> <td>  859.499</td> <td> 1.33e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8214.0</th>      <td> 5649.2334</td> <td> 3049.389</td> <td>    1.853</td> <td> 0.064</td> <td> -328.032</td> <td> 1.16e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8215.0</th>      <td> 3589.9167</td> <td> 3151.067</td> <td>    1.139</td> <td> 0.255</td> <td>-2586.652</td> <td> 9766.486</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8219.0</th>      <td> 1.015e+04</td> <td> 3202.762</td> <td>    3.170</td> <td> 0.002</td> <td> 3875.511</td> <td> 1.64e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8247.0</th>      <td> 5130.0212</td> <td> 3044.372</td> <td>    1.685</td> <td> 0.092</td> <td> -837.409</td> <td> 1.11e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8253.0</th>      <td>-2202.2944</td> <td> 3019.455</td> <td>   -0.729</td> <td> 0.466</td> <td>-8120.885</td> <td> 3716.296</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8290.0</th>      <td> 6667.9159</td> <td> 3236.736</td> <td>    2.060</td> <td> 0.039</td> <td>  323.422</td> <td>  1.3e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8293.0</th>      <td> 7346.0103</td> <td> 3043.721</td> <td>    2.413</td> <td> 0.016</td> <td> 1379.855</td> <td> 1.33e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8304.0</th>      <td> 9985.5502</td> <td> 3093.631</td> <td>    3.228</td> <td> 0.001</td> <td> 3921.565</td> <td>  1.6e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8334.0</th>      <td> 9750.2882</td> <td> 3258.525</td> <td>    2.992</td> <td> 0.003</td> <td> 3363.085</td> <td> 1.61e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8348.0</th>      <td> 9196.9702</td> <td> 3156.426</td> <td>    2.914</td> <td> 0.004</td> <td> 3009.895</td> <td> 1.54e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8357.0</th>      <td> 8782.9091</td> <td> 3076.771</td> <td>    2.855</td> <td> 0.004</td> <td> 2751.971</td> <td> 1.48e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8358.0</th>      <td> 6761.4473</td> <td> 3044.175</td> <td>    2.221</td> <td> 0.026</td> <td>  794.402</td> <td> 1.27e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8446.0</th>      <td>-3983.6259</td> <td> 3374.667</td> <td>   -1.180</td> <td> 0.238</td> <td>-1.06e+04</td> <td> 2631.234</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8460.0</th>      <td> 1.098e+04</td> <td> 3537.306</td> <td>    3.105</td> <td> 0.002</td> <td> 4051.291</td> <td> 1.79e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8463.0</th>      <td> 8838.8993</td> <td> 3110.041</td> <td>    2.842</td> <td> 0.004</td> <td> 2742.747</td> <td> 1.49e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8479.0</th>      <td> 7883.3944</td> <td> 3750.123</td> <td>    2.102</td> <td> 0.036</td> <td>  532.584</td> <td> 1.52e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8530.0</th>      <td> 2.055e+04</td> <td> 3130.331</td> <td>    6.565</td> <td> 0.000</td> <td> 1.44e+04</td> <td> 2.67e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8536.0</th>      <td> 5321.9245</td> <td> 3023.926</td> <td>    1.760</td> <td> 0.078</td> <td> -605.430</td> <td> 1.12e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8543.0</th>      <td>  2.91e+04</td> <td> 3348.461</td> <td>    8.689</td> <td> 0.000</td> <td> 2.25e+04</td> <td> 3.57e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8549.0</th>      <td>  288.7530</td> <td> 3183.883</td> <td>    0.091</td> <td> 0.928</td> <td>-5952.140</td> <td> 6529.646</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8551.0</th>      <td> 9857.0564</td> <td> 3160.749</td> <td>    3.119</td> <td> 0.002</td> <td> 3661.508</td> <td> 1.61e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8559.0</th>      <td> 6877.9877</td> <td> 3301.144</td> <td>    2.084</td> <td> 0.037</td> <td>  407.244</td> <td> 1.33e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8573.0</th>      <td> 2363.2893</td> <td> 3354.437</td> <td>    0.705</td> <td> 0.481</td> <td>-4211.916</td> <td> 8938.495</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8606.0</th>      <td> 9996.9128</td> <td> 3074.136</td> <td>    3.252</td> <td> 0.001</td> <td> 3971.140</td> <td>  1.6e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8607.0</th>      <td> 1.008e+04</td> <td> 3199.827</td> <td>    3.150</td> <td> 0.002</td> <td> 3805.949</td> <td> 1.64e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8648.0</th>      <td> 8703.5470</td> <td> 3078.394</td> <td>    2.827</td> <td> 0.005</td> <td> 2669.428</td> <td> 1.47e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8657.0</th>      <td> 4027.2377</td> <td> 3062.602</td> <td>    1.315</td> <td> 0.189</td> <td>-1975.927</td> <td>    1e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8675.0</th>      <td> 9234.4663</td> <td> 4423.761</td> <td>    2.087</td> <td> 0.037</td> <td>  563.222</td> <td> 1.79e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8681.0</th>      <td> 5022.8681</td> <td> 2990.914</td> <td>    1.679</td> <td> 0.093</td> <td> -839.778</td> <td> 1.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8687.0</th>      <td> 6865.4753</td> <td> 3330.626</td> <td>    2.061</td> <td> 0.039</td> <td>  336.943</td> <td> 1.34e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8692.0</th>      <td> 6724.1365</td> <td> 3040.648</td> <td>    2.211</td> <td> 0.027</td> <td>  764.005</td> <td> 1.27e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8699.0</th>      <td> 9368.7656</td> <td> 3104.748</td> <td>    3.018</td> <td> 0.003</td> <td> 3282.988</td> <td> 1.55e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8717.0</th>      <td> 1.007e+04</td> <td> 3139.976</td> <td>    3.206</td> <td> 0.001</td> <td> 3910.883</td> <td> 1.62e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8759.0</th>      <td> 6032.6233</td> <td> 3129.293</td> <td>    1.928</td> <td> 0.054</td> <td> -101.267</td> <td> 1.22e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8762.0</th>      <td> 1.005e+04</td> <td> 3163.140</td> <td>    3.177</td> <td> 0.001</td> <td> 3847.994</td> <td> 1.62e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8819.0</th>      <td>  1.08e+04</td> <td> 3255.498</td> <td>    3.319</td> <td> 0.001</td> <td> 4422.683</td> <td> 1.72e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8850.0</th>      <td> 9180.3611</td> <td> 3099.787</td> <td>    2.962</td> <td> 0.003</td> <td> 3104.308</td> <td> 1.53e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8852.0</th>      <td> 9396.6270</td> <td> 3137.971</td> <td>    2.994</td> <td> 0.003</td> <td> 3245.728</td> <td> 1.55e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8859.0</th>      <td> 9958.6402</td> <td> 3172.396</td> <td>    3.139</td> <td> 0.002</td> <td> 3740.263</td> <td> 1.62e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8867.0</th>      <td> 2878.0832</td> <td> 3278.995</td> <td>    0.878</td> <td> 0.380</td> <td>-3549.244</td> <td> 9305.411</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8881.0</th>      <td> 7955.4694</td> <td> 3090.496</td> <td>    2.574</td> <td> 0.010</td> <td> 1897.629</td> <td>  1.4e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8958.0</th>      <td> 7012.8960</td> <td> 3062.779</td> <td>    2.290</td> <td> 0.022</td> <td> 1009.384</td> <td>  1.3e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8972.0</th>      <td>-1.071e+04</td> <td> 3041.870</td> <td>   -3.522</td> <td> 0.000</td> <td>-1.67e+04</td> <td>-4751.155</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8990.0</th>      <td>  237.8112</td> <td> 3143.690</td> <td>    0.076</td> <td> 0.940</td> <td>-5924.298</td> <td> 6399.920</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9004.0</th>      <td> 1.047e+04</td> <td> 3372.333</td> <td>    3.105</td> <td> 0.002</td> <td> 3861.201</td> <td> 1.71e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9016.0</th>      <td> 7304.7780</td> <td> 3039.777</td> <td>    2.403</td> <td> 0.016</td> <td> 1346.353</td> <td> 1.33e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9048.0</th>      <td> 6403.1328</td> <td> 3012.256</td> <td>    2.126</td> <td> 0.034</td> <td>  498.654</td> <td> 1.23e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9051.0</th>      <td> 1965.6327</td> <td> 3401.698</td> <td>    0.578</td> <td> 0.563</td> <td>-4702.212</td> <td> 8633.478</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9071.0</th>      <td> 6269.8156</td> <td> 3082.415</td> <td>    2.034</td> <td> 0.042</td> <td>  227.814</td> <td> 1.23e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9112.0</th>      <td> 5595.9253</td> <td> 3023.816</td> <td>    1.851</td> <td> 0.064</td> <td> -331.214</td> <td> 1.15e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9114.0</th>      <td> 3815.5590</td> <td> 3108.453</td> <td>    1.227</td> <td> 0.220</td> <td>-2277.481</td> <td> 9908.599</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9132.0</th>      <td> 9293.0465</td> <td> 4448.428</td> <td>    2.089</td> <td> 0.037</td> <td>  573.452</td> <td>  1.8e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9173.0</th>      <td> 8593.1758</td> <td> 3436.473</td> <td>    2.501</td> <td> 0.012</td> <td> 1857.168</td> <td> 1.53e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9180.0</th>      <td> 9960.1426</td> <td> 3212.901</td> <td>    3.100</td> <td> 0.002</td> <td> 3662.368</td> <td> 1.63e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9186.0</th>      <td> 8369.7659</td> <td> 3096.656</td> <td>    2.703</td> <td> 0.007</td> <td> 2299.850</td> <td> 1.44e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9191.0</th>      <td> 5236.9855</td> <td> 4093.728</td> <td>    1.279</td> <td> 0.201</td> <td>-2787.343</td> <td> 1.33e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9216.0</th>      <td> 3177.1857</td> <td> 2977.132</td> <td>    1.067</td> <td> 0.286</td> <td>-2658.445</td> <td> 9012.817</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9217.0</th>      <td>  345.3862</td> <td> 2964.765</td> <td>    0.116</td> <td> 0.907</td> <td>-5466.004</td> <td> 6156.777</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9225.0</th>      <td> 9669.4538</td> <td> 3102.778</td> <td>    3.116</td> <td> 0.002</td> <td> 3587.537</td> <td> 1.58e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9230.0</th>      <td> 1.017e+04</td> <td> 3631.753</td> <td>    2.800</td> <td> 0.005</td> <td> 3049.714</td> <td> 1.73e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9259.0</th>      <td> 1.082e+04</td> <td> 3195.981</td> <td>    3.387</td> <td> 0.001</td> <td> 4559.228</td> <td> 1.71e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9293.0</th>      <td> 9826.5015</td> <td> 3129.155</td> <td>    3.140</td> <td> 0.002</td> <td> 3692.884</td> <td>  1.6e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9299.0</th>      <td> 4757.1723</td> <td> 3068.861</td> <td>    1.550</td> <td> 0.121</td> <td>-1258.262</td> <td> 1.08e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9308.0</th>      <td> 5449.7947</td> <td> 3213.596</td> <td>    1.696</td> <td> 0.090</td> <td> -849.341</td> <td> 1.17e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9311.0</th>      <td> 6091.4889</td> <td> 4097.403</td> <td>    1.487</td> <td> 0.137</td> <td>-1940.043</td> <td> 1.41e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9313.0</th>      <td> 4314.0795</td> <td> 3025.653</td> <td>    1.426</td> <td> 0.154</td> <td>-1616.660</td> <td> 1.02e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9325.0</th>      <td> 8571.9786</td> <td> 3107.010</td> <td>    2.759</td> <td> 0.006</td> <td> 2481.767</td> <td> 1.47e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9332.0</th>      <td> 7832.2604</td> <td> 3050.287</td> <td>    2.568</td> <td> 0.010</td> <td> 1853.235</td> <td> 1.38e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9340.0</th>      <td>-1.284e+04</td> <td> 4266.321</td> <td>   -3.009</td> <td> 0.003</td> <td>-2.12e+04</td> <td>-4476.619</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9372.0</th>      <td> 1.011e+04</td> <td> 3506.811</td> <td>    2.883</td> <td> 0.004</td> <td> 3237.019</td> <td>  1.7e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9411.0</th>      <td> 6355.8057</td> <td> 3158.698</td> <td>    2.012</td> <td> 0.044</td> <td>  164.278</td> <td> 1.25e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9459.0</th>      <td> 4594.2014</td> <td> 3082.822</td> <td>    1.490</td> <td> 0.136</td> <td>-1448.598</td> <td> 1.06e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9465.0</th>      <td> 1.241e+04</td> <td> 3064.660</td> <td>    4.049</td> <td> 0.000</td> <td> 6402.210</td> <td> 1.84e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9472.0</th>      <td> 4269.6200</td> <td> 2986.010</td> <td>    1.430</td> <td> 0.153</td> <td>-1583.412</td> <td> 1.01e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9483.0</th>      <td> -216.2534</td> <td> 3044.454</td> <td>   -0.071</td> <td> 0.943</td> <td>-6183.846</td> <td> 5751.340</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9563.0</th>      <td>-1.792e+04</td> <td> 4211.763</td> <td>   -4.256</td> <td> 0.000</td> <td>-2.62e+04</td> <td>-9668.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9590.0</th>      <td> 7000.0639</td> <td> 3121.546</td> <td>    2.242</td> <td> 0.025</td> <td>  881.359</td> <td> 1.31e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9598.0</th>      <td> 4487.5163</td> <td> 3762.106</td> <td>    1.193</td> <td> 0.233</td> <td>-2886.783</td> <td> 1.19e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9599.0</th>      <td> 3721.4346</td> <td> 3033.177</td> <td>    1.227</td> <td> 0.220</td> <td>-2224.052</td> <td> 9666.921</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9602.0</th>      <td> 3023.8387</td> <td> 4071.341</td> <td>    0.743</td> <td> 0.458</td> <td>-4956.608</td> <td>  1.1e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9619.0</th>      <td> 1.003e+04</td> <td> 3221.664</td> <td>    3.113</td> <td> 0.002</td> <td> 3715.041</td> <td> 1.63e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9643.0</th>      <td> 6673.9738</td> <td> 3111.149</td> <td>    2.145</td> <td> 0.032</td> <td>  575.650</td> <td> 1.28e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9650.0</th>      <td> 5948.1118</td> <td> 3049.133</td> <td>    1.951</td> <td> 0.051</td> <td>  -28.652</td> <td> 1.19e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9653.0</th>      <td>-5201.1049</td> <td> 5261.293</td> <td>   -0.989</td> <td> 0.323</td> <td>-1.55e+04</td> <td> 5111.828</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9667.0</th>      <td> 5978.4574</td> <td> 3032.475</td> <td>    1.971</td> <td> 0.049</td> <td>   34.345</td> <td> 1.19e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9698.0</th>      <td> 8360.8550</td> <td> 3113.996</td> <td>    2.685</td> <td> 0.007</td> <td> 2256.949</td> <td> 1.45e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9699.0</th>      <td> 9695.4952</td> <td> 3081.120</td> <td>    3.147</td> <td> 0.002</td> <td> 3656.031</td> <td> 1.57e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9719.0</th>      <td> 1673.7655</td> <td> 2960.502</td> <td>    0.565</td> <td> 0.572</td> <td>-4129.267</td> <td> 7476.798</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9742.0</th>      <td> 1462.5312</td> <td> 3123.254</td> <td>    0.468</td> <td> 0.640</td> <td>-4659.520</td> <td> 7584.583</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9761.0</th>      <td> 9161.1397</td> <td> 3123.661</td> <td>    2.933</td> <td> 0.003</td> <td> 3038.290</td> <td> 1.53e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9771.0</th>      <td> 2489.7585</td> <td> 2963.761</td> <td>    0.840</td> <td> 0.401</td> <td>-3319.664</td> <td> 8299.181</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9772.0</th>      <td> 9912.5502</td> <td> 3147.378</td> <td>    3.149</td> <td> 0.002</td> <td> 3743.211</td> <td> 1.61e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9778.0</th>      <td> 7202.1314</td> <td> 3024.139</td> <td>    2.382</td> <td> 0.017</td> <td> 1274.359</td> <td> 1.31e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9799.0</th>      <td> 1707.7949</td> <td> 3109.095</td> <td>    0.549</td> <td> 0.583</td> <td>-4386.503</td> <td> 7802.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9815.0</th>      <td> 9088.3459</td> <td> 3223.230</td> <td>    2.820</td> <td> 0.005</td> <td> 2770.327</td> <td> 1.54e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9818.0</th>      <td>-3.452e+04</td> <td> 3202.790</td> <td>  -10.779</td> <td> 0.000</td> <td>-4.08e+04</td> <td>-2.82e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9837.0</th>      <td> 1.056e+04</td> <td> 3244.249</td> <td>    3.254</td> <td> 0.001</td> <td> 4198.886</td> <td> 1.69e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9922.0</th>      <td> 2994.0482</td> <td> 3000.566</td> <td>    0.998</td> <td> 0.318</td> <td>-2887.517</td> <td> 8875.613</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9954.0</th>      <td> 5697.1012</td> <td> 3683.632</td> <td>    1.547</td> <td> 0.122</td> <td>-1523.378</td> <td> 1.29e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9963.0</th>      <td> 7227.4542</td> <td> 3090.223</td> <td>    2.339</td> <td> 0.019</td> <td> 1170.149</td> <td> 1.33e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9988.0</th>      <td> 1.018e+04</td> <td> 3189.909</td> <td>    3.192</td> <td> 0.001</td> <td> 3928.483</td> <td> 1.64e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>21744.289</td> <th>  Durbin-Watson:     </th>   <td>   0.548</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>50237524.155</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>10.223</td>   <th>  Prob(JB):          </th>   <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>302.434</td>  <th>  Cond. No.          </th>   <td>2.00e+07</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large,  2e+07. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &      rmkvaf      & \\textbf{  R-squared:         } &      0.665    \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &      0.645    \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &      33.22    \\\\\n",
       "\\textbf{Date:}             & Fri, 18 Oct 2024 & \\textbf{  Prob (F-statistic):} &      0.00     \\\\\n",
       "\\textbf{Time:}             &     18:53:18     & \\textbf{  Log-Likelihood:    } & -1.4157e+05   \\\\\n",
       "\\textbf{No. Observations:} &       13385      & \\textbf{  AIC:               } &  2.847e+05    \\\\\n",
       "\\textbf{Df Residuals:}     &       12629      & \\textbf{  BIC:               } &  2.903e+05    \\\\\n",
       "\\textbf{Df Model:}         &         755      & \\textbf{                     } &               \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &               \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                     & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}       &   -9940.5765  &     2385.347     &    -4.167  &         0.000        &    -1.46e+04    &    -5264.935     \\\\\n",
       "\\textbf{gspilltecIV} &       0.1002  &        0.027     &     3.746  &         0.000        &        0.048    &        0.153     \\\\\n",
       "\\textbf{gspillsicIV} &       0.3399  &        0.049     &     6.902  &         0.000        &        0.243    &        0.436     \\\\\n",
       "\\textbf{pat\\_count}  &     -30.6018  &        1.838     &   -16.652  &         0.000        &      -34.204    &      -26.999     \\\\\n",
       "\\textbf{rsales}      &       0.7812  &        0.037     &    21.055  &         0.000        &        0.708    &        0.854     \\\\\n",
       "\\textbf{rppent}      &       0.6108  &        0.084     &     7.234  &         0.000        &        0.445    &        0.776     \\\\\n",
       "\\textbf{emp}         &      18.0641  &        7.147     &     2.527  &         0.012        &        4.054    &       32.074     \\\\\n",
       "\\textbf{rxrd}        &      18.5941  &        0.614     &    30.295  &         0.000        &       17.391    &       19.797     \\\\\n",
       "\\textbf{1981}        &    -425.5119  &      618.180     &    -0.688  &         0.491        &    -1637.239    &      786.215     \\\\\n",
       "\\textbf{1982}        &    -295.2372  &      616.239     &    -0.479  &         0.632        &    -1503.159    &      912.685     \\\\\n",
       "\\textbf{1983}        &    -294.1870  &      609.557     &    -0.483  &         0.629        &    -1489.011    &      900.637     \\\\\n",
       "\\textbf{1984}        &    -812.2257  &      607.964     &    -1.336  &         0.182        &    -2003.927    &      379.476     \\\\\n",
       "\\textbf{1985}        &    -929.1950  &      609.921     &    -1.523  &         0.128        &    -2124.732    &      266.343     \\\\\n",
       "\\textbf{1986}        &   -1184.5891  &      607.667     &    -1.949  &         0.051        &    -2375.708    &        6.530     \\\\\n",
       "\\textbf{1987}        &   -1372.3041  &      607.937     &    -2.257  &         0.024        &    -2563.953    &     -180.655     \\\\\n",
       "\\textbf{1988}        &   -1686.4878  &      609.953     &    -2.765  &         0.006        &    -2882.088    &     -490.888     \\\\\n",
       "\\textbf{1989}        &   -1550.4891  &      610.972     &    -2.538  &         0.011        &    -2748.088    &     -352.891     \\\\\n",
       "\\textbf{1990}        &   -2052.0735  &      612.118     &    -3.352  &         0.001        &    -3251.918    &     -852.228     \\\\\n",
       "\\textbf{1991}        &   -1629.8854  &      614.732     &    -2.651  &         0.008        &    -2834.854    &     -424.917     \\\\\n",
       "\\textbf{1992}        &   -1754.6866  &      617.583     &    -2.841  &         0.005        &    -2965.243    &     -544.130     \\\\\n",
       "\\textbf{1993}        &   -1685.0176  &      621.230     &    -2.712  &         0.007        &    -2902.723    &     -467.312     \\\\\n",
       "\\textbf{1994}        &   -1916.7490  &      627.407     &    -3.055  &         0.002        &    -3146.563    &     -686.935     \\\\\n",
       "\\textbf{1995}        &   -1380.6021  &      636.986     &    -2.167  &         0.030        &    -2629.191    &     -132.013     \\\\\n",
       "\\textbf{1996}        &   -1098.4502  &      651.099     &    -1.687  &         0.092        &    -2374.702    &      177.802     \\\\\n",
       "\\textbf{1997}        &    -692.3174  &      667.994     &    -1.036  &         0.300        &    -2001.686    &      617.051     \\\\\n",
       "\\textbf{1998}        &    -575.0406  &      687.698     &    -0.836  &         0.403        &    -1923.033    &      772.951     \\\\\n",
       "\\textbf{1999}        &     142.3167  &      710.226     &     0.200  &         0.841        &    -1249.835    &     1534.468     \\\\\n",
       "\\textbf{2000}        &    -207.4580  &      738.322     &    -0.281  &         0.779        &    -1654.682    &     1239.766     \\\\\n",
       "\\textbf{2001}        &   -2283.3834  &      768.945     &    -2.970  &         0.003        &    -3790.633    &     -776.134     \\\\\n",
       "\\textbf{10005.0}     &    8596.1312  &     3076.471     &     2.794  &         0.005        &     2565.781    &     1.46e+04     \\\\\n",
       "\\textbf{10006.0}     &    8240.3993  &     3516.122     &     2.344  &         0.019        &     1348.266    &     1.51e+04     \\\\\n",
       "\\textbf{10008.0}     &    7558.3544  &     3040.531     &     2.486  &         0.013        &     1598.452    &     1.35e+04     \\\\\n",
       "\\textbf{10016.0}     &    8488.3062  &     3060.494     &     2.774  &         0.006        &     2489.273    &     1.45e+04     \\\\\n",
       "\\textbf{10030.0}     &    9963.3568  &     3135.789     &     3.177  &         0.001        &     3816.734    &     1.61e+04     \\\\\n",
       "\\textbf{1004.0}      &    9403.1634  &     3133.966     &     3.000  &         0.003        &     3260.115    &     1.55e+04     \\\\\n",
       "\\textbf{10056.0}     &    7589.4824  &     3061.708     &     2.479  &         0.013        &     1588.069    &     1.36e+04     \\\\\n",
       "\\textbf{10085.0}     &    4090.3185  &     2997.861     &     1.364  &         0.172        &    -1785.945    &     9966.582     \\\\\n",
       "\\textbf{10092.0}     &    9204.1913  &     5393.483     &     1.707  &         0.088        &    -1367.854    &     1.98e+04     \\\\\n",
       "\\textbf{10097.0}     &    2206.4047  &     2993.452     &     0.737  &         0.461        &    -3661.215    &     8074.024     \\\\\n",
       "\\textbf{1010.0}      &    8207.1099  &     5379.135     &     1.526  &         0.127        &    -2336.812    &     1.88e+04     \\\\\n",
       "\\textbf{10109.0}     &    1.097e+04  &     3193.217     &     3.436  &         0.001        &     4711.604    &     1.72e+04     \\\\\n",
       "\\textbf{10115.0}     &    7957.3563  &     3058.537     &     2.602  &         0.009        &     1962.159    &      1.4e+04     \\\\\n",
       "\\textbf{10124.0}     &     1.11e+04  &     3199.490     &     3.470  &         0.001        &     4829.168    &     1.74e+04     \\\\\n",
       "\\textbf{1013.0}      &    4769.1715  &     2983.003     &     1.599  &         0.110        &    -1077.968    &     1.06e+04     \\\\\n",
       "\\textbf{10150.0}     &    3170.2099  &     3465.956     &     0.915  &         0.360        &    -3623.590    &     9964.010     \\\\\n",
       "\\textbf{10159.0}     &    3378.9006  &     4384.246     &     0.771  &         0.441        &    -5214.887    &      1.2e+04     \\\\\n",
       "\\textbf{10174.0}     &    1.021e+04  &     3389.760     &     3.012  &         0.003        &     3565.375    &     1.69e+04     \\\\\n",
       "\\textbf{10185.0}     &    8313.1068  &     3338.064     &     2.490  &         0.013        &     1769.995    &     1.49e+04     \\\\\n",
       "\\textbf{10195.0}     &    2593.7222  &     3141.189     &     0.826  &         0.409        &    -3563.486    &     8750.931     \\\\\n",
       "\\textbf{10198.0}     &    9933.5369  &     3131.022     &     3.173  &         0.002        &     3796.259    &     1.61e+04     \\\\\n",
       "\\textbf{10215.0}     &     1.08e+04  &     3193.341     &     3.381  &         0.001        &     4537.838    &     1.71e+04     \\\\\n",
       "\\textbf{10232.0}     &    6925.4903  &     3326.104     &     2.082  &         0.037        &      405.821    &     1.34e+04     \\\\\n",
       "\\textbf{10236.0}     &    9750.4628  &     3137.458     &     3.108  &         0.002        &     3600.569    &     1.59e+04     \\\\\n",
       "\\textbf{10286.0}     &    8274.2845  &     3121.219     &     2.651  &         0.008        &     2156.221    &     1.44e+04     \\\\\n",
       "\\textbf{10301.0}     &   -1.476e+04  &     3014.308     &    -4.895  &         0.000        &    -2.07e+04    &    -8846.626     \\\\\n",
       "\\textbf{10312.0}     &    9198.1294  &     3124.523     &     2.944  &         0.003        &     3073.591    &     1.53e+04     \\\\\n",
       "\\textbf{10332.0}     &    3868.1997  &     4061.176     &     0.952  &         0.341        &    -4092.322    &     1.18e+04     \\\\\n",
       "\\textbf{1036.0}      &    7245.0618  &     3261.623     &     2.221  &         0.026        &      851.786    &     1.36e+04     \\\\\n",
       "\\textbf{10374.0}     &    8066.1980  &     3065.104     &     2.632  &         0.009        &     2058.129    &     1.41e+04     \\\\\n",
       "\\textbf{10386.0}     &    4140.6626  &     2986.789     &     1.386  &         0.166        &    -1713.897    &     9995.222     \\\\\n",
       "\\textbf{10391.0}     &    1064.5542  &     3026.844     &     0.352  &         0.725        &    -4868.521    &     6997.629     \\\\\n",
       "\\textbf{10407.0}     &    4895.6611  &     3017.572     &     1.622  &         0.105        &    -1019.237    &     1.08e+04     \\\\\n",
       "\\textbf{10420.0}     &    8765.7651  &     3082.897     &     2.843  &         0.004        &     2722.820    &     1.48e+04     \\\\\n",
       "\\textbf{10422.0}     &    6959.5604  &     3252.126     &     2.140  &         0.032        &      584.899    &     1.33e+04     \\\\\n",
       "\\textbf{10426.0}     &    9660.2255  &     3299.137     &     2.928  &         0.003        &     3193.415    &     1.61e+04     \\\\\n",
       "\\textbf{10441.0}     &    1.026e+04  &     3164.254     &     3.241  &         0.001        &     4053.796    &     1.65e+04     \\\\\n",
       "\\textbf{1045.0}      &   -1654.6262  &     3243.965     &    -0.510  &         0.610        &    -8013.291    &     4704.038     \\\\\n",
       "\\textbf{10453.0}     &    4005.2538  &     2991.151     &     1.339  &         0.181        &    -1857.856    &     9868.364     \\\\\n",
       "\\textbf{10482.0}     &    -1.46e+04  &     3475.563     &    -4.201  &         0.000        &    -2.14e+04    &    -7789.183     \\\\\n",
       "\\textbf{10498.0}     &    9301.1887  &     3158.846     &     2.944  &         0.003        &     3109.370    &     1.55e+04     \\\\\n",
       "\\textbf{10499.0}     &     290.8155  &     3069.162     &     0.095  &         0.925        &    -5725.207    &     6306.838     \\\\\n",
       "\\textbf{10511.0}     &    1.071e+04  &     3287.724     &     3.258  &         0.001        &     4268.117    &     1.72e+04     \\\\\n",
       "\\textbf{10519.0}     &   -5675.1567  &     2981.921     &    -1.903  &         0.057        &    -1.15e+04    &      169.862     \\\\\n",
       "\\textbf{10530.0}     &    5301.0836  &     3009.281     &     1.762  &         0.078        &     -597.565    &     1.12e+04     \\\\\n",
       "\\textbf{10537.0}     &    6186.0975  &     3392.545     &     1.823  &         0.068        &     -463.806    &     1.28e+04     \\\\\n",
       "\\textbf{10540.0}     &    7576.5476  &     3032.964     &     2.498  &         0.012        &     1631.477    &     1.35e+04     \\\\\n",
       "\\textbf{10541.0}     &    8964.6580  &     3229.126     &     2.776  &         0.006        &     2635.080    &     1.53e+04     \\\\\n",
       "\\textbf{10550.0}     &    6593.4131  &     6048.079     &     1.090  &         0.276        &    -5261.741    &     1.84e+04     \\\\\n",
       "\\textbf{10553.0}     &    3851.8113  &     3153.072     &     1.222  &         0.222        &    -2328.689    &        1e+04     \\\\\n",
       "\\textbf{10565.0}     &    1.053e+04  &     3138.295     &     3.355  &         0.001        &     4378.941    &     1.67e+04     \\\\\n",
       "\\textbf{10580.0}     &     1.08e+04  &     3213.498     &     3.360  &         0.001        &     4498.657    &     1.71e+04     \\\\\n",
       "\\textbf{10581.0}     &    7665.2631  &     3106.263     &     2.468  &         0.014        &     1576.515    &     1.38e+04     \\\\\n",
       "\\textbf{10588.0}     &    1176.5368  &     2963.147     &     0.397  &         0.691        &    -4631.681    &     6984.754     \\\\\n",
       "\\textbf{10597.0}     &    8900.5001  &     3128.719     &     2.845  &         0.004        &     2767.736    &      1.5e+04     \\\\\n",
       "\\textbf{10599.0}     &    9271.0496  &     3139.906     &     2.953  &         0.003        &     3116.357    &     1.54e+04     \\\\\n",
       "\\textbf{10618.0}     &    8556.4419  &     3093.780     &     2.766  &         0.006        &     2492.162    &     1.46e+04     \\\\\n",
       "\\textbf{10656.0}     &    8664.1385  &     3068.114     &     2.824  &         0.005        &     2650.168    &     1.47e+04     \\\\\n",
       "\\textbf{10658.0}     &    8540.1624  &     3064.938     &     2.786  &         0.005        &     2532.418    &     1.45e+04     \\\\\n",
       "\\textbf{10726.0}     &    1.264e+04  &     3268.775     &     3.866  &         0.000        &     6231.058    &      1.9e+04     \\\\\n",
       "\\textbf{10734.0}     &    8389.8503  &     3727.109     &     2.251  &         0.024        &     1084.150    &     1.57e+04     \\\\\n",
       "\\textbf{10735.0}     &    1.002e+04  &     3173.342     &     3.159  &         0.002        &     3803.931    &     1.62e+04     \\\\\n",
       "\\textbf{10764.0}     &    1.051e+04  &     3276.657     &     3.207  &         0.001        &     4084.421    &     1.69e+04     \\\\\n",
       "\\textbf{10777.0}     &    8530.3531  &     3067.334     &     2.781  &         0.005        &     2517.913    &     1.45e+04     \\\\\n",
       "\\textbf{1078.0}      &    5453.6061  &     3082.313     &     1.769  &         0.077        &     -588.196    &     1.15e+04     \\\\\n",
       "\\textbf{10793.0}     &    8093.7684  &     3137.200     &     2.580  &         0.010        &     1944.380    &     1.42e+04     \\\\\n",
       "\\textbf{10816.0}     &    7496.2748  &     3087.546     &     2.428  &         0.015        &     1444.216    &     1.35e+04     \\\\\n",
       "\\textbf{10839.0}     &    9481.3260  &     3097.020     &     3.061  &         0.002        &     3410.697    &     1.56e+04     \\\\\n",
       "\\textbf{10857.0}     &   -2182.7305  &     3058.140     &    -0.714  &         0.475        &    -8177.148    &     3811.687     \\\\\n",
       "\\textbf{10867.0}     &    4643.9565  &     3339.296     &     1.391  &         0.164        &    -1901.571    &     1.12e+04     \\\\\n",
       "\\textbf{10906.0}     &    8932.4951  &     3098.783     &     2.883  &         0.004        &     2858.410    &      1.5e+04     \\\\\n",
       "\\textbf{10950.0}     &    9034.0200  &     4140.834     &     2.182  &         0.029        &      917.357    &     1.72e+04     \\\\\n",
       "\\textbf{10983.0}     &   -2.383e+04  &     3227.575     &    -7.383  &         0.000        &    -3.02e+04    &    -1.75e+04     \\\\\n",
       "\\textbf{1099.0}      &    8536.2893  &     3106.895     &     2.748  &         0.006        &     2446.304    &     1.46e+04     \\\\\n",
       "\\textbf{10991.0}     &    6926.2901  &     3614.928     &     1.916  &         0.055        &     -159.519    &      1.4e+04     \\\\\n",
       "\\textbf{11012.0}     &    7880.6911  &     3137.824     &     2.512  &         0.012        &     1730.080    &      1.4e+04     \\\\\n",
       "\\textbf{11038.0}     &    3251.3206  &     3219.125     &     1.010  &         0.313        &    -3058.654    &     9561.295     \\\\\n",
       "\\textbf{1104.0}      &    9488.5996  &     3138.344     &     3.023  &         0.003        &     3336.969    &     1.56e+04     \\\\\n",
       "\\textbf{11060.0}     &    9235.2591  &     3132.146     &     2.949  &         0.003        &     3095.777    &     1.54e+04     \\\\\n",
       "\\textbf{11094.0}     &    8684.5592  &     3089.265     &     2.811  &         0.005        &     2629.130    &     1.47e+04     \\\\\n",
       "\\textbf{11096.0}     &    6740.1208  &     3028.318     &     2.226  &         0.026        &      804.158    &     1.27e+04     \\\\\n",
       "\\textbf{11113.0}     &    9316.9328  &     3367.569     &     2.767  &         0.006        &     2715.986    &     1.59e+04     \\\\\n",
       "\\textbf{1115.0}      &    7875.2019  &     3125.463     &     2.520  &         0.012        &     1748.819    &      1.4e+04     \\\\\n",
       "\\textbf{11161.0}     &    6631.5622  &     3048.603     &     2.175  &         0.030        &      655.838    &     1.26e+04     \\\\\n",
       "\\textbf{11225.0}     &    1.031e+04  &     3223.600     &     3.198  &         0.001        &     3991.623    &     1.66e+04     \\\\\n",
       "\\textbf{11228.0}     &    1.001e+04  &     3111.122     &     3.217  &         0.001        &     3909.102    &     1.61e+04     \\\\\n",
       "\\textbf{11236.0}     &    4820.4345  &     4564.449     &     1.056  &         0.291        &    -4126.579    &     1.38e+04     \\\\\n",
       "\\textbf{11288.0}     &     726.5183  &     3139.333     &     0.231  &         0.817        &    -5427.050    &     6880.087     \\\\\n",
       "\\textbf{11312.0}     &     624.6433  &     3085.276     &     0.202  &         0.840        &    -5422.965    &     6672.252     \\\\\n",
       "\\textbf{11361.0}     &    8139.1393  &     3054.443     &     2.665  &         0.008        &     2151.966    &     1.41e+04     \\\\\n",
       "\\textbf{11399.0}     &    1883.4788  &     2984.861     &     0.631  &         0.528        &    -3967.302    &     7734.260     \\\\\n",
       "\\textbf{114303.0}    &   -8981.4766  &     5402.255     &    -1.663  &         0.096        &    -1.96e+04    &     1607.764     \\\\\n",
       "\\textbf{11456.0}     &    3026.3818  &     3078.672     &     0.983  &         0.326        &    -3008.282    &     9061.046     \\\\\n",
       "\\textbf{11465.0}     &    4113.0085  &     3092.455     &     1.330  &         0.184        &    -1948.673    &     1.02e+04     \\\\\n",
       "\\textbf{11502.0}     &    9343.9264  &     3174.590     &     2.943  &         0.003        &     3121.249    &     1.56e+04     \\\\\n",
       "\\textbf{11506.0}     &    4190.2588  &     3073.981     &     1.363  &         0.173        &    -1835.210    &     1.02e+04     \\\\\n",
       "\\textbf{11537.0}     &    9104.8465  &     3090.809     &     2.946  &         0.003        &     3046.392    &     1.52e+04     \\\\\n",
       "\\textbf{11566.0}     &    1.069e+04  &     3188.150     &     3.352  &         0.001        &     4436.526    &     1.69e+04     \\\\\n",
       "\\textbf{11573.0}     &    8122.9750  &     3053.915     &     2.660  &         0.008        &     2136.837    &     1.41e+04     \\\\\n",
       "\\textbf{11580.0}     &    4660.7676  &     3401.528     &     1.370  &         0.171        &    -2006.744    &     1.13e+04     \\\\\n",
       "\\textbf{11600.0}     &    9955.4797  &     3181.578     &     3.129  &         0.002        &     3719.104    &     1.62e+04     \\\\\n",
       "\\textbf{11609.0}     &    1.339e+04  &     3141.316     &     4.263  &         0.000        &     7234.942    &     1.95e+04     \\\\\n",
       "\\textbf{1161.0}      &   -1142.7795  &     2963.636     &    -0.386  &         0.700        &    -6951.956    &     4666.397     \\\\\n",
       "\\textbf{11636.0}     &   -1.033e+04  &     3195.420     &    -3.234  &         0.001        &    -1.66e+04    &    -4069.451     \\\\\n",
       "\\textbf{11670.0}     &    1.045e+04  &     3195.585     &     3.270  &         0.001        &     4186.263    &     1.67e+04     \\\\\n",
       "\\textbf{11678.0}     &    -172.3965  &     3111.159     &    -0.055  &         0.956        &    -6270.740    &     5925.947     \\\\\n",
       "\\textbf{11682.0}     &    8157.6451  &     3195.335     &     2.553  &         0.011        &     1894.303    &     1.44e+04     \\\\\n",
       "\\textbf{11694.0}     &    9735.1845  &     3265.189     &     2.982  &         0.003        &     3334.919    &     1.61e+04     \\\\\n",
       "\\textbf{11720.0}     &    2342.1807  &     3978.963     &     0.589  &         0.556        &    -5457.192    &     1.01e+04     \\\\\n",
       "\\textbf{11721.0}     &   -3708.6926  &     3442.247     &    -1.077  &         0.281        &    -1.05e+04    &     3038.635     \\\\\n",
       "\\textbf{11722.0}     &    7939.5465  &     3308.424     &     2.400  &         0.016        &     1454.532    &     1.44e+04     \\\\\n",
       "\\textbf{11793.0}     &    6392.4048  &     6063.166     &     1.054  &         0.292        &    -5492.321    &     1.83e+04     \\\\\n",
       "\\textbf{11797.0}     &    1.098e+04  &     3552.518     &     3.091  &         0.002        &     4015.910    &     1.79e+04     \\\\\n",
       "\\textbf{11914.0}     &    9253.8306  &     3755.065     &     2.464  &         0.014        &     1893.333    &     1.66e+04     \\\\\n",
       "\\textbf{1209.0}      &    6916.3882  &     3021.090     &     2.289  &         0.022        &      994.593    &     1.28e+04     \\\\\n",
       "\\textbf{12136.0}     &   -5842.3430  &     3290.133     &    -1.776  &         0.076        &    -1.23e+04    &      606.816     \\\\\n",
       "\\textbf{12141.0}     &    8.981e+04  &     3291.619     &    27.284  &         0.000        &     8.34e+04    &     9.63e+04     \\\\\n",
       "\\textbf{12181.0}     &    6468.7957  &     4281.785     &     1.511  &         0.131        &    -1924.153    &     1.49e+04     \\\\\n",
       "\\textbf{12215.0}     &    -753.1168  &     3219.104     &    -0.234  &         0.815        &    -7063.050    &     5556.816     \\\\\n",
       "\\textbf{12216.0}     &    3866.8554  &     3252.277     &     1.189  &         0.234        &    -2508.101    &     1.02e+04     \\\\\n",
       "\\textbf{12256.0}     &    2682.4219  &     3240.915     &     0.828  &         0.408        &    -3670.264    &     9035.107     \\\\\n",
       "\\textbf{12262.0}     &    9564.5090  &     3423.360     &     2.794  &         0.005        &     2854.203    &     1.63e+04     \\\\\n",
       "\\textbf{12389.0}     &    8986.4050  &     3304.204     &     2.720  &         0.007        &     2509.663    &     1.55e+04     \\\\\n",
       "\\textbf{1239.0}      &    6577.3859  &     3030.471     &     2.170  &         0.030        &      637.203    &     1.25e+04     \\\\\n",
       "\\textbf{12390.0}     &    7461.3813  &     3602.948     &     2.071  &         0.038        &      399.057    &     1.45e+04     \\\\\n",
       "\\textbf{12397.0}     &    6292.8548  &     5345.675     &     1.177  &         0.239        &    -4185.481    &     1.68e+04     \\\\\n",
       "\\textbf{1243.0}      &    4184.8534  &     3158.124     &     1.325  &         0.185        &    -2005.548    &     1.04e+04     \\\\\n",
       "\\textbf{12548.0}     &    9038.3456  &     3632.299     &     2.488  &         0.013        &     1918.488    &     1.62e+04     \\\\\n",
       "\\textbf{12570.0}     &    8969.7124  &     3499.499     &     2.563  &         0.010        &     2110.162    &     1.58e+04     \\\\\n",
       "\\textbf{12581.0}     &    6220.9585  &     3679.891     &     1.691  &         0.091        &     -992.187    &     1.34e+04     \\\\\n",
       "\\textbf{12592.0}     &    7907.3965  &     3465.117     &     2.282  &         0.023        &     1115.241    &     1.47e+04     \\\\\n",
       "\\textbf{12604.0}     &    7117.2488  &     6104.480     &     1.166  &         0.244        &    -4848.459    &     1.91e+04     \\\\\n",
       "\\textbf{12656.0}     &    1.071e+04  &     3513.018     &     3.048  &         0.002        &     3822.505    &     1.76e+04     \\\\\n",
       "\\textbf{12679.0}     &   -8243.1620  &     3377.006     &    -2.441  &         0.015        &    -1.49e+04    &    -1623.718     \\\\\n",
       "\\textbf{1278.0}      &    9559.3089  &     3276.729     &     2.917  &         0.004        &     3136.423    &      1.6e+04     \\\\\n",
       "\\textbf{12788.0}     &   -2571.9810  &     3720.888     &    -0.691  &         0.489        &    -9865.486    &     4721.524     \\\\\n",
       "\\textbf{1283.0}      &    9778.5694  &     3188.479     &     3.067  &         0.002        &     3528.666    &      1.6e+04     \\\\\n",
       "\\textbf{1297.0}      &    8851.0971  &     3160.094     &     2.801  &         0.005        &     2656.833    &      1.5e+04     \\\\\n",
       "\\textbf{12992.0}     &    1.022e+04  &     3469.470     &     2.945  &         0.003        &     3415.928    &      1.7e+04     \\\\\n",
       "\\textbf{13135.0}     &    5736.5602  &     3444.412     &     1.665  &         0.096        &    -1015.010    &     1.25e+04     \\\\\n",
       "\\textbf{1327.0}      &    2830.7666  &     3184.260     &     0.889  &         0.374        &    -3410.866    &     9072.399     \\\\\n",
       "\\textbf{13282.0}     &    3707.5355  &     5340.406     &     0.694  &         0.488        &    -6760.470    &     1.42e+04     \\\\\n",
       "\\textbf{1334.0}      &    1959.2153  &     3392.421     &     0.578  &         0.564        &    -4690.446    &     8608.876     \\\\\n",
       "\\textbf{13351.0}     &    3934.9513  &     3942.379     &     0.998  &         0.318        &    -3792.710    &     1.17e+04     \\\\\n",
       "\\textbf{13365.0}     &   -7664.6310  &     3538.787     &    -2.166  &         0.030        &    -1.46e+04    &     -728.070     \\\\\n",
       "\\textbf{13369.0}     &    6192.2784  &     3353.245     &     1.847  &         0.065        &     -380.592    &     1.28e+04     \\\\\n",
       "\\textbf{13406.0}     &    9511.9068  &     3422.019     &     2.780  &         0.005        &     2804.230    &     1.62e+04     \\\\\n",
       "\\textbf{13407.0}     &    3435.2039  &     3325.530     &     1.033  &         0.302        &    -3083.341    &     9953.749     \\\\\n",
       "\\textbf{13417.0}     &    1.054e+04  &     3627.974     &     2.906  &         0.004        &     3431.229    &     1.77e+04     \\\\\n",
       "\\textbf{13525.0}     &    2730.9588  &     3557.222     &     0.768  &         0.443        &    -4241.736    &     9703.654     \\\\\n",
       "\\textbf{13554.0}     &     1.11e+04  &     3515.274     &     3.158  &         0.002        &     4209.150    &      1.8e+04     \\\\\n",
       "\\textbf{1359.0}      &     231.6921  &     3271.221     &     0.071  &         0.944        &    -6180.398    &     6643.783     \\\\\n",
       "\\textbf{13623.0}     &    7757.8946  &     3398.861     &     2.282  &         0.022        &     1095.611    &     1.44e+04     \\\\\n",
       "\\textbf{1372.0}      &    2969.1064  &     3094.408     &     0.960  &         0.337        &    -3096.404    &     9034.616     \\\\\n",
       "\\textbf{1380.0}      &    2428.4690  &     3086.422     &     0.787  &         0.431        &    -3621.386    &     8478.324     \\\\\n",
       "\\textbf{13923.0}     &    9004.3585  &     3723.204     &     2.418  &         0.016        &     1706.314    &     1.63e+04     \\\\\n",
       "\\textbf{13932.0}     &    9906.5945  &     4225.421     &     2.345  &         0.019        &     1624.127    &     1.82e+04     \\\\\n",
       "\\textbf{13941.0}     &    -775.7343  &     3345.291     &    -0.232  &         0.817        &    -7333.012    &     5781.544     \\\\\n",
       "\\textbf{1397.0}      &    7611.2849  &     3344.240     &     2.276  &         0.023        &     1056.066    &     1.42e+04     \\\\\n",
       "\\textbf{14064.0}     &    7822.3534  &     3374.212     &     2.318  &         0.020        &     1208.386    &     1.44e+04     \\\\\n",
       "\\textbf{14084.0}     &    7161.9191  &     3367.382     &     2.127  &         0.033        &      561.340    &     1.38e+04     \\\\\n",
       "\\textbf{14324.0}     &    2450.1067  &     3416.939     &     0.717  &         0.473        &    -4247.612    &     9147.825     \\\\\n",
       "\\textbf{14462.0}     &    5896.9695  &     3424.853     &     1.722  &         0.085        &     -816.263    &     1.26e+04     \\\\\n",
       "\\textbf{1447.0}      &    1.291e+04  &     4617.436     &     2.796  &         0.005        &     3861.195    &      2.2e+04     \\\\\n",
       "\\textbf{14531.0}     &    6013.3098  &        1e+04     &     0.600  &         0.549        &    -1.36e+04    &     2.57e+04     \\\\\n",
       "\\textbf{14593.0}     &    9717.6801  &     3546.928     &     2.740  &         0.006        &     2765.162    &     1.67e+04     \\\\\n",
       "\\textbf{14622.0}     &    8494.5972  &     7256.705     &     1.171  &         0.242        &    -5729.646    &     2.27e+04     \\\\\n",
       "\\textbf{1465.0}      &    9293.7357  &     3759.137     &     2.472  &         0.013        &     1925.257    &     1.67e+04     \\\\\n",
       "\\textbf{1468.0}      &    9813.2527  &     3591.620     &     2.732  &         0.006        &     2773.133    &     1.69e+04     \\\\\n",
       "\\textbf{14897.0}     &    8912.7989  &     5404.388     &     1.649  &         0.099        &    -1680.623    &     1.95e+04     \\\\\n",
       "\\textbf{14954.0}     &    9310.1232  &     3588.857     &     2.594  &         0.009        &     2275.418    &     1.63e+04     \\\\\n",
       "\\textbf{1496.0}      &    1.018e+04  &     3142.118     &     3.241  &         0.001        &     4023.346    &     1.63e+04     \\\\\n",
       "\\textbf{15267.0}     &    8561.1899  &     3545.299     &     2.415  &         0.016        &     1611.865    &     1.55e+04     \\\\\n",
       "\\textbf{15354.0}     &    3951.6292  &     3545.461     &     1.115  &         0.265        &    -2998.013    &     1.09e+04     \\\\\n",
       "\\textbf{1542.0}      &    8274.0285  &     3128.411     &     2.645  &         0.008        &     2141.867    &     1.44e+04     \\\\\n",
       "\\textbf{15459.0}     &    4755.0666  &     3491.964     &     1.362  &         0.173        &    -2089.713    &     1.16e+04     \\\\\n",
       "\\textbf{1554.0}      &    1.008e+04  &     3139.681     &     3.211  &         0.001        &     3928.295    &     1.62e+04     \\\\\n",
       "\\textbf{15708.0}     &   -8685.5979  &     3678.105     &    -2.361  &         0.018        &    -1.59e+04    &    -1475.954     \\\\\n",
       "\\textbf{15711.0}     &    7018.0335  &     3521.077     &     1.993  &         0.046        &      116.187    &     1.39e+04     \\\\\n",
       "\\textbf{15761.0}     &    9603.3202  &     4161.317     &     2.308  &         0.021        &     1446.507    &     1.78e+04     \\\\\n",
       "\\textbf{1581.0}      &   -2.338e+04  &     4066.536     &    -5.750  &         0.000        &    -3.14e+04    &    -1.54e+04     \\\\\n",
       "\\textbf{1593.0}      &    7360.1914  &     3039.605     &     2.421  &         0.015        &     1402.105    &     1.33e+04     \\\\\n",
       "\\textbf{1602.0}      &    1.541e+04  &     3144.958     &     4.899  &         0.000        &     9241.495    &     2.16e+04     \\\\\n",
       "\\textbf{1613.0}      &    9518.7977  &     3135.907     &     3.035  &         0.002        &     3371.944    &     1.57e+04     \\\\\n",
       "\\textbf{16188.0}     &    6141.7233  &     3600.100     &     1.706  &         0.088        &     -915.020    &     1.32e+04     \\\\\n",
       "\\textbf{1632.0}      &    2730.6569  &     2967.596     &     0.920  &         0.358        &    -3086.281    &     8547.595     \\\\\n",
       "\\textbf{1633.0}      &    7645.1535  &     3073.458     &     2.487  &         0.013        &     1620.710    &     1.37e+04     \\\\\n",
       "\\textbf{1635.0}      &   -2279.6622  &     3207.382     &    -0.711  &         0.477        &    -8566.618    &     4007.294     \\\\\n",
       "\\textbf{16401.0}     &   -2106.7953  &     3535.255     &    -0.596  &         0.551        &    -9036.432    &     4822.842     \\\\\n",
       "\\textbf{16437.0}     &    2453.7358  &     4040.565     &     0.607  &         0.544        &    -5466.386    &     1.04e+04     \\\\\n",
       "\\textbf{1651.0}      &    5550.2093  &     3015.031     &     1.841  &         0.066        &     -359.709    &     1.15e+04     \\\\\n",
       "\\textbf{1655.0}      &    9615.4742  &     3116.290     &     3.086  &         0.002        &     3507.073    &     1.57e+04     \\\\\n",
       "\\textbf{1663.0}      &    1.375e+04  &     3117.223     &     4.412  &         0.000        &     7643.430    &     1.99e+04     \\\\\n",
       "\\textbf{16710.0}     &    4741.7051  &     3561.723     &     1.331  &         0.183        &    -2239.813    &     1.17e+04     \\\\\n",
       "\\textbf{16729.0}     &    4221.0150  &     3488.991     &     1.210  &         0.226        &    -2617.938    &     1.11e+04     \\\\\n",
       "\\textbf{1690.0}      &   -9476.8601  &     3052.010     &    -3.105  &         0.002        &    -1.55e+04    &    -3494.457     \\\\\n",
       "\\textbf{1703.0}      &    7131.1531  &     3145.834     &     2.267  &         0.023        &      964.841    &     1.33e+04     \\\\\n",
       "\\textbf{17101.0}     &   -1.039e+04  &     1.02e+04     &    -1.021  &         0.307        &    -3.04e+04    &     9567.672     \\\\\n",
       "\\textbf{17202.0}     &    8565.2847  &     3580.793     &     2.392  &         0.017        &     1546.386    &     1.56e+04     \\\\\n",
       "\\textbf{1722.0}      &    7635.3384  &     3120.097     &     2.447  &         0.014        &     1519.474    &     1.38e+04     \\\\\n",
       "\\textbf{1728.0}      &    9786.0208  &     3133.400     &     3.123  &         0.002        &     3644.082    &     1.59e+04     \\\\\n",
       "\\textbf{1743.0}      &    9206.6002  &     4065.126     &     2.265  &         0.024        &     1238.335    &     1.72e+04     \\\\\n",
       "\\textbf{1754.0}      &    9356.9783  &     3245.442     &     2.883  &         0.004        &     2995.419    &     1.57e+04     \\\\\n",
       "\\textbf{1762.0}      &    3530.4584  &     3070.682     &     1.150  &         0.250        &    -2488.544    &     9549.461     \\\\\n",
       "\\textbf{1773.0}      &    9383.6572  &     3200.790     &     2.932  &         0.003        &     3109.623    &     1.57e+04     \\\\\n",
       "\\textbf{1786.0}      &   -2446.1653  &     3027.221     &    -0.808  &         0.419        &    -8379.979    &     3487.648     \\\\\n",
       "\\textbf{18100.0}     &    7610.5863  &     3547.409     &     2.145  &         0.032        &      657.126    &     1.46e+04     \\\\\n",
       "\\textbf{1820.0}      &    7035.3148  &     3094.333     &     2.274  &         0.023        &      969.953    &     1.31e+04     \\\\\n",
       "\\textbf{1848.0}      &   -1341.5977  &     3489.590     &    -0.384  &         0.701        &    -8181.724    &     5498.529     \\\\\n",
       "\\textbf{18654.0}     &    9308.6209  &     4398.704     &     2.116  &         0.034        &      686.493    &     1.79e+04     \\\\\n",
       "\\textbf{1875.0}      &    5422.0706  &     4559.415     &     1.189  &         0.234        &    -3515.075    &     1.44e+04     \\\\\n",
       "\\textbf{1884.0}      &    9556.3065  &     3257.766     &     2.933  &         0.003        &     3170.590    &     1.59e+04     \\\\\n",
       "\\textbf{1913.0}      &    5067.5445  &     3013.058     &     1.682  &         0.093        &     -838.507    &      1.1e+04     \\\\\n",
       "\\textbf{1919.0}      &    8460.0632  &     3225.767     &     2.623  &         0.009        &     2137.070    &     1.48e+04     \\\\\n",
       "\\textbf{1920.0}      &    5677.3684  &     2997.340     &     1.894  &         0.058        &     -197.872    &     1.16e+04     \\\\\n",
       "\\textbf{1968.0}      &    7609.1915  &     3040.834     &     2.502  &         0.012        &     1648.695    &     1.36e+04     \\\\\n",
       "\\textbf{1976.0}      &    1.067e+04  &     3116.261     &     3.425  &         0.001        &     4565.380    &     1.68e+04     \\\\\n",
       "\\textbf{1981.0}      &    9170.2560  &     3119.840     &     2.939  &         0.003        &     3054.895    &     1.53e+04     \\\\\n",
       "\\textbf{1988.0}      &      67.7686  &     3946.416     &     0.017  &         0.986        &    -7667.806    &     7803.344     \\\\\n",
       "\\textbf{1992.0}      &    7764.2033  &     3046.140     &     2.549  &         0.011        &     1793.305    &     1.37e+04     \\\\\n",
       "\\textbf{2008.0}      &    8115.3533  &     3045.881     &     2.664  &         0.008        &     2144.965    &     1.41e+04     \\\\\n",
       "\\textbf{2033.0}      &    9191.5623  &     3578.712     &     2.568  &         0.010        &     2176.744    &     1.62e+04     \\\\\n",
       "\\textbf{2044.0}      &    7375.6500  &     3054.171     &     2.415  &         0.016        &     1389.011    &     1.34e+04     \\\\\n",
       "\\textbf{2049.0}      &    7958.9282  &     3057.521     &     2.603  &         0.009        &     1965.724    &      1.4e+04     \\\\\n",
       "\\textbf{2061.0}      &    1.067e+04  &     3184.425     &     3.350  &         0.001        &     4425.887    &     1.69e+04     \\\\\n",
       "\\textbf{20779.0}     &    5.298e+04  &     3626.010     &    14.611  &         0.000        &     4.59e+04    &     6.01e+04     \\\\\n",
       "\\textbf{2085.0}      &   -2797.9037  &     3091.351     &    -0.905  &         0.365        &    -8857.420    &     3261.613     \\\\\n",
       "\\textbf{2086.0}      &    6298.7693  &     3040.273     &     2.072  &         0.038        &      339.373    &     1.23e+04     \\\\\n",
       "\\textbf{2111.0}      &    7111.0506  &     3027.347     &     2.349  &         0.019        &     1176.992    &      1.3e+04     \\\\\n",
       "\\textbf{21204.0}     &    5065.4342  &     3773.658     &     1.342  &         0.180        &    -2331.508    &     1.25e+04     \\\\\n",
       "\\textbf{21238.0}     &    9630.2308  &     3715.731     &     2.592  &         0.010        &     2346.833    &     1.69e+04     \\\\\n",
       "\\textbf{2124.0}      &    7814.7292  &     3156.973     &     2.475  &         0.013        &     1626.582    &      1.4e+04     \\\\\n",
       "\\textbf{2146.0}      &    1.782e+04  &     3967.047     &     4.493  &         0.000        &        1e+04    &     2.56e+04     \\\\\n",
       "\\textbf{21496.0}     &   -9707.4783  &     3795.661     &    -2.558  &         0.011        &    -1.71e+04    &    -2267.406     \\\\\n",
       "\\textbf{2154.0}      &    8531.2191  &     3092.395     &     2.759  &         0.006        &     2469.654    &     1.46e+04     \\\\\n",
       "\\textbf{2176.0}      &    4.917e+04  &     3655.506     &    13.450  &         0.000        &      4.2e+04    &     5.63e+04     \\\\\n",
       "\\textbf{2188.0}      &    1.064e+04  &     3272.692     &     3.252  &         0.001        &     4229.171    &     1.71e+04     \\\\\n",
       "\\textbf{2189.0}      &    1987.7047  &     3044.824     &     0.653  &         0.514        &    -3980.612    &     7956.022     \\\\\n",
       "\\textbf{2220.0}      &    8121.7655  &     3066.803     &     2.648  &         0.008        &     2110.366    &     1.41e+04     \\\\\n",
       "\\textbf{22205.0}     &    1.097e+04  &     3742.158     &     2.932  &         0.003        &     3635.194    &     1.83e+04     \\\\\n",
       "\\textbf{2226.0}      &    6564.1694  &     6056.783     &     1.084  &         0.278        &    -5308.045    &     1.84e+04     \\\\\n",
       "\\textbf{2230.0}      &    9663.4059  &     3448.942     &     2.802  &         0.005        &     2902.955    &     1.64e+04     \\\\\n",
       "\\textbf{22325.0}     &    2036.3731  &     3623.720     &     0.562  &         0.574        &    -5066.669    &     9139.415     \\\\\n",
       "\\textbf{2255.0}      &    7276.8607  &     3077.041     &     2.365  &         0.018        &     1245.393    &     1.33e+04     \\\\\n",
       "\\textbf{22619.0}     &    9459.5788  &     3864.126     &     2.448  &         0.014        &     1885.306    &      1.7e+04     \\\\\n",
       "\\textbf{2267.0}      &    1604.9439  &     3063.270     &     0.524  &         0.600        &    -4399.530    &     7609.418     \\\\\n",
       "\\textbf{22815.0}     &    4875.5667  &     3570.634     &     1.365  &         0.172        &    -2123.419    &     1.19e+04     \\\\\n",
       "\\textbf{2285.0}      &   -2.061e+04  &     3176.312     &    -6.490  &         0.000        &    -2.68e+04    &    -1.44e+04     \\\\\n",
       "\\textbf{2290.0}      &    4219.0616  &     3064.579     &     1.377  &         0.169        &    -1787.979    &     1.02e+04     \\\\\n",
       "\\textbf{2295.0}      &     1.02e+04  &     4631.605     &     2.202  &         0.028        &     1118.124    &     1.93e+04     \\\\\n",
       "\\textbf{2316.0}      &    3932.7481  &     3268.816     &     1.203  &         0.229        &    -2474.628    &     1.03e+04     \\\\\n",
       "\\textbf{23220.0}     &    7708.2043  &     3613.811     &     2.133  &         0.033        &      624.587    &     1.48e+04     \\\\\n",
       "\\textbf{23224.0}     &   -1416.5488  &     3999.474     &    -0.354  &         0.723        &    -9256.124    &     6423.027     \\\\\n",
       "\\textbf{2343.0}      &     371.2913  &     5445.150     &     0.068  &         0.946        &    -1.03e+04    &      1.1e+04     \\\\\n",
       "\\textbf{2352.0}      &    7033.5174  &     3195.255     &     2.201  &         0.028        &      770.332    &     1.33e+04     \\\\\n",
       "\\textbf{23700.0}     &   -4104.2067  &     4540.832     &    -0.904  &         0.366        &     -1.3e+04    &     4796.514     \\\\\n",
       "\\textbf{2390.0}      &    1.022e+04  &     3146.886     &     3.249  &         0.001        &     4054.843    &     1.64e+04     \\\\\n",
       "\\textbf{2393.0}      &    5256.7276  &     3021.333     &     1.740  &         0.082        &     -665.543    &     1.12e+04     \\\\\n",
       "\\textbf{2403.0}      &    1.544e+04  &     3116.842     &     4.954  &         0.000        &     9331.361    &     2.16e+04     \\\\\n",
       "\\textbf{2435.0}      &    1.204e+04  &     3215.430     &     3.744  &         0.000        &     5734.523    &     1.83e+04     \\\\\n",
       "\\textbf{2444.0}      &    5543.3070  &     3031.522     &     1.829  &         0.067        &     -398.936    &     1.15e+04     \\\\\n",
       "\\textbf{2448.0}      &    7626.0071  &     3053.285     &     2.498  &         0.013        &     1641.104    &     1.36e+04     \\\\\n",
       "\\textbf{2469.0}      &    9427.6259  &     4407.154     &     2.139  &         0.032        &      788.935    &     1.81e+04     \\\\\n",
       "\\textbf{24720.0}     &    8470.8001  &     3726.615     &     2.273  &         0.023        &     1166.069    &     1.58e+04     \\\\\n",
       "\\textbf{24800.0}     &    2679.9470  &     3896.093     &     0.688  &         0.492        &    -4956.987    &     1.03e+04     \\\\\n",
       "\\textbf{2482.0}      &    1.036e+04  &     3154.774     &     3.283  &         0.001        &     4172.094    &     1.65e+04     \\\\\n",
       "\\textbf{24969.0}     &     1.01e+04  &     4399.409     &     2.296  &         0.022        &     1476.724    &     1.87e+04     \\\\\n",
       "\\textbf{2498.0}      &    2822.1067  &     3205.564     &     0.880  &         0.379        &    -3461.286    &     9105.499     \\\\\n",
       "\\textbf{2504.0}      &   -5740.6155  &     3125.446     &    -1.837  &         0.066        &    -1.19e+04    &      385.734     \\\\\n",
       "\\textbf{2508.0}      &    9551.1213  &     3313.820     &     2.882  &         0.004        &     3055.530    &      1.6e+04     \\\\\n",
       "\\textbf{25124.0}     &    8839.2099  &     3850.901     &     2.295  &         0.022        &     1290.860    &     1.64e+04     \\\\\n",
       "\\textbf{2518.0}      &    9462.2606  &     3118.179     &     3.035  &         0.002        &     3350.156    &     1.56e+04     \\\\\n",
       "\\textbf{25224.0}     &    9181.2871  &     7262.529     &     1.264  &         0.206        &    -5054.373    &     2.34e+04     \\\\\n",
       "\\textbf{25279.0}     &    8309.3827  &     3823.370     &     2.173  &         0.030        &      814.996    &     1.58e+04     \\\\\n",
       "\\textbf{2537.0}      &   -1331.6614  &     3141.364     &    -0.424  &         0.672        &    -7489.212    &     4825.889     \\\\\n",
       "\\textbf{2538.0}      &    1.059e+04  &     4051.182     &     2.615  &         0.009        &     2653.302    &     1.85e+04     \\\\\n",
       "\\textbf{25389.0}     &    1.016e+04  &     6108.961     &     1.663  &         0.096        &    -1815.943    &     2.21e+04     \\\\\n",
       "\\textbf{2547.0}      &    1402.5130  &     3210.761     &     0.437  &         0.662        &    -4891.066    &     7696.092     \\\\\n",
       "\\textbf{2553.0}      &    9104.4999  &     3154.705     &     2.886  &         0.004        &     2920.799    &     1.53e+04     \\\\\n",
       "\\textbf{2574.0}      &    2817.6652  &     3621.446     &     0.778  &         0.437        &    -4280.919    &     9916.249     \\\\\n",
       "\\textbf{25747.0}     &    8887.4249  &     3853.652     &     2.306  &         0.021        &     1333.682    &     1.64e+04     \\\\\n",
       "\\textbf{2577.0}      &    7333.8930  &     3033.785     &     2.417  &         0.016        &     1387.213    &     1.33e+04     \\\\\n",
       "\\textbf{2593.0}      &    7608.5207  &     3056.291     &     2.489  &         0.013        &     1617.727    &     1.36e+04     \\\\\n",
       "\\textbf{2596.0}      &    7104.2843  &     3165.531     &     2.244  &         0.025        &      899.363    &     1.33e+04     \\\\\n",
       "\\textbf{2663.0}      &    1.201e+04  &     3109.709     &     3.862  &         0.000        &     5914.315    &     1.81e+04     \\\\\n",
       "\\textbf{2771.0}      &    7170.4426  &     3157.640     &     2.271  &         0.023        &      980.989    &     1.34e+04     \\\\\n",
       "\\textbf{2787.0}      &    8843.2302  &     3108.248     &     2.845  &         0.004        &     2750.591    &     1.49e+04     \\\\\n",
       "\\textbf{2797.0}      &   -1136.7600  &     3047.444     &    -0.373  &         0.709        &    -7110.213    &     4836.693     \\\\\n",
       "\\textbf{2802.0}      &    9981.2391  &     3145.382     &     3.173  &         0.002        &     3815.813    &     1.61e+04     \\\\\n",
       "\\textbf{2817.0}      &   -2423.3733  &     3105.183     &    -0.780  &         0.435        &    -8510.003    &     3663.257     \\\\\n",
       "\\textbf{28678.0}     &   -6800.8821  &     3938.721     &    -1.727  &         0.084        &    -1.45e+04    &      919.610     \\\\\n",
       "\\textbf{28701.0}     &    7289.6069  &     3122.789     &     2.334  &         0.020        &     1168.466    &     1.34e+04     \\\\\n",
       "\\textbf{28742.0}     &   -4379.2282  &     4023.812     &    -1.088  &         0.276        &    -1.23e+04    &     3508.053     \\\\\n",
       "\\textbf{2888.0}      &    8333.3928  &     3213.797     &     2.593  &         0.010        &     2033.862    &     1.46e+04     \\\\\n",
       "\\textbf{2897.0}      &    9522.3975  &     3838.939     &     2.480  &         0.013        &     1997.494    &      1.7e+04     \\\\\n",
       "\\textbf{2917.0}      &    4179.7509  &     3174.337     &     1.317  &         0.188        &    -2042.431    &     1.04e+04     \\\\\n",
       "\\textbf{29392.0}     &   -4484.0845  &     3895.740     &    -1.151  &         0.250        &    -1.21e+04    &     3152.158     \\\\\n",
       "\\textbf{2950.0}      &   -8939.5631  &     4197.529     &    -2.130  &         0.033        &    -1.72e+04    &     -711.769     \\\\\n",
       "\\textbf{2951.0}      &    1.053e+04  &     3554.152     &     2.964  &         0.003        &     3567.561    &     1.75e+04     \\\\\n",
       "\\textbf{2953.0}      &    8670.7332  &     3081.692     &     2.814  &         0.005        &     2630.148    &     1.47e+04     \\\\\n",
       "\\textbf{2960.0}      &    6927.1661  &     3807.516     &     1.819  &         0.069        &     -536.143    &     1.44e+04     \\\\\n",
       "\\textbf{2975.0}      &    4129.9550  &     3074.147     &     1.343  &         0.179        &    -1895.841    &     1.02e+04     \\\\\n",
       "\\textbf{2982.0}      &    8607.4496  &     3114.061     &     2.764  &         0.006        &     2503.416    &     1.47e+04     \\\\\n",
       "\\textbf{2991.0}      &   -2091.3592  &     3611.129     &    -0.579  &         0.563        &    -9169.721    &     4987.002     \\\\\n",
       "\\textbf{3011.0}      &     352.0291  &     3228.393     &     0.109  &         0.913        &    -5976.112    &     6680.170     \\\\\n",
       "\\textbf{3015.0}      &    1.066e+04  &     3189.868     &     3.341  &         0.001        &     4404.847    &     1.69e+04     \\\\\n",
       "\\textbf{3026.0}      &    8297.5216  &     3114.849     &     2.664  &         0.008        &     2191.944    &     1.44e+04     \\\\\n",
       "\\textbf{3031.0}      &   -7156.8279  &     3963.813     &    -1.806  &         0.071        &    -1.49e+04    &      612.847     \\\\\n",
       "\\textbf{3062.0}      &    1.013e+04  &     3216.055     &     3.150  &         0.002        &     3827.484    &     1.64e+04     \\\\\n",
       "\\textbf{3093.0}      &    4614.1396  &     3380.925     &     1.365  &         0.172        &    -2012.986    &     1.12e+04     \\\\\n",
       "\\textbf{3107.0}      &    8261.4341  &     4593.460     &     1.799  &         0.072        &     -742.444    &     1.73e+04     \\\\\n",
       "\\textbf{3121.0}      &    1.075e+04  &     3100.529     &     3.467  &         0.001        &     4670.905    &     1.68e+04     \\\\\n",
       "\\textbf{3126.0}      &    8639.8575  &     3074.886     &     2.810  &         0.005        &     2612.613    &     1.47e+04     \\\\\n",
       "\\textbf{3144.0}      &    6.167e+04  &     3143.112     &    19.622  &         0.000        &     5.55e+04    &     6.78e+04     \\\\\n",
       "\\textbf{3156.0}      &    9057.0292  &     3556.046     &     2.547  &         0.011        &     2086.640    &      1.6e+04     \\\\\n",
       "\\textbf{3157.0}      &    8487.6305  &     3086.887     &     2.750  &         0.006        &     2436.864    &     1.45e+04     \\\\\n",
       "\\textbf{3170.0}      &    1.112e+04  &     3070.843     &     3.621  &         0.000        &     5098.953    &     1.71e+04     \\\\\n",
       "\\textbf{3178.0}      &    4719.2301  &     3279.399     &     1.439  &         0.150        &    -1708.889    &     1.11e+04     \\\\\n",
       "\\textbf{3206.0}      &    5242.4391  &     3326.387     &     1.576  &         0.115        &    -1277.785    &     1.18e+04     \\\\\n",
       "\\textbf{3229.0}      &    6940.2745  &     3201.204     &     2.168  &         0.030        &      665.428    &     1.32e+04     \\\\\n",
       "\\textbf{3235.0}      &    8557.6434  &     3259.016     &     2.626  &         0.009        &     2169.477    &     1.49e+04     \\\\\n",
       "\\textbf{3246.0}      &    8959.3648  &     3141.052     &     2.852  &         0.004        &     2802.426    &     1.51e+04     \\\\\n",
       "\\textbf{3248.0}      &    8795.1454  &     3144.903     &     2.797  &         0.005        &     2630.657    &      1.5e+04     \\\\\n",
       "\\textbf{3282.0}      &   -1.882e+04  &     3179.239     &    -5.919  &         0.000        &     -2.5e+04    &    -1.26e+04     \\\\\n",
       "\\textbf{3362.0}      &    1467.2473  &     3430.530     &     0.428  &         0.669        &    -5257.112    &     8191.606     \\\\\n",
       "\\textbf{3372.0}      &    8967.9006  &     3615.991     &     2.480  &         0.013        &     1880.009    &     1.61e+04     \\\\\n",
       "\\textbf{3422.0}      &    8150.3780  &     3116.503     &     2.615  &         0.009        &     2041.559    &     1.43e+04     \\\\\n",
       "\\textbf{3497.0}      &    3305.8909  &     3020.187     &     1.095  &         0.274        &    -2614.134    &     9225.916     \\\\\n",
       "\\textbf{3502.0}      &    4413.0364  &     3019.260     &     1.462  &         0.144        &    -1505.172    &     1.03e+04     \\\\\n",
       "\\textbf{3504.0}      &    7330.3624  &     3693.007     &     1.985  &         0.047        &       91.508    &     1.46e+04     \\\\\n",
       "\\textbf{3505.0}      &    6509.4875  &     3039.592     &     2.142  &         0.032        &      551.425    &     1.25e+04     \\\\\n",
       "\\textbf{3532.0}      &    9367.0102  &     3036.064     &     3.085  &         0.002        &     3415.864    &     1.53e+04     \\\\\n",
       "\\textbf{3574.0}      &    9567.2283  &     4941.074     &     1.936  &         0.053        &     -118.027    &     1.93e+04     \\\\\n",
       "\\textbf{3580.0}      &    5668.8773  &     3023.668     &     1.875  &         0.061        &     -257.971    &     1.16e+04     \\\\\n",
       "\\textbf{3612.0}      &    1.077e+04  &     3190.707     &     3.376  &         0.001        &     4518.562    &      1.7e+04     \\\\\n",
       "\\textbf{3619.0}      &    7583.6331  &     3125.470     &     2.426  &         0.015        &     1457.238    &     1.37e+04     \\\\\n",
       "\\textbf{3622.0}      &    1.024e+04  &     3247.561     &     3.154  &         0.002        &     3877.236    &     1.66e+04     \\\\\n",
       "\\textbf{3639.0}      &     701.7362  &     2978.785     &     0.236  &         0.814        &    -5137.134    &     6540.606     \\\\\n",
       "\\textbf{3650.0}      &     -56.5141  &     3013.203     &    -0.019  &         0.985        &    -5962.849    &     5849.821     \\\\\n",
       "\\textbf{3662.0}      &    6515.3615  &     3036.473     &     2.146  &         0.032        &      563.413    &     1.25e+04     \\\\\n",
       "\\textbf{3734.0}      &   -4540.5498  &     3009.478     &    -1.509  &         0.131        &    -1.04e+04    &     1358.485     \\\\\n",
       "\\textbf{3735.0}      &    5998.0243  &     3363.381     &     1.783  &         0.075        &     -594.714    &     1.26e+04     \\\\\n",
       "\\textbf{3761.0}      &    4676.2483  &     3019.021     &     1.549  &         0.121        &    -1241.491    &     1.06e+04     \\\\\n",
       "\\textbf{3779.0}      &   -1115.3957  &     3351.604     &    -0.333  &         0.739        &    -7685.049    &     5454.258     \\\\\n",
       "\\textbf{3781.0}      &    3388.6729  &     3657.813     &     0.926  &         0.354        &    -3781.196    &     1.06e+04     \\\\\n",
       "\\textbf{3782.0}      &    -945.5519  &     3097.134     &    -0.305  &         0.760        &    -7016.405    &     5125.302     \\\\\n",
       "\\textbf{3786.0}      &    8059.2754  &     3095.380     &     2.604  &         0.009        &     1991.860    &     1.41e+04     \\\\\n",
       "\\textbf{3796.0}      &   -1921.4741  &     3437.318     &    -0.559  &         0.576        &    -8659.140    &     4816.192     \\\\\n",
       "\\textbf{3821.0}      &    9374.5415  &     3182.442     &     2.946  &         0.003        &     3136.471    &     1.56e+04     \\\\\n",
       "\\textbf{3835.0}      &    1623.3259  &     3068.940     &     0.529  &         0.597        &    -4392.263    &     7638.914     \\\\\n",
       "\\textbf{3839.0}      &    5038.7123  &     3787.676     &     1.330  &         0.183        &    -2385.707    &     1.25e+04     \\\\\n",
       "\\textbf{3840.0}      &    3096.0560  &     3106.065     &     0.997  &         0.319        &    -2992.302    &     9184.414     \\\\\n",
       "\\textbf{3895.0}      &    9436.3688  &     3115.660     &     3.029  &         0.002        &     3329.202    &     1.55e+04     \\\\\n",
       "\\textbf{3908.0}      &    6499.5003  &     4150.425     &     1.566  &         0.117        &    -1635.964    &     1.46e+04     \\\\\n",
       "\\textbf{3911.0}      &    3978.4256  &     3062.447     &     1.299  &         0.194        &    -2024.435    &     9981.286     \\\\\n",
       "\\textbf{3917.0}      &    9644.8467  &     3201.184     &     3.013  &         0.003        &     3370.040    &     1.59e+04     \\\\\n",
       "\\textbf{3946.0}      &     1.02e+04  &     3163.781     &     3.224  &         0.001        &     3997.651    &     1.64e+04     \\\\\n",
       "\\textbf{3971.0}      &    8857.9912  &     3190.900     &     2.776  &         0.006        &     2603.342    &     1.51e+04     \\\\\n",
       "\\textbf{3980.0}      &    1.889e+04  &     3114.804     &     6.066  &         0.000        &     1.28e+04    &      2.5e+04     \\\\\n",
       "\\textbf{4034.0}      &    5433.4828  &     3023.927     &     1.797  &         0.072        &     -493.873    &     1.14e+04     \\\\\n",
       "\\textbf{4036.0}      &    1.006e+04  &     3132.064     &     3.210  &         0.001        &     3915.798    &     1.62e+04     \\\\\n",
       "\\textbf{4040.0}      &    4402.5134  &     3085.061     &     1.427  &         0.154        &    -1644.674    &     1.04e+04     \\\\\n",
       "\\textbf{4058.0}      &    8496.1476  &     3074.049     &     2.764  &         0.006        &     2470.545    &     1.45e+04     \\\\\n",
       "\\textbf{4060.0}      &   -8502.7681  &     3085.688     &    -2.756  &         0.006        &    -1.46e+04    &    -2454.351     \\\\\n",
       "\\textbf{4062.0}      &    1.245e+04  &     3186.197     &     3.906  &         0.000        &     6200.250    &     1.87e+04     \\\\\n",
       "\\textbf{4077.0}      &    8049.1131  &     4325.812     &     1.861  &         0.063        &     -430.135    &     1.65e+04     \\\\\n",
       "\\textbf{4087.0}      &   -1.922e+04  &     3417.870     &    -5.622  &         0.000        &    -2.59e+04    &    -1.25e+04     \\\\\n",
       "\\textbf{4091.0}      &    7764.4934  &     3536.914     &     2.195  &         0.028        &      831.604    &     1.47e+04     \\\\\n",
       "\\textbf{4127.0}      &    3991.2384  &     2983.946     &     1.338  &         0.181        &    -1857.749    &     9840.226     \\\\\n",
       "\\textbf{4138.0}      &    1.012e+04  &     3751.511     &     2.696  &         0.007        &     2761.757    &     1.75e+04     \\\\\n",
       "\\textbf{4162.0}      &    8848.7229  &     3711.438     &     2.384  &         0.017        &     1573.741    &     1.61e+04     \\\\\n",
       "\\textbf{4186.0}      &    1.029e+04  &     3147.338     &     3.271  &         0.001        &     4124.177    &     1.65e+04     \\\\\n",
       "\\textbf{4194.0}      &    -206.5396  &     3254.206     &    -0.063  &         0.949        &    -6585.277    &     6172.197     \\\\\n",
       "\\textbf{4199.0}      &   -3080.7950  &     2986.731     &    -1.031  &         0.302        &    -8935.242    &     2773.652     \\\\\n",
       "\\textbf{4213.0}      &    9040.9619  &     3063.929     &     2.951  &         0.003        &     3035.197    &      1.5e+04     \\\\\n",
       "\\textbf{4222.0}      &    -427.7763  &     3036.691     &    -0.141  &         0.888        &    -6380.151    &     5524.598     \\\\\n",
       "\\textbf{4223.0}      &    8795.2266  &     3075.179     &     2.860  &         0.004        &     2767.409    &     1.48e+04     \\\\\n",
       "\\textbf{4251.0}      &    9920.6121  &     3135.291     &     3.164  &         0.002        &     3774.966    &     1.61e+04     \\\\\n",
       "\\textbf{4265.0}      &    8311.0668  &     3331.549     &     2.495  &         0.013        &     1780.724    &     1.48e+04     \\\\\n",
       "\\textbf{4274.0}      &    7457.4585  &     3194.105     &     2.335  &         0.020        &     1196.528    &     1.37e+04     \\\\\n",
       "\\textbf{4321.0}      &    5939.8774  &     3058.043     &     1.942  &         0.052        &      -54.352    &     1.19e+04     \\\\\n",
       "\\textbf{4335.0}      &    7276.7703  &     4582.157     &     1.588  &         0.112        &    -1704.953    &     1.63e+04     \\\\\n",
       "\\textbf{4340.0}      &    6243.3898  &     3049.262     &     2.048  &         0.041        &      266.372    &     1.22e+04     \\\\\n",
       "\\textbf{4371.0}      &    6746.0318  &     3081.412     &     2.189  &         0.029        &      705.997    &     1.28e+04     \\\\\n",
       "\\textbf{4415.0}      &    9237.0407  &     3230.539     &     2.859  &         0.004        &     2904.693    &     1.56e+04     \\\\\n",
       "\\textbf{4450.0}      &    7979.6767  &     3101.329     &     2.573  &         0.010        &     1900.602    &     1.41e+04     \\\\\n",
       "\\textbf{4476.0}      &     675.3081  &     3174.296     &     0.213  &         0.832        &    -5546.793    &     6897.409     \\\\\n",
       "\\textbf{4510.0}      &    2475.6995  &     3026.171     &     0.818  &         0.413        &    -3456.054    &     8407.453     \\\\\n",
       "\\textbf{4520.0}      &    7980.2863  &     3051.589     &     2.615  &         0.009        &     1998.708    &      1.4e+04     \\\\\n",
       "\\textbf{4551.0}      &    8011.4429  &     7270.601     &     1.102  &         0.271        &    -6240.039    &     2.23e+04     \\\\\n",
       "\\textbf{4568.0}      &    8842.8576  &     3229.403     &     2.738  &         0.006        &     2512.738    &     1.52e+04     \\\\\n",
       "\\textbf{4579.0}      &    1.065e+04  &     3189.762     &     3.338  &         0.001        &     4393.423    &     1.69e+04     \\\\\n",
       "\\textbf{4585.0}      &    1.003e+04  &     3206.938     &     3.129  &         0.002        &     3747.041    &     1.63e+04     \\\\\n",
       "\\textbf{4595.0}      &    6865.7401  &     3039.451     &     2.259  &         0.024        &      907.954    &     1.28e+04     \\\\\n",
       "\\textbf{4600.0}      &    1012.0246  &     3200.037     &     0.316  &         0.752        &    -5260.535    &     7284.584     \\\\\n",
       "\\textbf{4607.0}      &    9896.4315  &     3136.909     &     3.155  &         0.002        &     3747.613    &      1.6e+04     \\\\\n",
       "\\textbf{4608.0}      &    1926.7708  &     3084.280     &     0.625  &         0.532        &    -4118.886    &     7972.428     \\\\\n",
       "\\textbf{4622.0}      &    5050.9157  &     3012.296     &     1.677  &         0.094        &     -853.642    &      1.1e+04     \\\\\n",
       "\\textbf{4623.0}      &    9205.2343  &     3264.415     &     2.820  &         0.005        &     2806.486    &     1.56e+04     \\\\\n",
       "\\textbf{4768.0}      &    8149.0733  &     3123.950     &     2.609  &         0.009        &     2025.657    &     1.43e+04     \\\\\n",
       "\\textbf{4771.0}      &     1.02e+04  &     3154.399     &     3.233  &         0.001        &     4014.036    &     1.64e+04     \\\\\n",
       "\\textbf{4800.0}      &    8510.9355  &     3222.793     &     2.641  &         0.008        &     2193.771    &     1.48e+04     \\\\\n",
       "\\textbf{4802.0}      &    9756.0632  &     3122.659     &     3.124  &         0.002        &     3635.177    &     1.59e+04     \\\\\n",
       "\\textbf{4807.0}      &    9311.2841  &     3209.003     &     2.902  &         0.004        &     3021.150    &     1.56e+04     \\\\\n",
       "\\textbf{4839.0}      &    -1.39e+05  &     4400.348     &   -31.598  &         0.000        &    -1.48e+05    &     -1.3e+05     \\\\\n",
       "\\textbf{4843.0}      &    -155.0920  &     3300.774     &    -0.047  &         0.963        &    -6625.111    &     6314.927     \\\\\n",
       "\\textbf{4881.0}      &    7349.9526  &     3033.927     &     2.423  &         0.015        &     1402.995    &     1.33e+04     \\\\\n",
       "\\textbf{4900.0}      &    8056.7145  &     3130.004     &     2.574  &         0.010        &     1921.431    &     1.42e+04     \\\\\n",
       "\\textbf{4926.0}      &    6951.4250  &     3036.486     &     2.289  &         0.022        &      999.451    &     1.29e+04     \\\\\n",
       "\\textbf{4941.0}      &    7701.0234  &     3119.428     &     2.469  &         0.014        &     1586.472    &     1.38e+04     \\\\\n",
       "\\textbf{4961.0}      &   -6713.3878  &     3845.668     &    -1.746  &         0.081        &    -1.43e+04    &      824.706     \\\\\n",
       "\\textbf{4988.0}      &    1.555e+04  &     3152.418     &     4.932  &         0.000        &     9368.460    &     2.17e+04     \\\\\n",
       "\\textbf{4993.0}      &    1.078e+04  &     3191.719     &     3.379  &         0.001        &     4527.925    &      1.7e+04     \\\\\n",
       "\\textbf{5018.0}      &    2756.6116  &     3051.145     &     0.903  &         0.366        &    -3224.095    &     8737.318     \\\\\n",
       "\\textbf{5020.0}      &    1703.6436  &     3206.794     &     0.531  &         0.595        &    -4582.160    &     7989.448     \\\\\n",
       "\\textbf{5027.0}      &    5583.6057  &     3073.165     &     1.817  &         0.069        &     -440.265    &     1.16e+04     \\\\\n",
       "\\textbf{5032.0}      &    8848.7731  &     3093.419     &     2.861  &         0.004        &     2785.202    &     1.49e+04     \\\\\n",
       "\\textbf{5043.0}      &    5765.7251  &     3056.378     &     1.886  &         0.059        &     -225.240    &     1.18e+04     \\\\\n",
       "\\textbf{5046.0}      &   -3742.7011  &     3008.827     &    -1.244  &         0.214        &    -9640.459    &     2155.057     \\\\\n",
       "\\textbf{5047.0}      &    4.951e+04  &     3945.666     &    12.549  &         0.000        &     4.18e+04    &     5.72e+04     \\\\\n",
       "\\textbf{5065.0}      &    9943.6682  &     3565.116     &     2.789  &         0.005        &     2955.499    &     1.69e+04     \\\\\n",
       "\\textbf{5071.0}      &    8402.8199  &     3506.244     &     2.397  &         0.017        &     1530.049    &     1.53e+04     \\\\\n",
       "\\textbf{5073.0}      &    -2.03e+05  &     6327.061     &   -32.087  &         0.000        &    -2.15e+05    &    -1.91e+05     \\\\\n",
       "\\textbf{5087.0}      &    4808.3060  &     3031.181     &     1.586  &         0.113        &    -1133.268    &     1.07e+04     \\\\\n",
       "\\textbf{5109.0}      &        1e+04  &     3156.702     &     3.169  &         0.002        &     3815.966    &     1.62e+04     \\\\\n",
       "\\textbf{5116.0}      &     331.7479  &     3230.260     &     0.103  &         0.918        &    -6000.052    &     6663.548     \\\\\n",
       "\\textbf{5122.0}      &    5093.7234  &     3033.485     &     1.679  &         0.093        &     -852.368    &      1.1e+04     \\\\\n",
       "\\textbf{5134.0}      &    1619.9886  &     3164.783     &     0.512  &         0.609        &    -4583.467    &     7823.444     \\\\\n",
       "\\textbf{5142.0}      &    6629.5952  &     3817.878     &     1.736  &         0.083        &     -854.026    &     1.41e+04     \\\\\n",
       "\\textbf{5165.0}      &    7201.9002  &     3418.120     &     2.107  &         0.035        &      501.866    &     1.39e+04     \\\\\n",
       "\\textbf{5169.0}      &    1.921e+04  &     3111.749     &     6.173  &         0.000        &     1.31e+04    &     2.53e+04     \\\\\n",
       "\\textbf{5174.0}      &    6861.1596  &     3315.866     &     2.069  &         0.039        &      361.558    &     1.34e+04     \\\\\n",
       "\\textbf{5179.0}      &    9522.8653  &     3123.992     &     3.048  &         0.002        &     3399.366    &     1.56e+04     \\\\\n",
       "\\textbf{5181.0}      &    1.022e+04  &     3247.843     &     3.148  &         0.002        &     3857.092    &     1.66e+04     \\\\\n",
       "\\textbf{5187.0}      &    1.051e+04  &     3595.928     &     2.924  &         0.003        &     3466.116    &     1.76e+04     \\\\\n",
       "\\textbf{5229.0}      &    1832.7007  &     2976.839     &     0.616  &         0.538        &    -4002.356    &     7667.757     \\\\\n",
       "\\textbf{5234.0}      &   -5223.8465  &     3133.458     &    -1.667  &         0.096        &    -1.14e+04    &      918.206     \\\\\n",
       "\\textbf{5237.0}      &    9043.0280  &     3101.586     &     2.916  &         0.004        &     2963.448    &     1.51e+04     \\\\\n",
       "\\textbf{5252.0}      &    8212.2020  &     3060.018     &     2.684  &         0.007        &     2214.102    &     1.42e+04     \\\\\n",
       "\\textbf{5254.0}      &    8446.7502  &     3097.320     &     2.727  &         0.006        &     2375.532    &     1.45e+04     \\\\\n",
       "\\textbf{5306.0}      &    6465.5650  &     3027.709     &     2.135  &         0.033        &      530.795    &     1.24e+04     \\\\\n",
       "\\textbf{5338.0}      &    9319.2221  &     3098.305     &     3.008  &         0.003        &     3246.074    &     1.54e+04     \\\\\n",
       "\\textbf{5377.0}      &    1.009e+04  &     3165.731     &     3.188  &         0.001        &     3885.677    &     1.63e+04     \\\\\n",
       "\\textbf{5439.0}      &    7334.3884  &     3132.147     &     2.342  &         0.019        &     1194.905    &     1.35e+04     \\\\\n",
       "\\textbf{5456.0}      &    1.067e+04  &     3219.404     &     3.313  &         0.001        &     4356.183    &      1.7e+04     \\\\\n",
       "\\textbf{5464.0}      &    8046.9137  &     3717.507     &     2.165  &         0.030        &      760.036    &     1.53e+04     \\\\\n",
       "\\textbf{5476.0}      &    1.038e+04  &     3188.810     &     3.254  &         0.001        &     4125.428    &     1.66e+04     \\\\\n",
       "\\textbf{5492.0}      &   -7692.0384  &     3028.409     &    -2.540  &         0.011        &    -1.36e+04    &    -1755.897     \\\\\n",
       "\\textbf{5496.0}      &    8328.8408  &     3078.327     &     2.706  &         0.007        &     2294.852    &     1.44e+04     \\\\\n",
       "\\textbf{5505.0}      &    9584.8474  &     3145.488     &     3.047  &         0.002        &     3419.213    &     1.58e+04     \\\\\n",
       "\\textbf{5518.0}      &    8040.5569  &     3394.234     &     2.369  &         0.018        &     1387.343    &     1.47e+04     \\\\\n",
       "\\textbf{5520.0}      &    7141.4059  &     3085.889     &     2.314  &         0.021        &     1092.595    &     1.32e+04     \\\\\n",
       "\\textbf{5545.0}      &    9850.2695  &     3257.198     &     3.024  &         0.002        &     3465.667    &     1.62e+04     \\\\\n",
       "\\textbf{5568.0}      &      1.2e+04  &     3131.140     &     3.834  &         0.000        &     5866.525    &     1.81e+04     \\\\\n",
       "\\textbf{5569.0}      &    1.006e+04  &     3173.656     &     3.171  &         0.002        &     3841.616    &     1.63e+04     \\\\\n",
       "\\textbf{5578.0}      &    9572.4372  &     3115.964     &     3.072  &         0.002        &     3464.675    &     1.57e+04     \\\\\n",
       "\\textbf{5581.0}      &    9414.8809  &     3097.341     &     3.040  &         0.002        &     3343.622    &     1.55e+04     \\\\\n",
       "\\textbf{5589.0}      &    2400.9953  &     2973.079     &     0.808  &         0.419        &    -3426.690    &     8228.681     \\\\\n",
       "\\textbf{5597.0}      &     1.13e+04  &     3648.090     &     3.097  &         0.002        &     4145.936    &     1.84e+04     \\\\\n",
       "\\textbf{5606.0}      &   -2.745e+04  &     3152.384     &    -8.709  &         0.000        &    -3.36e+04    &    -2.13e+04     \\\\\n",
       "\\textbf{5639.0}      &    1.082e+04  &     3159.665     &     3.425  &         0.001        &     4628.029    &      1.7e+04     \\\\\n",
       "\\textbf{5667.0}      &    7446.7098  &     3218.672     &     2.314  &         0.021        &     1137.624    &     1.38e+04     \\\\\n",
       "\\textbf{5690.0}      &    9706.2182  &     3117.215     &     3.114  &         0.002        &     3596.004    &     1.58e+04     \\\\\n",
       "\\textbf{5709.0}      &    9020.8914  &     3130.883     &     2.881  &         0.004        &     2883.886    &     1.52e+04     \\\\\n",
       "\\textbf{5726.0}      &    9123.8740  &     3144.647     &     2.901  &         0.004        &     2959.887    &     1.53e+04     \\\\\n",
       "\\textbf{5764.0}      &    7723.0628  &     3018.519     &     2.559  &         0.011        &     1806.306    &     1.36e+04     \\\\\n",
       "\\textbf{5772.0}      &    8901.7882  &     3086.811     &     2.884  &         0.004        &     2851.170    &      1.5e+04     \\\\\n",
       "\\textbf{5860.0}      &   -1.948e+04  &     3110.857     &    -6.261  &         0.000        &    -2.56e+04    &    -1.34e+04     \\\\\n",
       "\\textbf{5878.0}      &    1.119e+04  &     3037.648     &     3.682  &         0.000        &     5231.276    &     1.71e+04     \\\\\n",
       "\\textbf{5903.0}      &    4917.5431  &     3123.826     &     1.574  &         0.115        &    -1205.631    &      1.1e+04     \\\\\n",
       "\\textbf{5905.0}      &    6472.3316  &     3072.948     &     2.106  &         0.035        &      448.886    &     1.25e+04     \\\\\n",
       "\\textbf{5959.0}      &    4032.3371  &     3074.491     &     1.312  &         0.190        &    -1994.131    &     1.01e+04     \\\\\n",
       "\\textbf{6008.0}      &    2.842e+04  &     3030.015     &     9.380  &         0.000        &     2.25e+04    &     3.44e+04     \\\\\n",
       "\\textbf{6034.0}      &    5915.9539  &     3166.969     &     1.868  &         0.062        &     -291.787    &     1.21e+04     \\\\\n",
       "\\textbf{6035.0}      &    4321.0088  &     3624.230     &     1.192  &         0.233        &    -2783.033    &     1.14e+04     \\\\\n",
       "\\textbf{6036.0}      &     672.3068  &     2994.346     &     0.225  &         0.822        &    -5197.066    &     6541.680     \\\\\n",
       "\\textbf{6039.0}      &    9107.9457  &     3133.532     &     2.907  &         0.004        &     2965.747    &     1.53e+04     \\\\\n",
       "\\textbf{6044.0}      &    1.053e+04  &     3386.931     &     3.110  &         0.002        &     3894.343    &     1.72e+04     \\\\\n",
       "\\textbf{6066.0}      &    -2.49e+04  &     4424.278     &    -5.629  &         0.000        &    -3.36e+04    &    -1.62e+04     \\\\\n",
       "\\textbf{6078.0}      &    9970.6042  &     3077.931     &     3.239  &         0.001        &     3937.391    &      1.6e+04     \\\\\n",
       "\\textbf{6081.0}      &   -8372.7134  &     2993.920     &    -2.797  &         0.005        &    -1.42e+04    &    -2504.175     \\\\\n",
       "\\textbf{60893.0}     &   -4392.3442  &     4603.659     &    -0.954  &         0.340        &    -1.34e+04    &     4631.526     \\\\\n",
       "\\textbf{6097.0}      &    1.012e+04  &     3186.388     &     3.177  &         0.001        &     3876.500    &     1.64e+04     \\\\\n",
       "\\textbf{6102.0}      &    8471.8648  &     3120.976     &     2.714  &         0.007        &     2354.277    &     1.46e+04     \\\\\n",
       "\\textbf{6104.0}      &   -1015.6692  &     3148.374     &    -0.323  &         0.747        &    -7186.960    &     5155.622     \\\\\n",
       "\\textbf{6109.0}      &    1845.7093  &     2960.815     &     0.623  &         0.533        &    -3957.937    &     7649.356     \\\\\n",
       "\\textbf{6127.0}      &    3170.7530  &     3399.610     &     0.933  &         0.351        &    -3492.999    &     9834.505     \\\\\n",
       "\\textbf{61552.0}     &   -3744.5941  &     4251.815     &    -0.881  &         0.378        &    -1.21e+04    &     4589.610     \\\\\n",
       "\\textbf{6158.0}      &    6412.2005  &     3180.992     &     2.016  &         0.044        &      176.973    &     1.26e+04     \\\\\n",
       "\\textbf{6171.0}      &    9057.6581  &     3095.055     &     2.926  &         0.003        &     2990.880    &     1.51e+04     \\\\\n",
       "\\textbf{61780.0}     &    7728.4892  &     4929.729     &     1.568  &         0.117        &    -1934.529    &     1.74e+04     \\\\\n",
       "\\textbf{6207.0}      &    9047.4137  &     3117.371     &     2.902  &         0.004        &     2936.893    &     1.52e+04     \\\\\n",
       "\\textbf{6214.0}      &    9507.7433  &     3104.135     &     3.063  &         0.002        &     3423.167    &     1.56e+04     \\\\\n",
       "\\textbf{6216.0}      &    9878.3520  &     3184.210     &     3.102  &         0.002        &     3636.816    &     1.61e+04     \\\\\n",
       "\\textbf{62221.0}     &    9234.8611  &     4394.723     &     2.101  &         0.036        &      620.537    &     1.78e+04     \\\\\n",
       "\\textbf{6259.0}      &    5439.7175  &     3440.702     &     1.581  &         0.114        &    -1304.581    &     1.22e+04     \\\\\n",
       "\\textbf{62599.0}     &   -2.283e+04  &     4958.737     &    -4.603  &         0.000        &    -3.25e+04    &    -1.31e+04     \\\\\n",
       "\\textbf{6266.0}      &    9238.7331  &     3091.436     &     2.988  &         0.003        &     3179.048    &     1.53e+04     \\\\\n",
       "\\textbf{6268.0}      &    1962.6459  &     3058.799     &     0.642  &         0.521        &    -4033.064    &     7958.356     \\\\\n",
       "\\textbf{6288.0}      &    8168.8157  &     3114.238     &     2.623  &         0.009        &     2064.437    &     1.43e+04     \\\\\n",
       "\\textbf{6297.0}      &    9274.3327  &     3198.409     &     2.900  &         0.004        &     3004.965    &     1.55e+04     \\\\\n",
       "\\textbf{6307.0}      &   -1.469e+04  &     3698.147     &    -3.973  &         0.000        &    -2.19e+04    &    -7443.955     \\\\\n",
       "\\textbf{6313.0}      &    8992.0347  &     4390.677     &     2.048  &         0.041        &      385.640    &     1.76e+04     \\\\\n",
       "\\textbf{6314.0}      &    9736.1987  &     3151.801     &     3.089  &         0.002        &     3558.191    &     1.59e+04     \\\\\n",
       "\\textbf{6326.0}      &    3826.7169  &     2984.925     &     1.282  &         0.200        &    -2024.190    &     9677.624     \\\\\n",
       "\\textbf{6349.0}      &    8643.9164  &     3087.391     &     2.800  &         0.005        &     2592.161    &     1.47e+04     \\\\\n",
       "\\textbf{6357.0}      &    1.032e+04  &     3297.883     &     3.130  &         0.002        &     3857.899    &     1.68e+04     \\\\\n",
       "\\textbf{6375.0}      &    1.413e+04  &     3134.685     &     4.507  &         0.000        &     7984.330    &     2.03e+04     \\\\\n",
       "\\textbf{6376.0}      &    9471.0692  &     3147.599     &     3.009  &         0.003        &     3301.297    &     1.56e+04     \\\\\n",
       "\\textbf{6379.0}      &   -3775.7784  &     6131.764     &    -0.616  &         0.538        &    -1.58e+04    &     8243.410     \\\\\n",
       "\\textbf{6386.0}      &    9629.8217  &     3110.678     &     3.096  &         0.002        &     3532.421    &     1.57e+04     \\\\\n",
       "\\textbf{6403.0}      &    5780.6448  &     3183.328     &     1.816  &         0.069        &     -459.161    &      1.2e+04     \\\\\n",
       "\\textbf{6410.0}      &    1.062e+04  &     3209.167     &     3.309  &         0.001        &     4327.639    &     1.69e+04     \\\\\n",
       "\\textbf{6416.0}      &    4480.9728  &     3166.668     &     1.415  &         0.157        &    -1726.177    &     1.07e+04     \\\\\n",
       "\\textbf{6424.0}      &    9498.0653  &     3132.089     &     3.033  &         0.002        &     3358.695    &     1.56e+04     \\\\\n",
       "\\textbf{6433.0}      &    9589.1419  &     3170.423     &     3.025  &         0.002        &     3374.632    &     1.58e+04     \\\\\n",
       "\\textbf{6435.0}      &    9723.4153  &     3042.211     &     3.196  &         0.001        &     3760.220    &     1.57e+04     \\\\\n",
       "\\textbf{6492.0}      &    6260.6289  &     3090.244     &     2.026  &         0.043        &      203.281    &     1.23e+04     \\\\\n",
       "\\textbf{6497.0}      &    2903.0101  &     3215.604     &     0.903  &         0.367        &    -3400.062    &     9206.082     \\\\\n",
       "\\textbf{6500.0}      &    8402.1659  &     7302.670     &     1.151  &         0.250        &    -5912.176    &     2.27e+04     \\\\\n",
       "\\textbf{6509.0}      &    8464.7557  &     3077.538     &     2.750  &         0.006        &     2432.313    &     1.45e+04     \\\\\n",
       "\\textbf{6527.0}      &    1.055e+04  &     3417.715     &     3.086  &         0.002        &     3848.357    &     1.72e+04     \\\\\n",
       "\\textbf{6528.0}      &    8661.1370  &     3343.926     &     2.590  &         0.010        &     2106.534    &     1.52e+04     \\\\\n",
       "\\textbf{6531.0}      &     -25.9974  &     3078.405     &    -0.008  &         0.993        &    -6060.139    &     6008.144     \\\\\n",
       "\\textbf{6532.0}      &    5885.9647  &     3095.765     &     1.901  &         0.057        &     -182.205    &      1.2e+04     \\\\\n",
       "\\textbf{6543.0}      &    9929.9352  &     3144.078     &     3.158  &         0.002        &     3767.065    &     1.61e+04     \\\\\n",
       "\\textbf{6548.0}      &    9593.2367  &     3169.925     &     3.026  &         0.002        &     3379.702    &     1.58e+04     \\\\\n",
       "\\textbf{6550.0}      &    9616.0676  &     3359.843     &     2.862  &         0.004        &     3030.264    &     1.62e+04     \\\\\n",
       "\\textbf{6552.0}      &    9638.8646  &     3275.149     &     2.943  &         0.003        &     3219.075    &     1.61e+04     \\\\\n",
       "\\textbf{6565.0}      &    4782.1084  &     3198.665     &     1.495  &         0.135        &    -1487.761    &     1.11e+04     \\\\\n",
       "\\textbf{6571.0}      &    9305.0305  &     3110.487     &     2.992  &         0.003        &     3208.004    &     1.54e+04     \\\\\n",
       "\\textbf{6573.0}      &    9082.6070  &     3092.638     &     2.937  &         0.003        &     3020.566    &     1.51e+04     \\\\\n",
       "\\textbf{6641.0}      &    7749.3873  &     5382.286     &     1.440  &         0.150        &    -2800.711    &     1.83e+04     \\\\\n",
       "\\textbf{6649.0}      &    1.053e+04  &     3159.208     &     3.335  &         0.001        &     4342.190    &     1.67e+04     \\\\\n",
       "\\textbf{6730.0}      &    8500.3738  &     3089.775     &     2.751  &         0.006        &     2443.946    &     1.46e+04     \\\\\n",
       "\\textbf{6731.0}      &    6466.6645  &     3134.642     &     2.063  &         0.039        &      322.291    &     1.26e+04     \\\\\n",
       "\\textbf{6742.0}      &    9550.9622  &     4649.788     &     2.054  &         0.040        &      436.672    &     1.87e+04     \\\\\n",
       "\\textbf{6745.0}      &    1.009e+04  &     3200.253     &     3.154  &         0.002        &     3820.559    &     1.64e+04     \\\\\n",
       "\\textbf{6756.0}      &    9834.8380  &     3160.429     &     3.112  &         0.002        &     3639.917    &      1.6e+04     \\\\\n",
       "\\textbf{6765.0}      &   -4414.1271  &     3022.513     &    -1.460  &         0.144        &    -1.03e+04    &     1510.458     \\\\\n",
       "\\textbf{6768.0}      &    1.156e+04  &     3234.772     &     3.575  &         0.000        &     5223.749    &     1.79e+04     \\\\\n",
       "\\textbf{6774.0}      &    -1.45e+04  &     3423.679     &    -4.235  &         0.000        &    -2.12e+04    &    -7789.918     \\\\\n",
       "\\textbf{6797.0}      &    1.062e+04  &     3560.156     &     2.982  &         0.003        &     3636.640    &     1.76e+04     \\\\\n",
       "\\textbf{6803.0}      &    9790.5158  &     3152.629     &     3.106  &         0.002        &     3610.883    &      1.6e+04     \\\\\n",
       "\\textbf{6821.0}      &    8916.7458  &     3111.850     &     2.865  &         0.004        &     2817.047    &      1.5e+04     \\\\\n",
       "\\textbf{6830.0}      &    8333.4226  &     3124.559     &     2.667  &         0.008        &     2208.812    &     1.45e+04     \\\\\n",
       "\\textbf{6845.0}      &    6582.6117  &     3033.170     &     2.170  &         0.030        &      637.138    &     1.25e+04     \\\\\n",
       "\\textbf{6848.0}      &    9265.8494  &     3380.966     &     2.741  &         0.006        &     2638.642    &     1.59e+04     \\\\\n",
       "\\textbf{6873.0}      &    5262.2493  &     3710.128     &     1.418  &         0.156        &    -2010.164    &     1.25e+04     \\\\\n",
       "\\textbf{6900.0}      &    7470.5391  &     3040.133     &     2.457  &         0.014        &     1511.417    &     1.34e+04     \\\\\n",
       "\\textbf{6908.0}      &    7574.9222  &     3037.300     &     2.494  &         0.013        &     1621.353    &     1.35e+04     \\\\\n",
       "\\textbf{6994.0}      &    8255.8589  &     3119.283     &     2.647  &         0.008        &     2141.590    &     1.44e+04     \\\\\n",
       "\\textbf{7045.0}      &    1844.4045  &     3736.226     &     0.494  &         0.622        &    -5479.167    &     9167.976     \\\\\n",
       "\\textbf{7065.0}      &    1.408e+04  &     3067.167     &     4.591  &         0.000        &     8070.340    &     2.01e+04     \\\\\n",
       "\\textbf{7085.0}      &     1.13e+04  &     3081.095     &     3.669  &         0.000        &     5264.878    &     1.73e+04     \\\\\n",
       "\\textbf{7107.0}      &    8052.7198  &     3211.390     &     2.508  &         0.012        &     1757.908    &     1.43e+04     \\\\\n",
       "\\textbf{7116.0}      &    1.032e+04  &     3179.999     &     3.245  &         0.001        &     4086.849    &     1.66e+04     \\\\\n",
       "\\textbf{7117.0}      &    1.055e+04  &     3949.975     &     2.671  &         0.008        &     2809.099    &     1.83e+04     \\\\\n",
       "\\textbf{7121.0}      &    8775.8315  &     3133.720     &     2.800  &         0.005        &     2633.264    &     1.49e+04     \\\\\n",
       "\\textbf{7127.0}      &    6420.8313  &     3243.158     &     1.980  &         0.048        &       63.750    &     1.28e+04     \\\\\n",
       "\\textbf{7139.0}      &    8727.2476  &     3099.294     &     2.816  &         0.005        &     2652.161    &     1.48e+04     \\\\\n",
       "\\textbf{7146.0}      &    9720.1875  &     3126.664     &     3.109  &         0.002        &     3591.451    &     1.58e+04     \\\\\n",
       "\\textbf{7163.0}      &    1.279e+04  &     3134.484     &     4.081  &         0.000        &     6646.405    &     1.89e+04     \\\\\n",
       "\\textbf{7180.0}      &    6160.9922  &     3087.312     &     1.996  &         0.046        &      109.392    &     1.22e+04     \\\\\n",
       "\\textbf{7183.0}      &    6762.3251  &     3128.386     &     2.162  &         0.031        &      630.214    &     1.29e+04     \\\\\n",
       "\\textbf{7228.0}      &    1.764e+04  &     3168.523     &     5.567  &         0.000        &     1.14e+04    &     2.38e+04     \\\\\n",
       "\\textbf{7232.0}      &    8154.6539  &     4154.025     &     1.963  &         0.050        &       12.134    &     1.63e+04     \\\\\n",
       "\\textbf{7250.0}      &    6766.0899  &     3377.887     &     2.003  &         0.045        &      144.918    &     1.34e+04     \\\\\n",
       "\\textbf{7257.0}      &    2.971e+04  &     3115.326     &     9.536  &         0.000        &     2.36e+04    &     3.58e+04     \\\\\n",
       "\\textbf{7260.0}      &    9150.8519  &     3085.180     &     2.966  &         0.003        &     3103.431    &     1.52e+04     \\\\\n",
       "\\textbf{7267.0}      &    8865.9508  &     3234.107     &     2.741  &         0.006        &     2526.610    &     1.52e+04     \\\\\n",
       "\\textbf{7268.0}      &    1505.3236  &     3301.821     &     0.456  &         0.648        &    -4966.748    &     7977.395     \\\\\n",
       "\\textbf{7281.0}      &    9732.5905  &     3991.005     &     2.439  &         0.015        &     1909.615    &     1.76e+04     \\\\\n",
       "\\textbf{7291.0}      &    7456.0581  &     3068.111     &     2.430  &         0.015        &     1442.096    &     1.35e+04     \\\\\n",
       "\\textbf{7343.0}      &    4436.4667  &     3573.654     &     1.241  &         0.214        &    -2568.438    &     1.14e+04     \\\\\n",
       "\\textbf{7346.0}      &    3238.1303  &     3079.092     &     1.052  &         0.293        &    -2797.357    &     9273.617     \\\\\n",
       "\\textbf{7401.0}      &    9349.7327  &     3138.244     &     2.979  &         0.003        &     3198.297    &     1.55e+04     \\\\\n",
       "\\textbf{7409.0}      &    8457.9972  &     3066.239     &     2.758  &         0.006        &     2447.702    &     1.45e+04     \\\\\n",
       "\\textbf{7420.0}      &    6215.9290  &     3018.667     &     2.059  &         0.039        &      298.884    &     1.21e+04     \\\\\n",
       "\\textbf{7435.0}      &    6751.7467  &     3158.717     &     2.137  &         0.033        &      560.181    &     1.29e+04     \\\\\n",
       "\\textbf{7466.0}      &    8553.9161  &     3269.146     &     2.617  &         0.009        &     2145.893    &      1.5e+04     \\\\\n",
       "\\textbf{7486.0}      &    1723.3876  &     3152.520     &     0.547  &         0.585        &    -4456.030    &     7902.805     \\\\\n",
       "\\textbf{7503.0}      &    9067.0759  &     4579.905     &     1.980  &         0.048        &       89.767    &      1.8e+04     \\\\\n",
       "\\textbf{7506.0}      &    9819.2990  &     3057.813     &     3.211  &         0.001        &     3825.522    &     1.58e+04     \\\\\n",
       "\\textbf{7537.0}      &    9430.8825  &     3170.373     &     2.975  &         0.003        &     3216.470    &     1.56e+04     \\\\\n",
       "\\textbf{7549.0}      &    7273.1684  &     3042.817     &     2.390  &         0.017        &     1308.786    &     1.32e+04     \\\\\n",
       "\\textbf{7554.0}      &    8897.8883  &     3135.083     &     2.838  &         0.005        &     2752.650    &      1.5e+04     \\\\\n",
       "\\textbf{7557.0}      &    6931.8955  &     3136.896     &     2.210  &         0.027        &      783.102    &     1.31e+04     \\\\\n",
       "\\textbf{7585.0}      &   -1.495e+04  &     3233.948     &    -4.624  &         0.000        &    -2.13e+04    &    -8613.193     \\\\\n",
       "\\textbf{7602.0}      &    8923.7108  &     3107.157     &     2.872  &         0.004        &     2833.211    &      1.5e+04     \\\\\n",
       "\\textbf{7620.0}      &    7129.5037  &     3384.544     &     2.106  &         0.035        &      495.283    &     1.38e+04     \\\\\n",
       "\\textbf{7636.0}      &    9304.1976  &     3123.447     &     2.979  &         0.003        &     3181.767    &     1.54e+04     \\\\\n",
       "\\textbf{7646.0}      &    9393.7191  &     3155.786     &     2.977  &         0.003        &     3207.900    &     1.56e+04     \\\\\n",
       "\\textbf{7658.0}      &    6253.3200  &     3022.501     &     2.069  &         0.039        &      328.759    &     1.22e+04     \\\\\n",
       "\\textbf{7683.0}      &    1.026e+04  &     3321.592     &     3.090  &         0.002        &     3753.317    &     1.68e+04     \\\\\n",
       "\\textbf{7685.0}      &    8767.4758  &     3234.267     &     2.711  &         0.007        &     2427.821    &     1.51e+04     \\\\\n",
       "\\textbf{7692.0}      &    5012.1399  &     3004.385     &     1.668  &         0.095        &     -876.911    &     1.09e+04     \\\\\n",
       "\\textbf{7762.0}      &    9366.4810  &     3091.150     &     3.030  &         0.002        &     3307.357    &     1.54e+04     \\\\\n",
       "\\textbf{7772.0}      &   -2443.1777  &     3001.938     &    -0.814  &         0.416        &    -8327.432    &     3441.076     \\\\\n",
       "\\textbf{7773.0}      &    8790.9387  &     3128.430     &     2.810  &         0.005        &     2658.740    &     1.49e+04     \\\\\n",
       "\\textbf{7777.0}      &    5620.5173  &     3072.543     &     1.829  &         0.067        &     -402.134    &     1.16e+04     \\\\\n",
       "\\textbf{7835.0}      &    9969.7493  &     3156.641     &     3.158  &         0.002        &     3782.253    &     1.62e+04     \\\\\n",
       "\\textbf{7873.0}      &    1753.2079  &     3096.978     &     0.566  &         0.571        &    -4317.340    &     7823.755     \\\\\n",
       "\\textbf{7883.0}      &    6648.1472  &     3032.795     &     2.192  &         0.028        &      703.409    &     1.26e+04     \\\\\n",
       "\\textbf{7904.0}      &    5757.8853  &     3042.665     &     1.892  &         0.058        &     -206.199    &     1.17e+04     \\\\\n",
       "\\textbf{7906.0}      &     1.24e+04  &     3192.708     &     3.884  &         0.000        &     6143.287    &     1.87e+04     \\\\\n",
       "\\textbf{7921.0}      &    9521.8682  &     3078.497     &     3.093  &         0.002        &     3487.546    &     1.56e+04     \\\\\n",
       "\\textbf{7923.0}      &    8424.9184  &     3204.025     &     2.629  &         0.009        &     2144.542    &     1.47e+04     \\\\\n",
       "\\textbf{7935.0}      &    6955.2953  &     3049.615     &     2.281  &         0.023        &      977.586    &     1.29e+04     \\\\\n",
       "\\textbf{7938.0}      &    7442.0282  &     3074.413     &     2.421  &         0.016        &     1415.711    &     1.35e+04     \\\\\n",
       "\\textbf{7985.0}      &   -1.012e+04  &     2991.410     &    -3.382  &         0.001        &     -1.6e+04    &    -4253.115     \\\\\n",
       "\\textbf{8014.0}      &    8157.1933  &     3199.316     &     2.550  &         0.011        &     1886.047    &     1.44e+04     \\\\\n",
       "\\textbf{8030.0}      &    1.069e+04  &     3172.643     &     3.370  &         0.001        &     4474.298    &     1.69e+04     \\\\\n",
       "\\textbf{8046.0}      &    2100.8383  &     3150.625     &     0.667  &         0.505        &    -4074.865    &     8276.542     \\\\\n",
       "\\textbf{8047.0}      &    8930.9265  &     3638.445     &     2.455  &         0.014        &     1799.022    &     1.61e+04     \\\\\n",
       "\\textbf{8062.0}      &    7656.2181  &     3156.951     &     2.425  &         0.015        &     1468.115    &     1.38e+04     \\\\\n",
       "\\textbf{8068.0}      &   -6316.9730  &     3342.935     &    -1.890  &         0.059        &    -1.29e+04    &      235.687     \\\\\n",
       "\\textbf{8087.0}      &   -1486.8453  &     3165.038     &    -0.470  &         0.639        &    -7690.801    &     4717.110     \\\\\n",
       "\\textbf{8095.0}      &    9092.3282  &     3091.617     &     2.941  &         0.003        &     3032.289    &     1.52e+04     \\\\\n",
       "\\textbf{8096.0}      &    9888.7824  &     3156.253     &     3.133  &         0.002        &     3702.048    &     1.61e+04     \\\\\n",
       "\\textbf{8109.0}      &    9592.9423  &     3114.281     &     3.080  &         0.002        &     3488.479    &     1.57e+04     \\\\\n",
       "\\textbf{8123.0}      &    5332.5335  &     3050.740     &     1.748  &         0.080        &     -647.380    &     1.13e+04     \\\\\n",
       "\\textbf{8150.0}      &    1.002e+04  &     3143.649     &     3.186  &         0.001        &     3854.817    &     1.62e+04     \\\\\n",
       "\\textbf{8163.0}      &    7135.9390  &     3109.533     &     2.295  &         0.022        &     1040.782    &     1.32e+04     \\\\\n",
       "\\textbf{8176.0}      &    5907.8263  &     3555.339     &     1.662  &         0.097        &    -1061.178    &     1.29e+04     \\\\\n",
       "\\textbf{8202.0}      &    7093.7298  &     3180.484     &     2.230  &         0.026        &      859.499    &     1.33e+04     \\\\\n",
       "\\textbf{8214.0}      &    5649.2334  &     3049.389     &     1.853  &         0.064        &     -328.032    &     1.16e+04     \\\\\n",
       "\\textbf{8215.0}      &    3589.9167  &     3151.067     &     1.139  &         0.255        &    -2586.652    &     9766.486     \\\\\n",
       "\\textbf{8219.0}      &    1.015e+04  &     3202.762     &     3.170  &         0.002        &     3875.511    &     1.64e+04     \\\\\n",
       "\\textbf{8247.0}      &    5130.0212  &     3044.372     &     1.685  &         0.092        &     -837.409    &     1.11e+04     \\\\\n",
       "\\textbf{8253.0}      &   -2202.2944  &     3019.455     &    -0.729  &         0.466        &    -8120.885    &     3716.296     \\\\\n",
       "\\textbf{8290.0}      &    6667.9159  &     3236.736     &     2.060  &         0.039        &      323.422    &      1.3e+04     \\\\\n",
       "\\textbf{8293.0}      &    7346.0103  &     3043.721     &     2.413  &         0.016        &     1379.855    &     1.33e+04     \\\\\n",
       "\\textbf{8304.0}      &    9985.5502  &     3093.631     &     3.228  &         0.001        &     3921.565    &      1.6e+04     \\\\\n",
       "\\textbf{8334.0}      &    9750.2882  &     3258.525     &     2.992  &         0.003        &     3363.085    &     1.61e+04     \\\\\n",
       "\\textbf{8348.0}      &    9196.9702  &     3156.426     &     2.914  &         0.004        &     3009.895    &     1.54e+04     \\\\\n",
       "\\textbf{8357.0}      &    8782.9091  &     3076.771     &     2.855  &         0.004        &     2751.971    &     1.48e+04     \\\\\n",
       "\\textbf{8358.0}      &    6761.4473  &     3044.175     &     2.221  &         0.026        &      794.402    &     1.27e+04     \\\\\n",
       "\\textbf{8446.0}      &   -3983.6259  &     3374.667     &    -1.180  &         0.238        &    -1.06e+04    &     2631.234     \\\\\n",
       "\\textbf{8460.0}      &    1.098e+04  &     3537.306     &     3.105  &         0.002        &     4051.291    &     1.79e+04     \\\\\n",
       "\\textbf{8463.0}      &    8838.8993  &     3110.041     &     2.842  &         0.004        &     2742.747    &     1.49e+04     \\\\\n",
       "\\textbf{8479.0}      &    7883.3944  &     3750.123     &     2.102  &         0.036        &      532.584    &     1.52e+04     \\\\\n",
       "\\textbf{8530.0}      &    2.055e+04  &     3130.331     &     6.565  &         0.000        &     1.44e+04    &     2.67e+04     \\\\\n",
       "\\textbf{8536.0}      &    5321.9245  &     3023.926     &     1.760  &         0.078        &     -605.430    &     1.12e+04     \\\\\n",
       "\\textbf{8543.0}      &     2.91e+04  &     3348.461     &     8.689  &         0.000        &     2.25e+04    &     3.57e+04     \\\\\n",
       "\\textbf{8549.0}      &     288.7530  &     3183.883     &     0.091  &         0.928        &    -5952.140    &     6529.646     \\\\\n",
       "\\textbf{8551.0}      &    9857.0564  &     3160.749     &     3.119  &         0.002        &     3661.508    &     1.61e+04     \\\\\n",
       "\\textbf{8559.0}      &    6877.9877  &     3301.144     &     2.084  &         0.037        &      407.244    &     1.33e+04     \\\\\n",
       "\\textbf{8573.0}      &    2363.2893  &     3354.437     &     0.705  &         0.481        &    -4211.916    &     8938.495     \\\\\n",
       "\\textbf{8606.0}      &    9996.9128  &     3074.136     &     3.252  &         0.001        &     3971.140    &      1.6e+04     \\\\\n",
       "\\textbf{8607.0}      &    1.008e+04  &     3199.827     &     3.150  &         0.002        &     3805.949    &     1.64e+04     \\\\\n",
       "\\textbf{8648.0}      &    8703.5470  &     3078.394     &     2.827  &         0.005        &     2669.428    &     1.47e+04     \\\\\n",
       "\\textbf{8657.0}      &    4027.2377  &     3062.602     &     1.315  &         0.189        &    -1975.927    &        1e+04     \\\\\n",
       "\\textbf{8675.0}      &    9234.4663  &     4423.761     &     2.087  &         0.037        &      563.222    &     1.79e+04     \\\\\n",
       "\\textbf{8681.0}      &    5022.8681  &     2990.914     &     1.679  &         0.093        &     -839.778    &     1.09e+04     \\\\\n",
       "\\textbf{8687.0}      &    6865.4753  &     3330.626     &     2.061  &         0.039        &      336.943    &     1.34e+04     \\\\\n",
       "\\textbf{8692.0}      &    6724.1365  &     3040.648     &     2.211  &         0.027        &      764.005    &     1.27e+04     \\\\\n",
       "\\textbf{8699.0}      &    9368.7656  &     3104.748     &     3.018  &         0.003        &     3282.988    &     1.55e+04     \\\\\n",
       "\\textbf{8717.0}      &    1.007e+04  &     3139.976     &     3.206  &         0.001        &     3910.883    &     1.62e+04     \\\\\n",
       "\\textbf{8759.0}      &    6032.6233  &     3129.293     &     1.928  &         0.054        &     -101.267    &     1.22e+04     \\\\\n",
       "\\textbf{8762.0}      &    1.005e+04  &     3163.140     &     3.177  &         0.001        &     3847.994    &     1.62e+04     \\\\\n",
       "\\textbf{8819.0}      &     1.08e+04  &     3255.498     &     3.319  &         0.001        &     4422.683    &     1.72e+04     \\\\\n",
       "\\textbf{8850.0}      &    9180.3611  &     3099.787     &     2.962  &         0.003        &     3104.308    &     1.53e+04     \\\\\n",
       "\\textbf{8852.0}      &    9396.6270  &     3137.971     &     2.994  &         0.003        &     3245.728    &     1.55e+04     \\\\\n",
       "\\textbf{8859.0}      &    9958.6402  &     3172.396     &     3.139  &         0.002        &     3740.263    &     1.62e+04     \\\\\n",
       "\\textbf{8867.0}      &    2878.0832  &     3278.995     &     0.878  &         0.380        &    -3549.244    &     9305.411     \\\\\n",
       "\\textbf{8881.0}      &    7955.4694  &     3090.496     &     2.574  &         0.010        &     1897.629    &      1.4e+04     \\\\\n",
       "\\textbf{8958.0}      &    7012.8960  &     3062.779     &     2.290  &         0.022        &     1009.384    &      1.3e+04     \\\\\n",
       "\\textbf{8972.0}      &   -1.071e+04  &     3041.870     &    -3.522  &         0.000        &    -1.67e+04    &    -4751.155     \\\\\n",
       "\\textbf{8990.0}      &     237.8112  &     3143.690     &     0.076  &         0.940        &    -5924.298    &     6399.920     \\\\\n",
       "\\textbf{9004.0}      &    1.047e+04  &     3372.333     &     3.105  &         0.002        &     3861.201    &     1.71e+04     \\\\\n",
       "\\textbf{9016.0}      &    7304.7780  &     3039.777     &     2.403  &         0.016        &     1346.353    &     1.33e+04     \\\\\n",
       "\\textbf{9048.0}      &    6403.1328  &     3012.256     &     2.126  &         0.034        &      498.654    &     1.23e+04     \\\\\n",
       "\\textbf{9051.0}      &    1965.6327  &     3401.698     &     0.578  &         0.563        &    -4702.212    &     8633.478     \\\\\n",
       "\\textbf{9071.0}      &    6269.8156  &     3082.415     &     2.034  &         0.042        &      227.814    &     1.23e+04     \\\\\n",
       "\\textbf{9112.0}      &    5595.9253  &     3023.816     &     1.851  &         0.064        &     -331.214    &     1.15e+04     \\\\\n",
       "\\textbf{9114.0}      &    3815.5590  &     3108.453     &     1.227  &         0.220        &    -2277.481    &     9908.599     \\\\\n",
       "\\textbf{9132.0}      &    9293.0465  &     4448.428     &     2.089  &         0.037        &      573.452    &      1.8e+04     \\\\\n",
       "\\textbf{9173.0}      &    8593.1758  &     3436.473     &     2.501  &         0.012        &     1857.168    &     1.53e+04     \\\\\n",
       "\\textbf{9180.0}      &    9960.1426  &     3212.901     &     3.100  &         0.002        &     3662.368    &     1.63e+04     \\\\\n",
       "\\textbf{9186.0}      &    8369.7659  &     3096.656     &     2.703  &         0.007        &     2299.850    &     1.44e+04     \\\\\n",
       "\\textbf{9191.0}      &    5236.9855  &     4093.728     &     1.279  &         0.201        &    -2787.343    &     1.33e+04     \\\\\n",
       "\\textbf{9216.0}      &    3177.1857  &     2977.132     &     1.067  &         0.286        &    -2658.445    &     9012.817     \\\\\n",
       "\\textbf{9217.0}      &     345.3862  &     2964.765     &     0.116  &         0.907        &    -5466.004    &     6156.777     \\\\\n",
       "\\textbf{9225.0}      &    9669.4538  &     3102.778     &     3.116  &         0.002        &     3587.537    &     1.58e+04     \\\\\n",
       "\\textbf{9230.0}      &    1.017e+04  &     3631.753     &     2.800  &         0.005        &     3049.714    &     1.73e+04     \\\\\n",
       "\\textbf{9259.0}      &    1.082e+04  &     3195.981     &     3.387  &         0.001        &     4559.228    &     1.71e+04     \\\\\n",
       "\\textbf{9293.0}      &    9826.5015  &     3129.155     &     3.140  &         0.002        &     3692.884    &      1.6e+04     \\\\\n",
       "\\textbf{9299.0}      &    4757.1723  &     3068.861     &     1.550  &         0.121        &    -1258.262    &     1.08e+04     \\\\\n",
       "\\textbf{9308.0}      &    5449.7947  &     3213.596     &     1.696  &         0.090        &     -849.341    &     1.17e+04     \\\\\n",
       "\\textbf{9311.0}      &    6091.4889  &     4097.403     &     1.487  &         0.137        &    -1940.043    &     1.41e+04     \\\\\n",
       "\\textbf{9313.0}      &    4314.0795  &     3025.653     &     1.426  &         0.154        &    -1616.660    &     1.02e+04     \\\\\n",
       "\\textbf{9325.0}      &    8571.9786  &     3107.010     &     2.759  &         0.006        &     2481.767    &     1.47e+04     \\\\\n",
       "\\textbf{9332.0}      &    7832.2604  &     3050.287     &     2.568  &         0.010        &     1853.235    &     1.38e+04     \\\\\n",
       "\\textbf{9340.0}      &   -1.284e+04  &     4266.321     &    -3.009  &         0.003        &    -2.12e+04    &    -4476.619     \\\\\n",
       "\\textbf{9372.0}      &    1.011e+04  &     3506.811     &     2.883  &         0.004        &     3237.019    &      1.7e+04     \\\\\n",
       "\\textbf{9411.0}      &    6355.8057  &     3158.698     &     2.012  &         0.044        &      164.278    &     1.25e+04     \\\\\n",
       "\\textbf{9459.0}      &    4594.2014  &     3082.822     &     1.490  &         0.136        &    -1448.598    &     1.06e+04     \\\\\n",
       "\\textbf{9465.0}      &    1.241e+04  &     3064.660     &     4.049  &         0.000        &     6402.210    &     1.84e+04     \\\\\n",
       "\\textbf{9472.0}      &    4269.6200  &     2986.010     &     1.430  &         0.153        &    -1583.412    &     1.01e+04     \\\\\n",
       "\\textbf{9483.0}      &    -216.2534  &     3044.454     &    -0.071  &         0.943        &    -6183.846    &     5751.340     \\\\\n",
       "\\textbf{9563.0}      &   -1.792e+04  &     4211.763     &    -4.256  &         0.000        &    -2.62e+04    &    -9668.157     \\\\\n",
       "\\textbf{9590.0}      &    7000.0639  &     3121.546     &     2.242  &         0.025        &      881.359    &     1.31e+04     \\\\\n",
       "\\textbf{9598.0}      &    4487.5163  &     3762.106     &     1.193  &         0.233        &    -2886.783    &     1.19e+04     \\\\\n",
       "\\textbf{9599.0}      &    3721.4346  &     3033.177     &     1.227  &         0.220        &    -2224.052    &     9666.921     \\\\\n",
       "\\textbf{9602.0}      &    3023.8387  &     4071.341     &     0.743  &         0.458        &    -4956.608    &      1.1e+04     \\\\\n",
       "\\textbf{9619.0}      &    1.003e+04  &     3221.664     &     3.113  &         0.002        &     3715.041    &     1.63e+04     \\\\\n",
       "\\textbf{9643.0}      &    6673.9738  &     3111.149     &     2.145  &         0.032        &      575.650    &     1.28e+04     \\\\\n",
       "\\textbf{9650.0}      &    5948.1118  &     3049.133     &     1.951  &         0.051        &      -28.652    &     1.19e+04     \\\\\n",
       "\\textbf{9653.0}      &   -5201.1049  &     5261.293     &    -0.989  &         0.323        &    -1.55e+04    &     5111.828     \\\\\n",
       "\\textbf{9667.0}      &    5978.4574  &     3032.475     &     1.971  &         0.049        &       34.345    &     1.19e+04     \\\\\n",
       "\\textbf{9698.0}      &    8360.8550  &     3113.996     &     2.685  &         0.007        &     2256.949    &     1.45e+04     \\\\\n",
       "\\textbf{9699.0}      &    9695.4952  &     3081.120     &     3.147  &         0.002        &     3656.031    &     1.57e+04     \\\\\n",
       "\\textbf{9719.0}      &    1673.7655  &     2960.502     &     0.565  &         0.572        &    -4129.267    &     7476.798     \\\\\n",
       "\\textbf{9742.0}      &    1462.5312  &     3123.254     &     0.468  &         0.640        &    -4659.520    &     7584.583     \\\\\n",
       "\\textbf{9761.0}      &    9161.1397  &     3123.661     &     2.933  &         0.003        &     3038.290    &     1.53e+04     \\\\\n",
       "\\textbf{9771.0}      &    2489.7585  &     2963.761     &     0.840  &         0.401        &    -3319.664    &     8299.181     \\\\\n",
       "\\textbf{9772.0}      &    9912.5502  &     3147.378     &     3.149  &         0.002        &     3743.211    &     1.61e+04     \\\\\n",
       "\\textbf{9778.0}      &    7202.1314  &     3024.139     &     2.382  &         0.017        &     1274.359    &     1.31e+04     \\\\\n",
       "\\textbf{9799.0}      &    1707.7949  &     3109.095     &     0.549  &         0.583        &    -4386.503    &     7802.093     \\\\\n",
       "\\textbf{9815.0}      &    9088.3459  &     3223.230     &     2.820  &         0.005        &     2770.327    &     1.54e+04     \\\\\n",
       "\\textbf{9818.0}      &   -3.452e+04  &     3202.790     &   -10.779  &         0.000        &    -4.08e+04    &    -2.82e+04     \\\\\n",
       "\\textbf{9837.0}      &    1.056e+04  &     3244.249     &     3.254  &         0.001        &     4198.886    &     1.69e+04     \\\\\n",
       "\\textbf{9922.0}      &    2994.0482  &     3000.566     &     0.998  &         0.318        &    -2887.517    &     8875.613     \\\\\n",
       "\\textbf{9954.0}      &    5697.1012  &     3683.632     &     1.547  &         0.122        &    -1523.378    &     1.29e+04     \\\\\n",
       "\\textbf{9963.0}      &    7227.4542  &     3090.223     &     2.339  &         0.019        &     1170.149    &     1.33e+04     \\\\\n",
       "\\textbf{9988.0}      &    1.018e+04  &     3189.909     &     3.192  &         0.001        &     3928.483    &     1.64e+04     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 21744.289 & \\textbf{  Durbin-Watson:     } &      0.548    \\\\\n",
       "\\textbf{Prob(Omnibus):} &    0.000  & \\textbf{  Jarque-Bera (JB):  } & 50237524.155  \\\\\n",
       "\\textbf{Skew:}          &   10.223  & \\textbf{  Prob(JB):          } &       0.00    \\\\\n",
       "\\textbf{Kurtosis:}      &  302.434  & \\textbf{  Cond. No.          } &   2.00e+07    \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large,  2e+07. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 rmkvaf   R-squared:                       0.665\n",
       "Model:                            OLS   Adj. R-squared:                  0.645\n",
       "Method:                 Least Squares   F-statistic:                     33.22\n",
       "Date:                Fri, 18 Oct 2024   Prob (F-statistic):               0.00\n",
       "Time:                        18:53:18   Log-Likelihood:            -1.4157e+05\n",
       "No. Observations:               13385   AIC:                         2.847e+05\n",
       "Df Residuals:                   12629   BIC:                         2.903e+05\n",
       "Df Model:                         755                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "const       -9940.5765   2385.347     -4.167      0.000   -1.46e+04   -5264.935\n",
       "gspilltecIV     0.1002      0.027      3.746      0.000       0.048       0.153\n",
       "gspillsicIV     0.3399      0.049      6.902      0.000       0.243       0.436\n",
       "pat_count     -30.6018      1.838    -16.652      0.000     -34.204     -26.999\n",
       "rsales          0.7812      0.037     21.055      0.000       0.708       0.854\n",
       "rppent          0.6108      0.084      7.234      0.000       0.445       0.776\n",
       "emp            18.0641      7.147      2.527      0.012       4.054      32.074\n",
       "rxrd           18.5941      0.614     30.295      0.000      17.391      19.797\n",
       "1981         -425.5119    618.180     -0.688      0.491   -1637.239     786.215\n",
       "1982         -295.2372    616.239     -0.479      0.632   -1503.159     912.685\n",
       "1983         -294.1870    609.557     -0.483      0.629   -1489.011     900.637\n",
       "1984         -812.2257    607.964     -1.336      0.182   -2003.927     379.476\n",
       "1985         -929.1950    609.921     -1.523      0.128   -2124.732     266.343\n",
       "1986        -1184.5891    607.667     -1.949      0.051   -2375.708       6.530\n",
       "1987        -1372.3041    607.937     -2.257      0.024   -2563.953    -180.655\n",
       "1988        -1686.4878    609.953     -2.765      0.006   -2882.088    -490.888\n",
       "1989        -1550.4891    610.972     -2.538      0.011   -2748.088    -352.891\n",
       "1990        -2052.0735    612.118     -3.352      0.001   -3251.918    -852.228\n",
       "1991        -1629.8854    614.732     -2.651      0.008   -2834.854    -424.917\n",
       "1992        -1754.6866    617.583     -2.841      0.005   -2965.243    -544.130\n",
       "1993        -1685.0176    621.230     -2.712      0.007   -2902.723    -467.312\n",
       "1994        -1916.7490    627.407     -3.055      0.002   -3146.563    -686.935\n",
       "1995        -1380.6021    636.986     -2.167      0.030   -2629.191    -132.013\n",
       "1996        -1098.4502    651.099     -1.687      0.092   -2374.702     177.802\n",
       "1997         -692.3174    667.994     -1.036      0.300   -2001.686     617.051\n",
       "1998         -575.0406    687.698     -0.836      0.403   -1923.033     772.951\n",
       "1999          142.3167    710.226      0.200      0.841   -1249.835    1534.468\n",
       "2000         -207.4580    738.322     -0.281      0.779   -1654.682    1239.766\n",
       "2001        -2283.3834    768.945     -2.970      0.003   -3790.633    -776.134\n",
       "10005.0      8596.1312   3076.471      2.794      0.005    2565.781    1.46e+04\n",
       "10006.0      8240.3993   3516.122      2.344      0.019    1348.266    1.51e+04\n",
       "10008.0      7558.3544   3040.531      2.486      0.013    1598.452    1.35e+04\n",
       "10016.0      8488.3062   3060.494      2.774      0.006    2489.273    1.45e+04\n",
       "10030.0      9963.3568   3135.789      3.177      0.001    3816.734    1.61e+04\n",
       "1004.0       9403.1634   3133.966      3.000      0.003    3260.115    1.55e+04\n",
       "10056.0      7589.4824   3061.708      2.479      0.013    1588.069    1.36e+04\n",
       "10085.0      4090.3185   2997.861      1.364      0.172   -1785.945    9966.582\n",
       "10092.0      9204.1913   5393.483      1.707      0.088   -1367.854    1.98e+04\n",
       "10097.0      2206.4047   2993.452      0.737      0.461   -3661.215    8074.024\n",
       "1010.0       8207.1099   5379.135      1.526      0.127   -2336.812    1.88e+04\n",
       "10109.0      1.097e+04   3193.217      3.436      0.001    4711.604    1.72e+04\n",
       "10115.0      7957.3563   3058.537      2.602      0.009    1962.159     1.4e+04\n",
       "10124.0       1.11e+04   3199.490      3.470      0.001    4829.168    1.74e+04\n",
       "1013.0       4769.1715   2983.003      1.599      0.110   -1077.968    1.06e+04\n",
       "10150.0      3170.2099   3465.956      0.915      0.360   -3623.590    9964.010\n",
       "10159.0      3378.9006   4384.246      0.771      0.441   -5214.887     1.2e+04\n",
       "10174.0      1.021e+04   3389.760      3.012      0.003    3565.375    1.69e+04\n",
       "10185.0      8313.1068   3338.064      2.490      0.013    1769.995    1.49e+04\n",
       "10195.0      2593.7222   3141.189      0.826      0.409   -3563.486    8750.931\n",
       "10198.0      9933.5369   3131.022      3.173      0.002    3796.259    1.61e+04\n",
       "10215.0       1.08e+04   3193.341      3.381      0.001    4537.838    1.71e+04\n",
       "10232.0      6925.4903   3326.104      2.082      0.037     405.821    1.34e+04\n",
       "10236.0      9750.4628   3137.458      3.108      0.002    3600.569    1.59e+04\n",
       "10286.0      8274.2845   3121.219      2.651      0.008    2156.221    1.44e+04\n",
       "10301.0     -1.476e+04   3014.308     -4.895      0.000   -2.07e+04   -8846.626\n",
       "10312.0      9198.1294   3124.523      2.944      0.003    3073.591    1.53e+04\n",
       "10332.0      3868.1997   4061.176      0.952      0.341   -4092.322    1.18e+04\n",
       "1036.0       7245.0618   3261.623      2.221      0.026     851.786    1.36e+04\n",
       "10374.0      8066.1980   3065.104      2.632      0.009    2058.129    1.41e+04\n",
       "10386.0      4140.6626   2986.789      1.386      0.166   -1713.897    9995.222\n",
       "10391.0      1064.5542   3026.844      0.352      0.725   -4868.521    6997.629\n",
       "10407.0      4895.6611   3017.572      1.622      0.105   -1019.237    1.08e+04\n",
       "10420.0      8765.7651   3082.897      2.843      0.004    2722.820    1.48e+04\n",
       "10422.0      6959.5604   3252.126      2.140      0.032     584.899    1.33e+04\n",
       "10426.0      9660.2255   3299.137      2.928      0.003    3193.415    1.61e+04\n",
       "10441.0      1.026e+04   3164.254      3.241      0.001    4053.796    1.65e+04\n",
       "1045.0      -1654.6262   3243.965     -0.510      0.610   -8013.291    4704.038\n",
       "10453.0      4005.2538   2991.151      1.339      0.181   -1857.856    9868.364\n",
       "10482.0      -1.46e+04   3475.563     -4.201      0.000   -2.14e+04   -7789.183\n",
       "10498.0      9301.1887   3158.846      2.944      0.003    3109.370    1.55e+04\n",
       "10499.0       290.8155   3069.162      0.095      0.925   -5725.207    6306.838\n",
       "10511.0      1.071e+04   3287.724      3.258      0.001    4268.117    1.72e+04\n",
       "10519.0     -5675.1567   2981.921     -1.903      0.057   -1.15e+04     169.862\n",
       "10530.0      5301.0836   3009.281      1.762      0.078    -597.565    1.12e+04\n",
       "10537.0      6186.0975   3392.545      1.823      0.068    -463.806    1.28e+04\n",
       "10540.0      7576.5476   3032.964      2.498      0.012    1631.477    1.35e+04\n",
       "10541.0      8964.6580   3229.126      2.776      0.006    2635.080    1.53e+04\n",
       "10550.0      6593.4131   6048.079      1.090      0.276   -5261.741    1.84e+04\n",
       "10553.0      3851.8113   3153.072      1.222      0.222   -2328.689       1e+04\n",
       "10565.0      1.053e+04   3138.295      3.355      0.001    4378.941    1.67e+04\n",
       "10580.0       1.08e+04   3213.498      3.360      0.001    4498.657    1.71e+04\n",
       "10581.0      7665.2631   3106.263      2.468      0.014    1576.515    1.38e+04\n",
       "10588.0      1176.5368   2963.147      0.397      0.691   -4631.681    6984.754\n",
       "10597.0      8900.5001   3128.719      2.845      0.004    2767.736     1.5e+04\n",
       "10599.0      9271.0496   3139.906      2.953      0.003    3116.357    1.54e+04\n",
       "10618.0      8556.4419   3093.780      2.766      0.006    2492.162    1.46e+04\n",
       "10656.0      8664.1385   3068.114      2.824      0.005    2650.168    1.47e+04\n",
       "10658.0      8540.1624   3064.938      2.786      0.005    2532.418    1.45e+04\n",
       "10726.0      1.264e+04   3268.775      3.866      0.000    6231.058     1.9e+04\n",
       "10734.0      8389.8503   3727.109      2.251      0.024    1084.150    1.57e+04\n",
       "10735.0      1.002e+04   3173.342      3.159      0.002    3803.931    1.62e+04\n",
       "10764.0      1.051e+04   3276.657      3.207      0.001    4084.421    1.69e+04\n",
       "10777.0      8530.3531   3067.334      2.781      0.005    2517.913    1.45e+04\n",
       "1078.0       5453.6061   3082.313      1.769      0.077    -588.196    1.15e+04\n",
       "10793.0      8093.7684   3137.200      2.580      0.010    1944.380    1.42e+04\n",
       "10816.0      7496.2748   3087.546      2.428      0.015    1444.216    1.35e+04\n",
       "10839.0      9481.3260   3097.020      3.061      0.002    3410.697    1.56e+04\n",
       "10857.0     -2182.7305   3058.140     -0.714      0.475   -8177.148    3811.687\n",
       "10867.0      4643.9565   3339.296      1.391      0.164   -1901.571    1.12e+04\n",
       "10906.0      8932.4951   3098.783      2.883      0.004    2858.410     1.5e+04\n",
       "10950.0      9034.0200   4140.834      2.182      0.029     917.357    1.72e+04\n",
       "10983.0     -2.383e+04   3227.575     -7.383      0.000   -3.02e+04   -1.75e+04\n",
       "1099.0       8536.2893   3106.895      2.748      0.006    2446.304    1.46e+04\n",
       "10991.0      6926.2901   3614.928      1.916      0.055    -159.519     1.4e+04\n",
       "11012.0      7880.6911   3137.824      2.512      0.012    1730.080     1.4e+04\n",
       "11038.0      3251.3206   3219.125      1.010      0.313   -3058.654    9561.295\n",
       "1104.0       9488.5996   3138.344      3.023      0.003    3336.969    1.56e+04\n",
       "11060.0      9235.2591   3132.146      2.949      0.003    3095.777    1.54e+04\n",
       "11094.0      8684.5592   3089.265      2.811      0.005    2629.130    1.47e+04\n",
       "11096.0      6740.1208   3028.318      2.226      0.026     804.158    1.27e+04\n",
       "11113.0      9316.9328   3367.569      2.767      0.006    2715.986    1.59e+04\n",
       "1115.0       7875.2019   3125.463      2.520      0.012    1748.819     1.4e+04\n",
       "11161.0      6631.5622   3048.603      2.175      0.030     655.838    1.26e+04\n",
       "11225.0      1.031e+04   3223.600      3.198      0.001    3991.623    1.66e+04\n",
       "11228.0      1.001e+04   3111.122      3.217      0.001    3909.102    1.61e+04\n",
       "11236.0      4820.4345   4564.449      1.056      0.291   -4126.579    1.38e+04\n",
       "11288.0       726.5183   3139.333      0.231      0.817   -5427.050    6880.087\n",
       "11312.0       624.6433   3085.276      0.202      0.840   -5422.965    6672.252\n",
       "11361.0      8139.1393   3054.443      2.665      0.008    2151.966    1.41e+04\n",
       "11399.0      1883.4788   2984.861      0.631      0.528   -3967.302    7734.260\n",
       "114303.0    -8981.4766   5402.255     -1.663      0.096   -1.96e+04    1607.764\n",
       "11456.0      3026.3818   3078.672      0.983      0.326   -3008.282    9061.046\n",
       "11465.0      4113.0085   3092.455      1.330      0.184   -1948.673    1.02e+04\n",
       "11502.0      9343.9264   3174.590      2.943      0.003    3121.249    1.56e+04\n",
       "11506.0      4190.2588   3073.981      1.363      0.173   -1835.210    1.02e+04\n",
       "11537.0      9104.8465   3090.809      2.946      0.003    3046.392    1.52e+04\n",
       "11566.0      1.069e+04   3188.150      3.352      0.001    4436.526    1.69e+04\n",
       "11573.0      8122.9750   3053.915      2.660      0.008    2136.837    1.41e+04\n",
       "11580.0      4660.7676   3401.528      1.370      0.171   -2006.744    1.13e+04\n",
       "11600.0      9955.4797   3181.578      3.129      0.002    3719.104    1.62e+04\n",
       "11609.0      1.339e+04   3141.316      4.263      0.000    7234.942    1.95e+04\n",
       "1161.0      -1142.7795   2963.636     -0.386      0.700   -6951.956    4666.397\n",
       "11636.0     -1.033e+04   3195.420     -3.234      0.001   -1.66e+04   -4069.451\n",
       "11670.0      1.045e+04   3195.585      3.270      0.001    4186.263    1.67e+04\n",
       "11678.0      -172.3965   3111.159     -0.055      0.956   -6270.740    5925.947\n",
       "11682.0      8157.6451   3195.335      2.553      0.011    1894.303    1.44e+04\n",
       "11694.0      9735.1845   3265.189      2.982      0.003    3334.919    1.61e+04\n",
       "11720.0      2342.1807   3978.963      0.589      0.556   -5457.192    1.01e+04\n",
       "11721.0     -3708.6926   3442.247     -1.077      0.281   -1.05e+04    3038.635\n",
       "11722.0      7939.5465   3308.424      2.400      0.016    1454.532    1.44e+04\n",
       "11793.0      6392.4048   6063.166      1.054      0.292   -5492.321    1.83e+04\n",
       "11797.0      1.098e+04   3552.518      3.091      0.002    4015.910    1.79e+04\n",
       "11914.0      9253.8306   3755.065      2.464      0.014    1893.333    1.66e+04\n",
       "1209.0       6916.3882   3021.090      2.289      0.022     994.593    1.28e+04\n",
       "12136.0     -5842.3430   3290.133     -1.776      0.076   -1.23e+04     606.816\n",
       "12141.0      8.981e+04   3291.619     27.284      0.000    8.34e+04    9.63e+04\n",
       "12181.0      6468.7957   4281.785      1.511      0.131   -1924.153    1.49e+04\n",
       "12215.0      -753.1168   3219.104     -0.234      0.815   -7063.050    5556.816\n",
       "12216.0      3866.8554   3252.277      1.189      0.234   -2508.101    1.02e+04\n",
       "12256.0      2682.4219   3240.915      0.828      0.408   -3670.264    9035.107\n",
       "12262.0      9564.5090   3423.360      2.794      0.005    2854.203    1.63e+04\n",
       "12389.0      8986.4050   3304.204      2.720      0.007    2509.663    1.55e+04\n",
       "1239.0       6577.3859   3030.471      2.170      0.030     637.203    1.25e+04\n",
       "12390.0      7461.3813   3602.948      2.071      0.038     399.057    1.45e+04\n",
       "12397.0      6292.8548   5345.675      1.177      0.239   -4185.481    1.68e+04\n",
       "1243.0       4184.8534   3158.124      1.325      0.185   -2005.548    1.04e+04\n",
       "12548.0      9038.3456   3632.299      2.488      0.013    1918.488    1.62e+04\n",
       "12570.0      8969.7124   3499.499      2.563      0.010    2110.162    1.58e+04\n",
       "12581.0      6220.9585   3679.891      1.691      0.091    -992.187    1.34e+04\n",
       "12592.0      7907.3965   3465.117      2.282      0.023    1115.241    1.47e+04\n",
       "12604.0      7117.2488   6104.480      1.166      0.244   -4848.459    1.91e+04\n",
       "12656.0      1.071e+04   3513.018      3.048      0.002    3822.505    1.76e+04\n",
       "12679.0     -8243.1620   3377.006     -2.441      0.015   -1.49e+04   -1623.718\n",
       "1278.0       9559.3089   3276.729      2.917      0.004    3136.423     1.6e+04\n",
       "12788.0     -2571.9810   3720.888     -0.691      0.489   -9865.486    4721.524\n",
       "1283.0       9778.5694   3188.479      3.067      0.002    3528.666     1.6e+04\n",
       "1297.0       8851.0971   3160.094      2.801      0.005    2656.833     1.5e+04\n",
       "12992.0      1.022e+04   3469.470      2.945      0.003    3415.928     1.7e+04\n",
       "13135.0      5736.5602   3444.412      1.665      0.096   -1015.010    1.25e+04\n",
       "1327.0       2830.7666   3184.260      0.889      0.374   -3410.866    9072.399\n",
       "13282.0      3707.5355   5340.406      0.694      0.488   -6760.470    1.42e+04\n",
       "1334.0       1959.2153   3392.421      0.578      0.564   -4690.446    8608.876\n",
       "13351.0      3934.9513   3942.379      0.998      0.318   -3792.710    1.17e+04\n",
       "13365.0     -7664.6310   3538.787     -2.166      0.030   -1.46e+04    -728.070\n",
       "13369.0      6192.2784   3353.245      1.847      0.065    -380.592    1.28e+04\n",
       "13406.0      9511.9068   3422.019      2.780      0.005    2804.230    1.62e+04\n",
       "13407.0      3435.2039   3325.530      1.033      0.302   -3083.341    9953.749\n",
       "13417.0      1.054e+04   3627.974      2.906      0.004    3431.229    1.77e+04\n",
       "13525.0      2730.9588   3557.222      0.768      0.443   -4241.736    9703.654\n",
       "13554.0       1.11e+04   3515.274      3.158      0.002    4209.150     1.8e+04\n",
       "1359.0        231.6921   3271.221      0.071      0.944   -6180.398    6643.783\n",
       "13623.0      7757.8946   3398.861      2.282      0.022    1095.611    1.44e+04\n",
       "1372.0       2969.1064   3094.408      0.960      0.337   -3096.404    9034.616\n",
       "1380.0       2428.4690   3086.422      0.787      0.431   -3621.386    8478.324\n",
       "13923.0      9004.3585   3723.204      2.418      0.016    1706.314    1.63e+04\n",
       "13932.0      9906.5945   4225.421      2.345      0.019    1624.127    1.82e+04\n",
       "13941.0      -775.7343   3345.291     -0.232      0.817   -7333.012    5781.544\n",
       "1397.0       7611.2849   3344.240      2.276      0.023    1056.066    1.42e+04\n",
       "14064.0      7822.3534   3374.212      2.318      0.020    1208.386    1.44e+04\n",
       "14084.0      7161.9191   3367.382      2.127      0.033     561.340    1.38e+04\n",
       "14324.0      2450.1067   3416.939      0.717      0.473   -4247.612    9147.825\n",
       "14462.0      5896.9695   3424.853      1.722      0.085    -816.263    1.26e+04\n",
       "1447.0       1.291e+04   4617.436      2.796      0.005    3861.195     2.2e+04\n",
       "14531.0      6013.3098      1e+04      0.600      0.549   -1.36e+04    2.57e+04\n",
       "14593.0      9717.6801   3546.928      2.740      0.006    2765.162    1.67e+04\n",
       "14622.0      8494.5972   7256.705      1.171      0.242   -5729.646    2.27e+04\n",
       "1465.0       9293.7357   3759.137      2.472      0.013    1925.257    1.67e+04\n",
       "1468.0       9813.2527   3591.620      2.732      0.006    2773.133    1.69e+04\n",
       "14897.0      8912.7989   5404.388      1.649      0.099   -1680.623    1.95e+04\n",
       "14954.0      9310.1232   3588.857      2.594      0.009    2275.418    1.63e+04\n",
       "1496.0       1.018e+04   3142.118      3.241      0.001    4023.346    1.63e+04\n",
       "15267.0      8561.1899   3545.299      2.415      0.016    1611.865    1.55e+04\n",
       "15354.0      3951.6292   3545.461      1.115      0.265   -2998.013    1.09e+04\n",
       "1542.0       8274.0285   3128.411      2.645      0.008    2141.867    1.44e+04\n",
       "15459.0      4755.0666   3491.964      1.362      0.173   -2089.713    1.16e+04\n",
       "1554.0       1.008e+04   3139.681      3.211      0.001    3928.295    1.62e+04\n",
       "15708.0     -8685.5979   3678.105     -2.361      0.018   -1.59e+04   -1475.954\n",
       "15711.0      7018.0335   3521.077      1.993      0.046     116.187    1.39e+04\n",
       "15761.0      9603.3202   4161.317      2.308      0.021    1446.507    1.78e+04\n",
       "1581.0      -2.338e+04   4066.536     -5.750      0.000   -3.14e+04   -1.54e+04\n",
       "1593.0       7360.1914   3039.605      2.421      0.015    1402.105    1.33e+04\n",
       "1602.0       1.541e+04   3144.958      4.899      0.000    9241.495    2.16e+04\n",
       "1613.0       9518.7977   3135.907      3.035      0.002    3371.944    1.57e+04\n",
       "16188.0      6141.7233   3600.100      1.706      0.088    -915.020    1.32e+04\n",
       "1632.0       2730.6569   2967.596      0.920      0.358   -3086.281    8547.595\n",
       "1633.0       7645.1535   3073.458      2.487      0.013    1620.710    1.37e+04\n",
       "1635.0      -2279.6622   3207.382     -0.711      0.477   -8566.618    4007.294\n",
       "16401.0     -2106.7953   3535.255     -0.596      0.551   -9036.432    4822.842\n",
       "16437.0      2453.7358   4040.565      0.607      0.544   -5466.386    1.04e+04\n",
       "1651.0       5550.2093   3015.031      1.841      0.066    -359.709    1.15e+04\n",
       "1655.0       9615.4742   3116.290      3.086      0.002    3507.073    1.57e+04\n",
       "1663.0       1.375e+04   3117.223      4.412      0.000    7643.430    1.99e+04\n",
       "16710.0      4741.7051   3561.723      1.331      0.183   -2239.813    1.17e+04\n",
       "16729.0      4221.0150   3488.991      1.210      0.226   -2617.938    1.11e+04\n",
       "1690.0      -9476.8601   3052.010     -3.105      0.002   -1.55e+04   -3494.457\n",
       "1703.0       7131.1531   3145.834      2.267      0.023     964.841    1.33e+04\n",
       "17101.0     -1.039e+04   1.02e+04     -1.021      0.307   -3.04e+04    9567.672\n",
       "17202.0      8565.2847   3580.793      2.392      0.017    1546.386    1.56e+04\n",
       "1722.0       7635.3384   3120.097      2.447      0.014    1519.474    1.38e+04\n",
       "1728.0       9786.0208   3133.400      3.123      0.002    3644.082    1.59e+04\n",
       "1743.0       9206.6002   4065.126      2.265      0.024    1238.335    1.72e+04\n",
       "1754.0       9356.9783   3245.442      2.883      0.004    2995.419    1.57e+04\n",
       "1762.0       3530.4584   3070.682      1.150      0.250   -2488.544    9549.461\n",
       "1773.0       9383.6572   3200.790      2.932      0.003    3109.623    1.57e+04\n",
       "1786.0      -2446.1653   3027.221     -0.808      0.419   -8379.979    3487.648\n",
       "18100.0      7610.5863   3547.409      2.145      0.032     657.126    1.46e+04\n",
       "1820.0       7035.3148   3094.333      2.274      0.023     969.953    1.31e+04\n",
       "1848.0      -1341.5977   3489.590     -0.384      0.701   -8181.724    5498.529\n",
       "18654.0      9308.6209   4398.704      2.116      0.034     686.493    1.79e+04\n",
       "1875.0       5422.0706   4559.415      1.189      0.234   -3515.075    1.44e+04\n",
       "1884.0       9556.3065   3257.766      2.933      0.003    3170.590    1.59e+04\n",
       "1913.0       5067.5445   3013.058      1.682      0.093    -838.507     1.1e+04\n",
       "1919.0       8460.0632   3225.767      2.623      0.009    2137.070    1.48e+04\n",
       "1920.0       5677.3684   2997.340      1.894      0.058    -197.872    1.16e+04\n",
       "1968.0       7609.1915   3040.834      2.502      0.012    1648.695    1.36e+04\n",
       "1976.0       1.067e+04   3116.261      3.425      0.001    4565.380    1.68e+04\n",
       "1981.0       9170.2560   3119.840      2.939      0.003    3054.895    1.53e+04\n",
       "1988.0         67.7686   3946.416      0.017      0.986   -7667.806    7803.344\n",
       "1992.0       7764.2033   3046.140      2.549      0.011    1793.305    1.37e+04\n",
       "2008.0       8115.3533   3045.881      2.664      0.008    2144.965    1.41e+04\n",
       "2033.0       9191.5623   3578.712      2.568      0.010    2176.744    1.62e+04\n",
       "2044.0       7375.6500   3054.171      2.415      0.016    1389.011    1.34e+04\n",
       "2049.0       7958.9282   3057.521      2.603      0.009    1965.724     1.4e+04\n",
       "2061.0       1.067e+04   3184.425      3.350      0.001    4425.887    1.69e+04\n",
       "20779.0      5.298e+04   3626.010     14.611      0.000    4.59e+04    6.01e+04\n",
       "2085.0      -2797.9037   3091.351     -0.905      0.365   -8857.420    3261.613\n",
       "2086.0       6298.7693   3040.273      2.072      0.038     339.373    1.23e+04\n",
       "2111.0       7111.0506   3027.347      2.349      0.019    1176.992     1.3e+04\n",
       "21204.0      5065.4342   3773.658      1.342      0.180   -2331.508    1.25e+04\n",
       "21238.0      9630.2308   3715.731      2.592      0.010    2346.833    1.69e+04\n",
       "2124.0       7814.7292   3156.973      2.475      0.013    1626.582     1.4e+04\n",
       "2146.0       1.782e+04   3967.047      4.493      0.000       1e+04    2.56e+04\n",
       "21496.0     -9707.4783   3795.661     -2.558      0.011   -1.71e+04   -2267.406\n",
       "2154.0       8531.2191   3092.395      2.759      0.006    2469.654    1.46e+04\n",
       "2176.0       4.917e+04   3655.506     13.450      0.000     4.2e+04    5.63e+04\n",
       "2188.0       1.064e+04   3272.692      3.252      0.001    4229.171    1.71e+04\n",
       "2189.0       1987.7047   3044.824      0.653      0.514   -3980.612    7956.022\n",
       "2220.0       8121.7655   3066.803      2.648      0.008    2110.366    1.41e+04\n",
       "22205.0      1.097e+04   3742.158      2.932      0.003    3635.194    1.83e+04\n",
       "2226.0       6564.1694   6056.783      1.084      0.278   -5308.045    1.84e+04\n",
       "2230.0       9663.4059   3448.942      2.802      0.005    2902.955    1.64e+04\n",
       "22325.0      2036.3731   3623.720      0.562      0.574   -5066.669    9139.415\n",
       "2255.0       7276.8607   3077.041      2.365      0.018    1245.393    1.33e+04\n",
       "22619.0      9459.5788   3864.126      2.448      0.014    1885.306     1.7e+04\n",
       "2267.0       1604.9439   3063.270      0.524      0.600   -4399.530    7609.418\n",
       "22815.0      4875.5667   3570.634      1.365      0.172   -2123.419    1.19e+04\n",
       "2285.0      -2.061e+04   3176.312     -6.490      0.000   -2.68e+04   -1.44e+04\n",
       "2290.0       4219.0616   3064.579      1.377      0.169   -1787.979    1.02e+04\n",
       "2295.0        1.02e+04   4631.605      2.202      0.028    1118.124    1.93e+04\n",
       "2316.0       3932.7481   3268.816      1.203      0.229   -2474.628    1.03e+04\n",
       "23220.0      7708.2043   3613.811      2.133      0.033     624.587    1.48e+04\n",
       "23224.0     -1416.5488   3999.474     -0.354      0.723   -9256.124    6423.027\n",
       "2343.0        371.2913   5445.150      0.068      0.946   -1.03e+04     1.1e+04\n",
       "2352.0       7033.5174   3195.255      2.201      0.028     770.332    1.33e+04\n",
       "23700.0     -4104.2067   4540.832     -0.904      0.366    -1.3e+04    4796.514\n",
       "2390.0       1.022e+04   3146.886      3.249      0.001    4054.843    1.64e+04\n",
       "2393.0       5256.7276   3021.333      1.740      0.082    -665.543    1.12e+04\n",
       "2403.0       1.544e+04   3116.842      4.954      0.000    9331.361    2.16e+04\n",
       "2435.0       1.204e+04   3215.430      3.744      0.000    5734.523    1.83e+04\n",
       "2444.0       5543.3070   3031.522      1.829      0.067    -398.936    1.15e+04\n",
       "2448.0       7626.0071   3053.285      2.498      0.013    1641.104    1.36e+04\n",
       "2469.0       9427.6259   4407.154      2.139      0.032     788.935    1.81e+04\n",
       "24720.0      8470.8001   3726.615      2.273      0.023    1166.069    1.58e+04\n",
       "24800.0      2679.9470   3896.093      0.688      0.492   -4956.987    1.03e+04\n",
       "2482.0       1.036e+04   3154.774      3.283      0.001    4172.094    1.65e+04\n",
       "24969.0       1.01e+04   4399.409      2.296      0.022    1476.724    1.87e+04\n",
       "2498.0       2822.1067   3205.564      0.880      0.379   -3461.286    9105.499\n",
       "2504.0      -5740.6155   3125.446     -1.837      0.066   -1.19e+04     385.734\n",
       "2508.0       9551.1213   3313.820      2.882      0.004    3055.530     1.6e+04\n",
       "25124.0      8839.2099   3850.901      2.295      0.022    1290.860    1.64e+04\n",
       "2518.0       9462.2606   3118.179      3.035      0.002    3350.156    1.56e+04\n",
       "25224.0      9181.2871   7262.529      1.264      0.206   -5054.373    2.34e+04\n",
       "25279.0      8309.3827   3823.370      2.173      0.030     814.996    1.58e+04\n",
       "2537.0      -1331.6614   3141.364     -0.424      0.672   -7489.212    4825.889\n",
       "2538.0       1.059e+04   4051.182      2.615      0.009    2653.302    1.85e+04\n",
       "25389.0      1.016e+04   6108.961      1.663      0.096   -1815.943    2.21e+04\n",
       "2547.0       1402.5130   3210.761      0.437      0.662   -4891.066    7696.092\n",
       "2553.0       9104.4999   3154.705      2.886      0.004    2920.799    1.53e+04\n",
       "2574.0       2817.6652   3621.446      0.778      0.437   -4280.919    9916.249\n",
       "25747.0      8887.4249   3853.652      2.306      0.021    1333.682    1.64e+04\n",
       "2577.0       7333.8930   3033.785      2.417      0.016    1387.213    1.33e+04\n",
       "2593.0       7608.5207   3056.291      2.489      0.013    1617.727    1.36e+04\n",
       "2596.0       7104.2843   3165.531      2.244      0.025     899.363    1.33e+04\n",
       "2663.0       1.201e+04   3109.709      3.862      0.000    5914.315    1.81e+04\n",
       "2771.0       7170.4426   3157.640      2.271      0.023     980.989    1.34e+04\n",
       "2787.0       8843.2302   3108.248      2.845      0.004    2750.591    1.49e+04\n",
       "2797.0      -1136.7600   3047.444     -0.373      0.709   -7110.213    4836.693\n",
       "2802.0       9981.2391   3145.382      3.173      0.002    3815.813    1.61e+04\n",
       "2817.0      -2423.3733   3105.183     -0.780      0.435   -8510.003    3663.257\n",
       "28678.0     -6800.8821   3938.721     -1.727      0.084   -1.45e+04     919.610\n",
       "28701.0      7289.6069   3122.789      2.334      0.020    1168.466    1.34e+04\n",
       "28742.0     -4379.2282   4023.812     -1.088      0.276   -1.23e+04    3508.053\n",
       "2888.0       8333.3928   3213.797      2.593      0.010    2033.862    1.46e+04\n",
       "2897.0       9522.3975   3838.939      2.480      0.013    1997.494     1.7e+04\n",
       "2917.0       4179.7509   3174.337      1.317      0.188   -2042.431    1.04e+04\n",
       "29392.0     -4484.0845   3895.740     -1.151      0.250   -1.21e+04    3152.158\n",
       "2950.0      -8939.5631   4197.529     -2.130      0.033   -1.72e+04    -711.769\n",
       "2951.0       1.053e+04   3554.152      2.964      0.003    3567.561    1.75e+04\n",
       "2953.0       8670.7332   3081.692      2.814      0.005    2630.148    1.47e+04\n",
       "2960.0       6927.1661   3807.516      1.819      0.069    -536.143    1.44e+04\n",
       "2975.0       4129.9550   3074.147      1.343      0.179   -1895.841    1.02e+04\n",
       "2982.0       8607.4496   3114.061      2.764      0.006    2503.416    1.47e+04\n",
       "2991.0      -2091.3592   3611.129     -0.579      0.563   -9169.721    4987.002\n",
       "3011.0        352.0291   3228.393      0.109      0.913   -5976.112    6680.170\n",
       "3015.0       1.066e+04   3189.868      3.341      0.001    4404.847    1.69e+04\n",
       "3026.0       8297.5216   3114.849      2.664      0.008    2191.944    1.44e+04\n",
       "3031.0      -7156.8279   3963.813     -1.806      0.071   -1.49e+04     612.847\n",
       "3062.0       1.013e+04   3216.055      3.150      0.002    3827.484    1.64e+04\n",
       "3093.0       4614.1396   3380.925      1.365      0.172   -2012.986    1.12e+04\n",
       "3107.0       8261.4341   4593.460      1.799      0.072    -742.444    1.73e+04\n",
       "3121.0       1.075e+04   3100.529      3.467      0.001    4670.905    1.68e+04\n",
       "3126.0       8639.8575   3074.886      2.810      0.005    2612.613    1.47e+04\n",
       "3144.0       6.167e+04   3143.112     19.622      0.000    5.55e+04    6.78e+04\n",
       "3156.0       9057.0292   3556.046      2.547      0.011    2086.640     1.6e+04\n",
       "3157.0       8487.6305   3086.887      2.750      0.006    2436.864    1.45e+04\n",
       "3170.0       1.112e+04   3070.843      3.621      0.000    5098.953    1.71e+04\n",
       "3178.0       4719.2301   3279.399      1.439      0.150   -1708.889    1.11e+04\n",
       "3206.0       5242.4391   3326.387      1.576      0.115   -1277.785    1.18e+04\n",
       "3229.0       6940.2745   3201.204      2.168      0.030     665.428    1.32e+04\n",
       "3235.0       8557.6434   3259.016      2.626      0.009    2169.477    1.49e+04\n",
       "3246.0       8959.3648   3141.052      2.852      0.004    2802.426    1.51e+04\n",
       "3248.0       8795.1454   3144.903      2.797      0.005    2630.657     1.5e+04\n",
       "3282.0      -1.882e+04   3179.239     -5.919      0.000    -2.5e+04   -1.26e+04\n",
       "3362.0       1467.2473   3430.530      0.428      0.669   -5257.112    8191.606\n",
       "3372.0       8967.9006   3615.991      2.480      0.013    1880.009    1.61e+04\n",
       "3422.0       8150.3780   3116.503      2.615      0.009    2041.559    1.43e+04\n",
       "3497.0       3305.8909   3020.187      1.095      0.274   -2614.134    9225.916\n",
       "3502.0       4413.0364   3019.260      1.462      0.144   -1505.172    1.03e+04\n",
       "3504.0       7330.3624   3693.007      1.985      0.047      91.508    1.46e+04\n",
       "3505.0       6509.4875   3039.592      2.142      0.032     551.425    1.25e+04\n",
       "3532.0       9367.0102   3036.064      3.085      0.002    3415.864    1.53e+04\n",
       "3574.0       9567.2283   4941.074      1.936      0.053    -118.027    1.93e+04\n",
       "3580.0       5668.8773   3023.668      1.875      0.061    -257.971    1.16e+04\n",
       "3612.0       1.077e+04   3190.707      3.376      0.001    4518.562     1.7e+04\n",
       "3619.0       7583.6331   3125.470      2.426      0.015    1457.238    1.37e+04\n",
       "3622.0       1.024e+04   3247.561      3.154      0.002    3877.236    1.66e+04\n",
       "3639.0        701.7362   2978.785      0.236      0.814   -5137.134    6540.606\n",
       "3650.0        -56.5141   3013.203     -0.019      0.985   -5962.849    5849.821\n",
       "3662.0       6515.3615   3036.473      2.146      0.032     563.413    1.25e+04\n",
       "3734.0      -4540.5498   3009.478     -1.509      0.131   -1.04e+04    1358.485\n",
       "3735.0       5998.0243   3363.381      1.783      0.075    -594.714    1.26e+04\n",
       "3761.0       4676.2483   3019.021      1.549      0.121   -1241.491    1.06e+04\n",
       "3779.0      -1115.3957   3351.604     -0.333      0.739   -7685.049    5454.258\n",
       "3781.0       3388.6729   3657.813      0.926      0.354   -3781.196    1.06e+04\n",
       "3782.0       -945.5519   3097.134     -0.305      0.760   -7016.405    5125.302\n",
       "3786.0       8059.2754   3095.380      2.604      0.009    1991.860    1.41e+04\n",
       "3796.0      -1921.4741   3437.318     -0.559      0.576   -8659.140    4816.192\n",
       "3821.0       9374.5415   3182.442      2.946      0.003    3136.471    1.56e+04\n",
       "3835.0       1623.3259   3068.940      0.529      0.597   -4392.263    7638.914\n",
       "3839.0       5038.7123   3787.676      1.330      0.183   -2385.707    1.25e+04\n",
       "3840.0       3096.0560   3106.065      0.997      0.319   -2992.302    9184.414\n",
       "3895.0       9436.3688   3115.660      3.029      0.002    3329.202    1.55e+04\n",
       "3908.0       6499.5003   4150.425      1.566      0.117   -1635.964    1.46e+04\n",
       "3911.0       3978.4256   3062.447      1.299      0.194   -2024.435    9981.286\n",
       "3917.0       9644.8467   3201.184      3.013      0.003    3370.040    1.59e+04\n",
       "3946.0        1.02e+04   3163.781      3.224      0.001    3997.651    1.64e+04\n",
       "3971.0       8857.9912   3190.900      2.776      0.006    2603.342    1.51e+04\n",
       "3980.0       1.889e+04   3114.804      6.066      0.000    1.28e+04     2.5e+04\n",
       "4034.0       5433.4828   3023.927      1.797      0.072    -493.873    1.14e+04\n",
       "4036.0       1.006e+04   3132.064      3.210      0.001    3915.798    1.62e+04\n",
       "4040.0       4402.5134   3085.061      1.427      0.154   -1644.674    1.04e+04\n",
       "4058.0       8496.1476   3074.049      2.764      0.006    2470.545    1.45e+04\n",
       "4060.0      -8502.7681   3085.688     -2.756      0.006   -1.46e+04   -2454.351\n",
       "4062.0       1.245e+04   3186.197      3.906      0.000    6200.250    1.87e+04\n",
       "4077.0       8049.1131   4325.812      1.861      0.063    -430.135    1.65e+04\n",
       "4087.0      -1.922e+04   3417.870     -5.622      0.000   -2.59e+04   -1.25e+04\n",
       "4091.0       7764.4934   3536.914      2.195      0.028     831.604    1.47e+04\n",
       "4127.0       3991.2384   2983.946      1.338      0.181   -1857.749    9840.226\n",
       "4138.0       1.012e+04   3751.511      2.696      0.007    2761.757    1.75e+04\n",
       "4162.0       8848.7229   3711.438      2.384      0.017    1573.741    1.61e+04\n",
       "4186.0       1.029e+04   3147.338      3.271      0.001    4124.177    1.65e+04\n",
       "4194.0       -206.5396   3254.206     -0.063      0.949   -6585.277    6172.197\n",
       "4199.0      -3080.7950   2986.731     -1.031      0.302   -8935.242    2773.652\n",
       "4213.0       9040.9619   3063.929      2.951      0.003    3035.197     1.5e+04\n",
       "4222.0       -427.7763   3036.691     -0.141      0.888   -6380.151    5524.598\n",
       "4223.0       8795.2266   3075.179      2.860      0.004    2767.409    1.48e+04\n",
       "4251.0       9920.6121   3135.291      3.164      0.002    3774.966    1.61e+04\n",
       "4265.0       8311.0668   3331.549      2.495      0.013    1780.724    1.48e+04\n",
       "4274.0       7457.4585   3194.105      2.335      0.020    1196.528    1.37e+04\n",
       "4321.0       5939.8774   3058.043      1.942      0.052     -54.352    1.19e+04\n",
       "4335.0       7276.7703   4582.157      1.588      0.112   -1704.953    1.63e+04\n",
       "4340.0       6243.3898   3049.262      2.048      0.041     266.372    1.22e+04\n",
       "4371.0       6746.0318   3081.412      2.189      0.029     705.997    1.28e+04\n",
       "4415.0       9237.0407   3230.539      2.859      0.004    2904.693    1.56e+04\n",
       "4450.0       7979.6767   3101.329      2.573      0.010    1900.602    1.41e+04\n",
       "4476.0        675.3081   3174.296      0.213      0.832   -5546.793    6897.409\n",
       "4510.0       2475.6995   3026.171      0.818      0.413   -3456.054    8407.453\n",
       "4520.0       7980.2863   3051.589      2.615      0.009    1998.708     1.4e+04\n",
       "4551.0       8011.4429   7270.601      1.102      0.271   -6240.039    2.23e+04\n",
       "4568.0       8842.8576   3229.403      2.738      0.006    2512.738    1.52e+04\n",
       "4579.0       1.065e+04   3189.762      3.338      0.001    4393.423    1.69e+04\n",
       "4585.0       1.003e+04   3206.938      3.129      0.002    3747.041    1.63e+04\n",
       "4595.0       6865.7401   3039.451      2.259      0.024     907.954    1.28e+04\n",
       "4600.0       1012.0246   3200.037      0.316      0.752   -5260.535    7284.584\n",
       "4607.0       9896.4315   3136.909      3.155      0.002    3747.613     1.6e+04\n",
       "4608.0       1926.7708   3084.280      0.625      0.532   -4118.886    7972.428\n",
       "4622.0       5050.9157   3012.296      1.677      0.094    -853.642     1.1e+04\n",
       "4623.0       9205.2343   3264.415      2.820      0.005    2806.486    1.56e+04\n",
       "4768.0       8149.0733   3123.950      2.609      0.009    2025.657    1.43e+04\n",
       "4771.0        1.02e+04   3154.399      3.233      0.001    4014.036    1.64e+04\n",
       "4800.0       8510.9355   3222.793      2.641      0.008    2193.771    1.48e+04\n",
       "4802.0       9756.0632   3122.659      3.124      0.002    3635.177    1.59e+04\n",
       "4807.0       9311.2841   3209.003      2.902      0.004    3021.150    1.56e+04\n",
       "4839.0       -1.39e+05   4400.348    -31.598      0.000   -1.48e+05    -1.3e+05\n",
       "4843.0       -155.0920   3300.774     -0.047      0.963   -6625.111    6314.927\n",
       "4881.0       7349.9526   3033.927      2.423      0.015    1402.995    1.33e+04\n",
       "4900.0       8056.7145   3130.004      2.574      0.010    1921.431    1.42e+04\n",
       "4926.0       6951.4250   3036.486      2.289      0.022     999.451    1.29e+04\n",
       "4941.0       7701.0234   3119.428      2.469      0.014    1586.472    1.38e+04\n",
       "4961.0      -6713.3878   3845.668     -1.746      0.081   -1.43e+04     824.706\n",
       "4988.0       1.555e+04   3152.418      4.932      0.000    9368.460    2.17e+04\n",
       "4993.0       1.078e+04   3191.719      3.379      0.001    4527.925     1.7e+04\n",
       "5018.0       2756.6116   3051.145      0.903      0.366   -3224.095    8737.318\n",
       "5020.0       1703.6436   3206.794      0.531      0.595   -4582.160    7989.448\n",
       "5027.0       5583.6057   3073.165      1.817      0.069    -440.265    1.16e+04\n",
       "5032.0       8848.7731   3093.419      2.861      0.004    2785.202    1.49e+04\n",
       "5043.0       5765.7251   3056.378      1.886      0.059    -225.240    1.18e+04\n",
       "5046.0      -3742.7011   3008.827     -1.244      0.214   -9640.459    2155.057\n",
       "5047.0       4.951e+04   3945.666     12.549      0.000    4.18e+04    5.72e+04\n",
       "5065.0       9943.6682   3565.116      2.789      0.005    2955.499    1.69e+04\n",
       "5071.0       8402.8199   3506.244      2.397      0.017    1530.049    1.53e+04\n",
       "5073.0       -2.03e+05   6327.061    -32.087      0.000   -2.15e+05   -1.91e+05\n",
       "5087.0       4808.3060   3031.181      1.586      0.113   -1133.268    1.07e+04\n",
       "5109.0           1e+04   3156.702      3.169      0.002    3815.966    1.62e+04\n",
       "5116.0        331.7479   3230.260      0.103      0.918   -6000.052    6663.548\n",
       "5122.0       5093.7234   3033.485      1.679      0.093    -852.368     1.1e+04\n",
       "5134.0       1619.9886   3164.783      0.512      0.609   -4583.467    7823.444\n",
       "5142.0       6629.5952   3817.878      1.736      0.083    -854.026    1.41e+04\n",
       "5165.0       7201.9002   3418.120      2.107      0.035     501.866    1.39e+04\n",
       "5169.0       1.921e+04   3111.749      6.173      0.000    1.31e+04    2.53e+04\n",
       "5174.0       6861.1596   3315.866      2.069      0.039     361.558    1.34e+04\n",
       "5179.0       9522.8653   3123.992      3.048      0.002    3399.366    1.56e+04\n",
       "5181.0       1.022e+04   3247.843      3.148      0.002    3857.092    1.66e+04\n",
       "5187.0       1.051e+04   3595.928      2.924      0.003    3466.116    1.76e+04\n",
       "5229.0       1832.7007   2976.839      0.616      0.538   -4002.356    7667.757\n",
       "5234.0      -5223.8465   3133.458     -1.667      0.096   -1.14e+04     918.206\n",
       "5237.0       9043.0280   3101.586      2.916      0.004    2963.448    1.51e+04\n",
       "5252.0       8212.2020   3060.018      2.684      0.007    2214.102    1.42e+04\n",
       "5254.0       8446.7502   3097.320      2.727      0.006    2375.532    1.45e+04\n",
       "5306.0       6465.5650   3027.709      2.135      0.033     530.795    1.24e+04\n",
       "5338.0       9319.2221   3098.305      3.008      0.003    3246.074    1.54e+04\n",
       "5377.0       1.009e+04   3165.731      3.188      0.001    3885.677    1.63e+04\n",
       "5439.0       7334.3884   3132.147      2.342      0.019    1194.905    1.35e+04\n",
       "5456.0       1.067e+04   3219.404      3.313      0.001    4356.183     1.7e+04\n",
       "5464.0       8046.9137   3717.507      2.165      0.030     760.036    1.53e+04\n",
       "5476.0       1.038e+04   3188.810      3.254      0.001    4125.428    1.66e+04\n",
       "5492.0      -7692.0384   3028.409     -2.540      0.011   -1.36e+04   -1755.897\n",
       "5496.0       8328.8408   3078.327      2.706      0.007    2294.852    1.44e+04\n",
       "5505.0       9584.8474   3145.488      3.047      0.002    3419.213    1.58e+04\n",
       "5518.0       8040.5569   3394.234      2.369      0.018    1387.343    1.47e+04\n",
       "5520.0       7141.4059   3085.889      2.314      0.021    1092.595    1.32e+04\n",
       "5545.0       9850.2695   3257.198      3.024      0.002    3465.667    1.62e+04\n",
       "5568.0         1.2e+04   3131.140      3.834      0.000    5866.525    1.81e+04\n",
       "5569.0       1.006e+04   3173.656      3.171      0.002    3841.616    1.63e+04\n",
       "5578.0       9572.4372   3115.964      3.072      0.002    3464.675    1.57e+04\n",
       "5581.0       9414.8809   3097.341      3.040      0.002    3343.622    1.55e+04\n",
       "5589.0       2400.9953   2973.079      0.808      0.419   -3426.690    8228.681\n",
       "5597.0        1.13e+04   3648.090      3.097      0.002    4145.936    1.84e+04\n",
       "5606.0      -2.745e+04   3152.384     -8.709      0.000   -3.36e+04   -2.13e+04\n",
       "5639.0       1.082e+04   3159.665      3.425      0.001    4628.029     1.7e+04\n",
       "5667.0       7446.7098   3218.672      2.314      0.021    1137.624    1.38e+04\n",
       "5690.0       9706.2182   3117.215      3.114      0.002    3596.004    1.58e+04\n",
       "5709.0       9020.8914   3130.883      2.881      0.004    2883.886    1.52e+04\n",
       "5726.0       9123.8740   3144.647      2.901      0.004    2959.887    1.53e+04\n",
       "5764.0       7723.0628   3018.519      2.559      0.011    1806.306    1.36e+04\n",
       "5772.0       8901.7882   3086.811      2.884      0.004    2851.170     1.5e+04\n",
       "5860.0      -1.948e+04   3110.857     -6.261      0.000   -2.56e+04   -1.34e+04\n",
       "5878.0       1.119e+04   3037.648      3.682      0.000    5231.276    1.71e+04\n",
       "5903.0       4917.5431   3123.826      1.574      0.115   -1205.631     1.1e+04\n",
       "5905.0       6472.3316   3072.948      2.106      0.035     448.886    1.25e+04\n",
       "5959.0       4032.3371   3074.491      1.312      0.190   -1994.131    1.01e+04\n",
       "6008.0       2.842e+04   3030.015      9.380      0.000    2.25e+04    3.44e+04\n",
       "6034.0       5915.9539   3166.969      1.868      0.062    -291.787    1.21e+04\n",
       "6035.0       4321.0088   3624.230      1.192      0.233   -2783.033    1.14e+04\n",
       "6036.0        672.3068   2994.346      0.225      0.822   -5197.066    6541.680\n",
       "6039.0       9107.9457   3133.532      2.907      0.004    2965.747    1.53e+04\n",
       "6044.0       1.053e+04   3386.931      3.110      0.002    3894.343    1.72e+04\n",
       "6066.0       -2.49e+04   4424.278     -5.629      0.000   -3.36e+04   -1.62e+04\n",
       "6078.0       9970.6042   3077.931      3.239      0.001    3937.391     1.6e+04\n",
       "6081.0      -8372.7134   2993.920     -2.797      0.005   -1.42e+04   -2504.175\n",
       "60893.0     -4392.3442   4603.659     -0.954      0.340   -1.34e+04    4631.526\n",
       "6097.0       1.012e+04   3186.388      3.177      0.001    3876.500    1.64e+04\n",
       "6102.0       8471.8648   3120.976      2.714      0.007    2354.277    1.46e+04\n",
       "6104.0      -1015.6692   3148.374     -0.323      0.747   -7186.960    5155.622\n",
       "6109.0       1845.7093   2960.815      0.623      0.533   -3957.937    7649.356\n",
       "6127.0       3170.7530   3399.610      0.933      0.351   -3492.999    9834.505\n",
       "61552.0     -3744.5941   4251.815     -0.881      0.378   -1.21e+04    4589.610\n",
       "6158.0       6412.2005   3180.992      2.016      0.044     176.973    1.26e+04\n",
       "6171.0       9057.6581   3095.055      2.926      0.003    2990.880    1.51e+04\n",
       "61780.0      7728.4892   4929.729      1.568      0.117   -1934.529    1.74e+04\n",
       "6207.0       9047.4137   3117.371      2.902      0.004    2936.893    1.52e+04\n",
       "6214.0       9507.7433   3104.135      3.063      0.002    3423.167    1.56e+04\n",
       "6216.0       9878.3520   3184.210      3.102      0.002    3636.816    1.61e+04\n",
       "62221.0      9234.8611   4394.723      2.101      0.036     620.537    1.78e+04\n",
       "6259.0       5439.7175   3440.702      1.581      0.114   -1304.581    1.22e+04\n",
       "62599.0     -2.283e+04   4958.737     -4.603      0.000   -3.25e+04   -1.31e+04\n",
       "6266.0       9238.7331   3091.436      2.988      0.003    3179.048    1.53e+04\n",
       "6268.0       1962.6459   3058.799      0.642      0.521   -4033.064    7958.356\n",
       "6288.0       8168.8157   3114.238      2.623      0.009    2064.437    1.43e+04\n",
       "6297.0       9274.3327   3198.409      2.900      0.004    3004.965    1.55e+04\n",
       "6307.0      -1.469e+04   3698.147     -3.973      0.000   -2.19e+04   -7443.955\n",
       "6313.0       8992.0347   4390.677      2.048      0.041     385.640    1.76e+04\n",
       "6314.0       9736.1987   3151.801      3.089      0.002    3558.191    1.59e+04\n",
       "6326.0       3826.7169   2984.925      1.282      0.200   -2024.190    9677.624\n",
       "6349.0       8643.9164   3087.391      2.800      0.005    2592.161    1.47e+04\n",
       "6357.0       1.032e+04   3297.883      3.130      0.002    3857.899    1.68e+04\n",
       "6375.0       1.413e+04   3134.685      4.507      0.000    7984.330    2.03e+04\n",
       "6376.0       9471.0692   3147.599      3.009      0.003    3301.297    1.56e+04\n",
       "6379.0      -3775.7784   6131.764     -0.616      0.538   -1.58e+04    8243.410\n",
       "6386.0       9629.8217   3110.678      3.096      0.002    3532.421    1.57e+04\n",
       "6403.0       5780.6448   3183.328      1.816      0.069    -459.161     1.2e+04\n",
       "6410.0       1.062e+04   3209.167      3.309      0.001    4327.639    1.69e+04\n",
       "6416.0       4480.9728   3166.668      1.415      0.157   -1726.177    1.07e+04\n",
       "6424.0       9498.0653   3132.089      3.033      0.002    3358.695    1.56e+04\n",
       "6433.0       9589.1419   3170.423      3.025      0.002    3374.632    1.58e+04\n",
       "6435.0       9723.4153   3042.211      3.196      0.001    3760.220    1.57e+04\n",
       "6492.0       6260.6289   3090.244      2.026      0.043     203.281    1.23e+04\n",
       "6497.0       2903.0101   3215.604      0.903      0.367   -3400.062    9206.082\n",
       "6500.0       8402.1659   7302.670      1.151      0.250   -5912.176    2.27e+04\n",
       "6509.0       8464.7557   3077.538      2.750      0.006    2432.313    1.45e+04\n",
       "6527.0       1.055e+04   3417.715      3.086      0.002    3848.357    1.72e+04\n",
       "6528.0       8661.1370   3343.926      2.590      0.010    2106.534    1.52e+04\n",
       "6531.0        -25.9974   3078.405     -0.008      0.993   -6060.139    6008.144\n",
       "6532.0       5885.9647   3095.765      1.901      0.057    -182.205     1.2e+04\n",
       "6543.0       9929.9352   3144.078      3.158      0.002    3767.065    1.61e+04\n",
       "6548.0       9593.2367   3169.925      3.026      0.002    3379.702    1.58e+04\n",
       "6550.0       9616.0676   3359.843      2.862      0.004    3030.264    1.62e+04\n",
       "6552.0       9638.8646   3275.149      2.943      0.003    3219.075    1.61e+04\n",
       "6565.0       4782.1084   3198.665      1.495      0.135   -1487.761    1.11e+04\n",
       "6571.0       9305.0305   3110.487      2.992      0.003    3208.004    1.54e+04\n",
       "6573.0       9082.6070   3092.638      2.937      0.003    3020.566    1.51e+04\n",
       "6641.0       7749.3873   5382.286      1.440      0.150   -2800.711    1.83e+04\n",
       "6649.0       1.053e+04   3159.208      3.335      0.001    4342.190    1.67e+04\n",
       "6730.0       8500.3738   3089.775      2.751      0.006    2443.946    1.46e+04\n",
       "6731.0       6466.6645   3134.642      2.063      0.039     322.291    1.26e+04\n",
       "6742.0       9550.9622   4649.788      2.054      0.040     436.672    1.87e+04\n",
       "6745.0       1.009e+04   3200.253      3.154      0.002    3820.559    1.64e+04\n",
       "6756.0       9834.8380   3160.429      3.112      0.002    3639.917     1.6e+04\n",
       "6765.0      -4414.1271   3022.513     -1.460      0.144   -1.03e+04    1510.458\n",
       "6768.0       1.156e+04   3234.772      3.575      0.000    5223.749    1.79e+04\n",
       "6774.0       -1.45e+04   3423.679     -4.235      0.000   -2.12e+04   -7789.918\n",
       "6797.0       1.062e+04   3560.156      2.982      0.003    3636.640    1.76e+04\n",
       "6803.0       9790.5158   3152.629      3.106      0.002    3610.883     1.6e+04\n",
       "6821.0       8916.7458   3111.850      2.865      0.004    2817.047     1.5e+04\n",
       "6830.0       8333.4226   3124.559      2.667      0.008    2208.812    1.45e+04\n",
       "6845.0       6582.6117   3033.170      2.170      0.030     637.138    1.25e+04\n",
       "6848.0       9265.8494   3380.966      2.741      0.006    2638.642    1.59e+04\n",
       "6873.0       5262.2493   3710.128      1.418      0.156   -2010.164    1.25e+04\n",
       "6900.0       7470.5391   3040.133      2.457      0.014    1511.417    1.34e+04\n",
       "6908.0       7574.9222   3037.300      2.494      0.013    1621.353    1.35e+04\n",
       "6994.0       8255.8589   3119.283      2.647      0.008    2141.590    1.44e+04\n",
       "7045.0       1844.4045   3736.226      0.494      0.622   -5479.167    9167.976\n",
       "7065.0       1.408e+04   3067.167      4.591      0.000    8070.340    2.01e+04\n",
       "7085.0        1.13e+04   3081.095      3.669      0.000    5264.878    1.73e+04\n",
       "7107.0       8052.7198   3211.390      2.508      0.012    1757.908    1.43e+04\n",
       "7116.0       1.032e+04   3179.999      3.245      0.001    4086.849    1.66e+04\n",
       "7117.0       1.055e+04   3949.975      2.671      0.008    2809.099    1.83e+04\n",
       "7121.0       8775.8315   3133.720      2.800      0.005    2633.264    1.49e+04\n",
       "7127.0       6420.8313   3243.158      1.980      0.048      63.750    1.28e+04\n",
       "7139.0       8727.2476   3099.294      2.816      0.005    2652.161    1.48e+04\n",
       "7146.0       9720.1875   3126.664      3.109      0.002    3591.451    1.58e+04\n",
       "7163.0       1.279e+04   3134.484      4.081      0.000    6646.405    1.89e+04\n",
       "7180.0       6160.9922   3087.312      1.996      0.046     109.392    1.22e+04\n",
       "7183.0       6762.3251   3128.386      2.162      0.031     630.214    1.29e+04\n",
       "7228.0       1.764e+04   3168.523      5.567      0.000    1.14e+04    2.38e+04\n",
       "7232.0       8154.6539   4154.025      1.963      0.050      12.134    1.63e+04\n",
       "7250.0       6766.0899   3377.887      2.003      0.045     144.918    1.34e+04\n",
       "7257.0       2.971e+04   3115.326      9.536      0.000    2.36e+04    3.58e+04\n",
       "7260.0       9150.8519   3085.180      2.966      0.003    3103.431    1.52e+04\n",
       "7267.0       8865.9508   3234.107      2.741      0.006    2526.610    1.52e+04\n",
       "7268.0       1505.3236   3301.821      0.456      0.648   -4966.748    7977.395\n",
       "7281.0       9732.5905   3991.005      2.439      0.015    1909.615    1.76e+04\n",
       "7291.0       7456.0581   3068.111      2.430      0.015    1442.096    1.35e+04\n",
       "7343.0       4436.4667   3573.654      1.241      0.214   -2568.438    1.14e+04\n",
       "7346.0       3238.1303   3079.092      1.052      0.293   -2797.357    9273.617\n",
       "7401.0       9349.7327   3138.244      2.979      0.003    3198.297    1.55e+04\n",
       "7409.0       8457.9972   3066.239      2.758      0.006    2447.702    1.45e+04\n",
       "7420.0       6215.9290   3018.667      2.059      0.039     298.884    1.21e+04\n",
       "7435.0       6751.7467   3158.717      2.137      0.033     560.181    1.29e+04\n",
       "7466.0       8553.9161   3269.146      2.617      0.009    2145.893     1.5e+04\n",
       "7486.0       1723.3876   3152.520      0.547      0.585   -4456.030    7902.805\n",
       "7503.0       9067.0759   4579.905      1.980      0.048      89.767     1.8e+04\n",
       "7506.0       9819.2990   3057.813      3.211      0.001    3825.522    1.58e+04\n",
       "7537.0       9430.8825   3170.373      2.975      0.003    3216.470    1.56e+04\n",
       "7549.0       7273.1684   3042.817      2.390      0.017    1308.786    1.32e+04\n",
       "7554.0       8897.8883   3135.083      2.838      0.005    2752.650     1.5e+04\n",
       "7557.0       6931.8955   3136.896      2.210      0.027     783.102    1.31e+04\n",
       "7585.0      -1.495e+04   3233.948     -4.624      0.000   -2.13e+04   -8613.193\n",
       "7602.0       8923.7108   3107.157      2.872      0.004    2833.211     1.5e+04\n",
       "7620.0       7129.5037   3384.544      2.106      0.035     495.283    1.38e+04\n",
       "7636.0       9304.1976   3123.447      2.979      0.003    3181.767    1.54e+04\n",
       "7646.0       9393.7191   3155.786      2.977      0.003    3207.900    1.56e+04\n",
       "7658.0       6253.3200   3022.501      2.069      0.039     328.759    1.22e+04\n",
       "7683.0       1.026e+04   3321.592      3.090      0.002    3753.317    1.68e+04\n",
       "7685.0       8767.4758   3234.267      2.711      0.007    2427.821    1.51e+04\n",
       "7692.0       5012.1399   3004.385      1.668      0.095    -876.911    1.09e+04\n",
       "7762.0       9366.4810   3091.150      3.030      0.002    3307.357    1.54e+04\n",
       "7772.0      -2443.1777   3001.938     -0.814      0.416   -8327.432    3441.076\n",
       "7773.0       8790.9387   3128.430      2.810      0.005    2658.740    1.49e+04\n",
       "7777.0       5620.5173   3072.543      1.829      0.067    -402.134    1.16e+04\n",
       "7835.0       9969.7493   3156.641      3.158      0.002    3782.253    1.62e+04\n",
       "7873.0       1753.2079   3096.978      0.566      0.571   -4317.340    7823.755\n",
       "7883.0       6648.1472   3032.795      2.192      0.028     703.409    1.26e+04\n",
       "7904.0       5757.8853   3042.665      1.892      0.058    -206.199    1.17e+04\n",
       "7906.0        1.24e+04   3192.708      3.884      0.000    6143.287    1.87e+04\n",
       "7921.0       9521.8682   3078.497      3.093      0.002    3487.546    1.56e+04\n",
       "7923.0       8424.9184   3204.025      2.629      0.009    2144.542    1.47e+04\n",
       "7935.0       6955.2953   3049.615      2.281      0.023     977.586    1.29e+04\n",
       "7938.0       7442.0282   3074.413      2.421      0.016    1415.711    1.35e+04\n",
       "7985.0      -1.012e+04   2991.410     -3.382      0.001    -1.6e+04   -4253.115\n",
       "8014.0       8157.1933   3199.316      2.550      0.011    1886.047    1.44e+04\n",
       "8030.0       1.069e+04   3172.643      3.370      0.001    4474.298    1.69e+04\n",
       "8046.0       2100.8383   3150.625      0.667      0.505   -4074.865    8276.542\n",
       "8047.0       8930.9265   3638.445      2.455      0.014    1799.022    1.61e+04\n",
       "8062.0       7656.2181   3156.951      2.425      0.015    1468.115    1.38e+04\n",
       "8068.0      -6316.9730   3342.935     -1.890      0.059   -1.29e+04     235.687\n",
       "8087.0      -1486.8453   3165.038     -0.470      0.639   -7690.801    4717.110\n",
       "8095.0       9092.3282   3091.617      2.941      0.003    3032.289    1.52e+04\n",
       "8096.0       9888.7824   3156.253      3.133      0.002    3702.048    1.61e+04\n",
       "8109.0       9592.9423   3114.281      3.080      0.002    3488.479    1.57e+04\n",
       "8123.0       5332.5335   3050.740      1.748      0.080    -647.380    1.13e+04\n",
       "8150.0       1.002e+04   3143.649      3.186      0.001    3854.817    1.62e+04\n",
       "8163.0       7135.9390   3109.533      2.295      0.022    1040.782    1.32e+04\n",
       "8176.0       5907.8263   3555.339      1.662      0.097   -1061.178    1.29e+04\n",
       "8202.0       7093.7298   3180.484      2.230      0.026     859.499    1.33e+04\n",
       "8214.0       5649.2334   3049.389      1.853      0.064    -328.032    1.16e+04\n",
       "8215.0       3589.9167   3151.067      1.139      0.255   -2586.652    9766.486\n",
       "8219.0       1.015e+04   3202.762      3.170      0.002    3875.511    1.64e+04\n",
       "8247.0       5130.0212   3044.372      1.685      0.092    -837.409    1.11e+04\n",
       "8253.0      -2202.2944   3019.455     -0.729      0.466   -8120.885    3716.296\n",
       "8290.0       6667.9159   3236.736      2.060      0.039     323.422     1.3e+04\n",
       "8293.0       7346.0103   3043.721      2.413      0.016    1379.855    1.33e+04\n",
       "8304.0       9985.5502   3093.631      3.228      0.001    3921.565     1.6e+04\n",
       "8334.0       9750.2882   3258.525      2.992      0.003    3363.085    1.61e+04\n",
       "8348.0       9196.9702   3156.426      2.914      0.004    3009.895    1.54e+04\n",
       "8357.0       8782.9091   3076.771      2.855      0.004    2751.971    1.48e+04\n",
       "8358.0       6761.4473   3044.175      2.221      0.026     794.402    1.27e+04\n",
       "8446.0      -3983.6259   3374.667     -1.180      0.238   -1.06e+04    2631.234\n",
       "8460.0       1.098e+04   3537.306      3.105      0.002    4051.291    1.79e+04\n",
       "8463.0       8838.8993   3110.041      2.842      0.004    2742.747    1.49e+04\n",
       "8479.0       7883.3944   3750.123      2.102      0.036     532.584    1.52e+04\n",
       "8530.0       2.055e+04   3130.331      6.565      0.000    1.44e+04    2.67e+04\n",
       "8536.0       5321.9245   3023.926      1.760      0.078    -605.430    1.12e+04\n",
       "8543.0        2.91e+04   3348.461      8.689      0.000    2.25e+04    3.57e+04\n",
       "8549.0        288.7530   3183.883      0.091      0.928   -5952.140    6529.646\n",
       "8551.0       9857.0564   3160.749      3.119      0.002    3661.508    1.61e+04\n",
       "8559.0       6877.9877   3301.144      2.084      0.037     407.244    1.33e+04\n",
       "8573.0       2363.2893   3354.437      0.705      0.481   -4211.916    8938.495\n",
       "8606.0       9996.9128   3074.136      3.252      0.001    3971.140     1.6e+04\n",
       "8607.0       1.008e+04   3199.827      3.150      0.002    3805.949    1.64e+04\n",
       "8648.0       8703.5470   3078.394      2.827      0.005    2669.428    1.47e+04\n",
       "8657.0       4027.2377   3062.602      1.315      0.189   -1975.927       1e+04\n",
       "8675.0       9234.4663   4423.761      2.087      0.037     563.222    1.79e+04\n",
       "8681.0       5022.8681   2990.914      1.679      0.093    -839.778    1.09e+04\n",
       "8687.0       6865.4753   3330.626      2.061      0.039     336.943    1.34e+04\n",
       "8692.0       6724.1365   3040.648      2.211      0.027     764.005    1.27e+04\n",
       "8699.0       9368.7656   3104.748      3.018      0.003    3282.988    1.55e+04\n",
       "8717.0       1.007e+04   3139.976      3.206      0.001    3910.883    1.62e+04\n",
       "8759.0       6032.6233   3129.293      1.928      0.054    -101.267    1.22e+04\n",
       "8762.0       1.005e+04   3163.140      3.177      0.001    3847.994    1.62e+04\n",
       "8819.0        1.08e+04   3255.498      3.319      0.001    4422.683    1.72e+04\n",
       "8850.0       9180.3611   3099.787      2.962      0.003    3104.308    1.53e+04\n",
       "8852.0       9396.6270   3137.971      2.994      0.003    3245.728    1.55e+04\n",
       "8859.0       9958.6402   3172.396      3.139      0.002    3740.263    1.62e+04\n",
       "8867.0       2878.0832   3278.995      0.878      0.380   -3549.244    9305.411\n",
       "8881.0       7955.4694   3090.496      2.574      0.010    1897.629     1.4e+04\n",
       "8958.0       7012.8960   3062.779      2.290      0.022    1009.384     1.3e+04\n",
       "8972.0      -1.071e+04   3041.870     -3.522      0.000   -1.67e+04   -4751.155\n",
       "8990.0        237.8112   3143.690      0.076      0.940   -5924.298    6399.920\n",
       "9004.0       1.047e+04   3372.333      3.105      0.002    3861.201    1.71e+04\n",
       "9016.0       7304.7780   3039.777      2.403      0.016    1346.353    1.33e+04\n",
       "9048.0       6403.1328   3012.256      2.126      0.034     498.654    1.23e+04\n",
       "9051.0       1965.6327   3401.698      0.578      0.563   -4702.212    8633.478\n",
       "9071.0       6269.8156   3082.415      2.034      0.042     227.814    1.23e+04\n",
       "9112.0       5595.9253   3023.816      1.851      0.064    -331.214    1.15e+04\n",
       "9114.0       3815.5590   3108.453      1.227      0.220   -2277.481    9908.599\n",
       "9132.0       9293.0465   4448.428      2.089      0.037     573.452     1.8e+04\n",
       "9173.0       8593.1758   3436.473      2.501      0.012    1857.168    1.53e+04\n",
       "9180.0       9960.1426   3212.901      3.100      0.002    3662.368    1.63e+04\n",
       "9186.0       8369.7659   3096.656      2.703      0.007    2299.850    1.44e+04\n",
       "9191.0       5236.9855   4093.728      1.279      0.201   -2787.343    1.33e+04\n",
       "9216.0       3177.1857   2977.132      1.067      0.286   -2658.445    9012.817\n",
       "9217.0        345.3862   2964.765      0.116      0.907   -5466.004    6156.777\n",
       "9225.0       9669.4538   3102.778      3.116      0.002    3587.537    1.58e+04\n",
       "9230.0       1.017e+04   3631.753      2.800      0.005    3049.714    1.73e+04\n",
       "9259.0       1.082e+04   3195.981      3.387      0.001    4559.228    1.71e+04\n",
       "9293.0       9826.5015   3129.155      3.140      0.002    3692.884     1.6e+04\n",
       "9299.0       4757.1723   3068.861      1.550      0.121   -1258.262    1.08e+04\n",
       "9308.0       5449.7947   3213.596      1.696      0.090    -849.341    1.17e+04\n",
       "9311.0       6091.4889   4097.403      1.487      0.137   -1940.043    1.41e+04\n",
       "9313.0       4314.0795   3025.653      1.426      0.154   -1616.660    1.02e+04\n",
       "9325.0       8571.9786   3107.010      2.759      0.006    2481.767    1.47e+04\n",
       "9332.0       7832.2604   3050.287      2.568      0.010    1853.235    1.38e+04\n",
       "9340.0      -1.284e+04   4266.321     -3.009      0.003   -2.12e+04   -4476.619\n",
       "9372.0       1.011e+04   3506.811      2.883      0.004    3237.019     1.7e+04\n",
       "9411.0       6355.8057   3158.698      2.012      0.044     164.278    1.25e+04\n",
       "9459.0       4594.2014   3082.822      1.490      0.136   -1448.598    1.06e+04\n",
       "9465.0       1.241e+04   3064.660      4.049      0.000    6402.210    1.84e+04\n",
       "9472.0       4269.6200   2986.010      1.430      0.153   -1583.412    1.01e+04\n",
       "9483.0       -216.2534   3044.454     -0.071      0.943   -6183.846    5751.340\n",
       "9563.0      -1.792e+04   4211.763     -4.256      0.000   -2.62e+04   -9668.157\n",
       "9590.0       7000.0639   3121.546      2.242      0.025     881.359    1.31e+04\n",
       "9598.0       4487.5163   3762.106      1.193      0.233   -2886.783    1.19e+04\n",
       "9599.0       3721.4346   3033.177      1.227      0.220   -2224.052    9666.921\n",
       "9602.0       3023.8387   4071.341      0.743      0.458   -4956.608     1.1e+04\n",
       "9619.0       1.003e+04   3221.664      3.113      0.002    3715.041    1.63e+04\n",
       "9643.0       6673.9738   3111.149      2.145      0.032     575.650    1.28e+04\n",
       "9650.0       5948.1118   3049.133      1.951      0.051     -28.652    1.19e+04\n",
       "9653.0      -5201.1049   5261.293     -0.989      0.323   -1.55e+04    5111.828\n",
       "9667.0       5978.4574   3032.475      1.971      0.049      34.345    1.19e+04\n",
       "9698.0       8360.8550   3113.996      2.685      0.007    2256.949    1.45e+04\n",
       "9699.0       9695.4952   3081.120      3.147      0.002    3656.031    1.57e+04\n",
       "9719.0       1673.7655   2960.502      0.565      0.572   -4129.267    7476.798\n",
       "9742.0       1462.5312   3123.254      0.468      0.640   -4659.520    7584.583\n",
       "9761.0       9161.1397   3123.661      2.933      0.003    3038.290    1.53e+04\n",
       "9771.0       2489.7585   2963.761      0.840      0.401   -3319.664    8299.181\n",
       "9772.0       9912.5502   3147.378      3.149      0.002    3743.211    1.61e+04\n",
       "9778.0       7202.1314   3024.139      2.382      0.017    1274.359    1.31e+04\n",
       "9799.0       1707.7949   3109.095      0.549      0.583   -4386.503    7802.093\n",
       "9815.0       9088.3459   3223.230      2.820      0.005    2770.327    1.54e+04\n",
       "9818.0      -3.452e+04   3202.790    -10.779      0.000   -4.08e+04   -2.82e+04\n",
       "9837.0       1.056e+04   3244.249      3.254      0.001    4198.886    1.69e+04\n",
       "9922.0       2994.0482   3000.566      0.998      0.318   -2887.517    8875.613\n",
       "9954.0       5697.1012   3683.632      1.547      0.122   -1523.378    1.29e+04\n",
       "9963.0       7227.4542   3090.223      2.339      0.019    1170.149    1.33e+04\n",
       "9988.0       1.018e+04   3189.909      3.192      0.001    3928.483    1.64e+04\n",
       "==============================================================================\n",
       "Omnibus:                    21744.289   Durbin-Watson:                   0.548\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         50237524.155\n",
       "Skew:                          10.223   Prob(JB):                         0.00\n",
       "Kurtosis:                     302.434   Cond. No.                     2.00e+07\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large,  2e+07. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_vars = df[x_vars]\n",
    "x_vars = sm.add_constant(x_vars)\n",
    "x_vars = x_vars.astype(float) # converts categorical booleans to floats\n",
    "\n",
    "lin_reg = sm.OLS(y_var,x_vars).fit()\n",
    "lin_reg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59501cbb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"text-align:center\"><tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td colspan=\"1\"><em>Dependent variable: rmkvaf</em></td></tr><tr><td style=\"text-align:left\"></td><tr><td style=\"text-align:left\"></td><td>(1)</td></tr>\n",
       "<tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "\n",
       "<tr><td style=\"text-align:left\">const</td><td>-9940.577<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(2385.347)</td></tr>\n",
       "<tr><td style=\"text-align:left\">gspilltecIV</td><td>0.100<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.027)</td></tr>\n",
       "<tr><td style=\"text-align:left\">gspillsicIV</td><td>0.340<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.049)</td></tr>\n",
       "<tr><td style=\"text-align:left\">pat_count</td><td>-30.602<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(1.838)</td></tr>\n",
       "<tr><td style=\"text-align:left\">rsales</td><td>0.781<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.037)</td></tr>\n",
       "<tr><td style=\"text-align:left\">rppent</td><td>0.611<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.084)</td></tr>\n",
       "<tr><td style=\"text-align:left\">emp</td><td>18.064<sup>**</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(7.147)</td></tr>\n",
       "<tr><td style=\"text-align:left\">rxrd</td><td>18.594<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.614)</td></tr>\n",
       "\n",
       "<tr><td style=\"text-align: left\">Firm & Time Effects</td><td>Yes</td></tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align: left\">Observations</td><td>13385</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.665</td></tr><tr><td style=\"text-align: left\">Adjusted R<sup>2</sup></td><td>0.645</td></tr><tr><td style=\"text-align: left\">Residual Std. Error</td><td>9771.830 (df=12629)</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>33.221<sup>***</sup> (df=755; 12629)</td></tr>\n",
       "<tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td><td colspan=\"1\" style=\"text-align: right\"><sup>*</sup>p&lt;0.1; <sup>**</sup>p&lt;0.05; <sup>***</sup>p&lt;0.01</td></tr></table>"
      ],
      "text/plain": [
       "<stargazer.stargazer.Stargazer at 0x7fc81d121790>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export results, omit fixed effects\n",
    "stargazer = Stargazer([lin_reg])\n",
    "\n",
    "main_vars = [col for col in x_vars.columns if col not in fixed_effects]\n",
    "cov_labels = {'rmkvaf': 'Market Value',\n",
    "             'pat_count': 'Patent Count',\n",
    "             'rsales': 'Sales',\n",
    "             'rppent': '',\n",
    "             'emp': 'Employment',\n",
    "             'rxrd': 'R&D Expenditures'}\n",
    "\n",
    "\n",
    "stargazer.covariate_order(main_vars)\n",
    "stargazer.add_line(\"Firm & Time Effects\", ['Yes'])\n",
    "#stargazer.rename_covariates(cov_labels)\n",
    "stargazer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94e65e5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[!htbp] \\centering\n",
      "\\begin{tabular}{@{\\extracolsep{5pt}}lc}\n",
      "\\\\[-1.8ex]\\hline\n",
      "\\hline \\\\[-1.8ex]\n",
      "& \\multicolumn{1}{c}{\\textit{Dependent variable: rmkvaf}} \\\n",
      "\\cr \\cline{2-2}\n",
      "\\\\[-1.8ex] & (1) \\\\\n",
      "\\hline \\\\[-1.8ex]\n",
      " const & -9940.577$^{***}$ \\\\\n",
      "& (2385.347) \\\\\n",
      " gspilltecIV & 0.100$^{***}$ \\\\\n",
      "& (0.027) \\\\\n",
      " gspillsicIV & 0.340$^{***}$ \\\\\n",
      "& (0.049) \\\\\n",
      " pat_count & -30.602$^{***}$ \\\\\n",
      "& (1.838) \\\\\n",
      " rsales & 0.781$^{***}$ \\\\\n",
      "& (0.037) \\\\\n",
      " rppent & 0.611$^{***}$ \\\\\n",
      "& (0.084) \\\\\n",
      " emp & 18.064$^{**}$ \\\\\n",
      "& (7.147) \\\\\n",
      " rxrd & 18.594$^{***}$ \\\\\n",
      "& (0.614) \\\\\n",
      " Firm & Time Effects & Yes \\\\\n",
      "\\hline \\\\[-1.8ex]\n",
      " Observations & 13385 \\\\\n",
      " $R^2$ & 0.665 \\\\\n",
      " Adjusted $R^2$ & 0.645 \\\\\n",
      " Residual Std. Error & 9771.830 (df=12629) \\\\\n",
      " F Statistic & 33.221$^{***}$ (df=755; 12629) \\\\\n",
      "\\hline\n",
      "\\hline \\\\[-1.8ex]\n",
      "\\textit{Note:} & \\multicolumn{1}{r}{$^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01} \\\\\n",
      "\\end{tabular}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "# render to latex\n",
    "print(stargazer.render_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bbb04b",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0ad6a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# design = MS(df.columns.drop([col for col in df.columns if col not in x_vars.columns])).fit(df)\n",
    "# NOTE: including all of the fixed effects seems to kill the notebook. Running Ridge/LASSO on subset excluding FE's\n",
    "\n",
    "# Check: outlier in dataset driving a split in reg tree.\n",
    "## Drop two outlier firms: i = 5047, i = 12141, i = 6008\n",
    "df = df.loc[(df['i'] != '5047.0') & (df['i'] != '12141.0') & (df['i'] != '6008.0')]\n",
    "\n",
    "design = MS(df.columns.drop([col for col in df.columns if col not in x_vars.columns or col in fixed_effects])).fit(df)\n",
    "Y = np.array(df['rmkvaf'])\n",
    "X = design.transform(df)\n",
    "\n",
    "D = design.fit_transform(df)\n",
    "D = D.drop('intercept', axis=1)\n",
    "X = np.asarray(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "643f4695-8889-4a0f-8fd1-e7abe27e3d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>rmkvaf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>20779.0</td>\n",
       "      <td>436988.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9175</th>\n",
       "      <td>8530.0</td>\n",
       "      <td>271724.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9176</th>\n",
       "      <td>8530.0</td>\n",
       "      <td>228610.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7418</th>\n",
       "      <td>7257.0</td>\n",
       "      <td>202124.515625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>20779.0</td>\n",
       "      <td>194111.171875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11426</th>\n",
       "      <td>10215.0</td>\n",
       "      <td>0.756740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10890</th>\n",
       "      <td>9799.0</td>\n",
       "      <td>0.718651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9447</th>\n",
       "      <td>8681.0</td>\n",
       "      <td>0.634273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10891</th>\n",
       "      <td>9799.0</td>\n",
       "      <td>0.617000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10892</th>\n",
       "      <td>9799.0</td>\n",
       "      <td>0.432155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13325 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             i         rmkvaf\n",
       "904    20779.0  436988.531250\n",
       "9175    8530.0  271724.750000\n",
       "9176    8530.0  228610.859375\n",
       "7418    7257.0  202124.515625\n",
       "903    20779.0  194111.171875\n",
       "...        ...            ...\n",
       "11426  10215.0       0.756740\n",
       "10890   9799.0       0.718651\n",
       "9447    8681.0       0.634273\n",
       "10891   9799.0       0.617000\n",
       "10892   9799.0       0.432155\n",
       "\n",
       "[13325 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['i','rmkvaf']].sort_values('rmkvaf', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "968dedb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ModelSpec(terms=Index([&#x27;rxrd&#x27;, &#x27;pat_count&#x27;, &#x27;rsales&#x27;, &#x27;rppent&#x27;, &#x27;emp&#x27;, &#x27;gspilltecIV&#x27;,\n",
       "       &#x27;gspillsicIV&#x27;],\n",
       "      dtype=&#x27;object&#x27;))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ModelSpec</label><div class=\"sk-toggleable__content\"><pre>ModelSpec(terms=Index([&#x27;rxrd&#x27;, &#x27;pat_count&#x27;, &#x27;rsales&#x27;, &#x27;rppent&#x27;, &#x27;emp&#x27;, &#x27;gspilltecIV&#x27;,\n",
       "       &#x27;gspillsicIV&#x27;],\n",
       "      dtype=&#x27;object&#x27;))</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ModelSpec(terms=Index(['rxrd', 'pat_count', 'rsales', 'rppent', 'emp', 'gspilltecIV',\n",
       "       'gspillsicIV'],\n",
       "      dtype='object'))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6996449",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1097622458263.0627, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1097582592759.0806, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1097532301523.779, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1097287928278.9343, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1097160671205.5079, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1097000226857.8716, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1096797985075.5941, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1096543128226.2659, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1096222080776.6653, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1095817830767.4758, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1095309098831.6775, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1094669329146.029, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1093865477861.7535, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1092856580086.3606, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1091592089381.1823, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1090010008379.0867, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1088034871573.5668, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1085575709348.579, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1082524224690.4636, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1078753558370.0934, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1074118206320.2416, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1068455871174.8545, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1061592236580.0118, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1053349760721.1654, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1043561450382.8282, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1032090009162.562, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1018851580344.3143, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003841505405.8765, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 987157411344.5521, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 969013309233.9867, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 949738353518.6455, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 929756390102.0393, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 909547319239.4812, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 889597049624.498, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 870346886024.6908, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 852153510263.9482, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 835267070262.4497, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 819829073989.0403, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 805886387525.1746, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 793414535420.8507, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 782343133947.8167, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 772577943030.8448, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 764016577236.3497, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 756557398060.3286, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 750102904742.2596, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 744559790655.4528, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 739837788505.7505, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 735848784403.1954, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 732506844689.9487, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 729729116868.3756, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 727437204256.852, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 725558555503.5277, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 724027534585.2634, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 722786015892.2922, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 721783499166.7552, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 720976829563.4169, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 720329642920.7789, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 719811653588.1552, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 719397880466.3943, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 719067879710.983, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 718805027390.9995, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 718595875459.7067, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 718429590192.3008, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 718297473033.9185, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 718192558411.4476, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 718109280357.261, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 718043198837.4747, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 717990776778.7076, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 717949199467.1333, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 717916228940.6221, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 717890087018.1964, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 717869361602.1312, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 717852931790.8408, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 717839908132.1796, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 717829585022.8748, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 717821402826.8296, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 717814917754.3455, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 717809777928.9146, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 717805704380.7697, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 717802475959.7673, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 717799917363.3588, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 717797889639.066, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 717796282651.7646, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 717795009110.0918, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 717793999830.1788, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 717793199980.6025, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 717792566105.6345, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 717792063765.6301, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 717791665666.6669, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 717791350178.1057, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 717791100157.5858, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 717790902019.8363, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 717790744998.5765, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 717790620561.6069, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 717790521947.2557, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 717790443796.9402, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 717790381864.081, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 717790332783.2946, tolerance: 219554957.16334796\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEUAAAAVCAYAAAAQAyPeAAAACXBIWXMAAA7EAAAOxAGVKw4bAAADIUlEQVRYCd2Y7XHTQBCGRYYClNCB6MAhFRB3YNwBcQfkp/0vEzogVMAkHQAVMLgDuwOMOzDvs74Vh3QRR6yxSXbmtHer9/ZLezenKzabTRG36XRaxeOn3k/Fe1RENJvN3mk4cJHGldqFWumyJ8iJkbhrekYlQHoxEjsTvzTBb9mtjxN8LfxxQr6TSDr5MNg9VX+dUib5dZD/EH+pdi3ZsonNwQlDUojlhvmWFA2ohK/ipwidNMYwDraMSXaudinMnfjOFHz4KEUrtVdq2D2WvJUUyb7r3ZXbDnORDdWvfc3FaV4RsK/F188RiAj+g/UaD4GGDREKKmTivSQk6CL4N6H/xzJG5iSbF+qXsW31+cr4Qgzmby7O9Ya55GHie8pYSqx0IhDdb42xDynViQ/2zEncPGETX8/lF1UP5eIMHOInD+WRHuwldckZIjz0rlUJkpHNqxi35z7LliXWJI+B91AubovePtExplIoty9bWfdTCWHZDMRTX6p7cg9vZderoEvbSS4uoYQ8DEkKm9oiAUiJqBLaoegkGG5tvpFDJC4XF02zLnmoSApKUuVoKH+EKmHNZlWVzzsAf5FpM4UjD5YUstqVebfBxurr1mX75l0fz6uDc0suruk/8ZVUSi6xIXcZy9XzYJyq1D8e1d0kly1zcU0FGluBkBQCdYUJnJ1HeF+prZOA/QpZvvjSJK8UX965uFgPca5ICiWTMhKD2YyheytFX6czsdvpvTw5/rs/sUJO4/OoSnJxsQ4SuyQpc7Wz+E2i7wEnKyUk5Kc4R+0+yDdB//q1TtngkLkSZzkbBftjDd4GUZGLc3zglliO+Z/UyGoXkTgSwqmxRXKAY7ZtUuIcwZPJa01sCDTP/fAD2G3Q+1k8PnHjPKdqPiYbK5z/FvyMKRfnc7A7sbsU3Sks1Aa73p1Ix0it3FXPIebL70ptgW2WD8SBrI9/Ga4eHlQl5sVhH1yZ2MHUkhJKk8uWv22497qtuaVeUsqPjkLcxG9L1CuFQPirTF4fZEbJDd37TOz/BiPueqXUN294GTI2esTB/XOyFSt3N3fi9Wn9F1Hku17ZY8bCAAAAAElFTkSuQmCC\n",
      "text/latex": [
       "$\\displaystyle \\left( 7, \\  100\\right)$"
      ],
      "text/plain": [
       "(7, 100)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs = X - X.mean(0)[None,:]\n",
    "X_scale = X.std(0)\n",
    "Xs = Xs / X_scale[None,:]\n",
    "lambdas = 10**np.linspace(8, -2, 100) / Y.std()\n",
    "soln_array = lm.ElasticNet.path(Xs,\n",
    "                                 Y,\n",
    "                                 l1_ratio=0.,\n",
    "                                 alphas=lambdas)[1]\n",
    "soln_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12466d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rxrd</th>\n",
       "      <th>pat_count</th>\n",
       "      <th>rsales</th>\n",
       "      <th>rppent</th>\n",
       "      <th>emp</th>\n",
       "      <th>gspilltecIV</th>\n",
       "      <th>gspillsicIV</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative log(lambda)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-8.997627</th>\n",
       "      <td>0.892316</td>\n",
       "      <td>0.424800</td>\n",
       "      <td>0.842053</td>\n",
       "      <td>0.725879</td>\n",
       "      <td>0.597987</td>\n",
       "      <td>0.388765</td>\n",
       "      <td>0.325032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-8.765043</th>\n",
       "      <td>1.125856</td>\n",
       "      <td>0.535961</td>\n",
       "      <td>1.062429</td>\n",
       "      <td>0.915848</td>\n",
       "      <td>0.754468</td>\n",
       "      <td>0.490504</td>\n",
       "      <td>0.410105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-8.532459</th>\n",
       "      <td>1.420481</td>\n",
       "      <td>0.676185</td>\n",
       "      <td>1.340440</td>\n",
       "      <td>1.155497</td>\n",
       "      <td>0.951864</td>\n",
       "      <td>0.618847</td>\n",
       "      <td>0.517433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-8.299874</th>\n",
       "      <td>1.792144</td>\n",
       "      <td>0.853057</td>\n",
       "      <td>1.691136</td>\n",
       "      <td>1.457798</td>\n",
       "      <td>1.200849</td>\n",
       "      <td>0.780738</td>\n",
       "      <td>0.652830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-8.067290</th>\n",
       "      <td>2.260952</td>\n",
       "      <td>1.076129</td>\n",
       "      <td>2.133482</td>\n",
       "      <td>1.839098</td>\n",
       "      <td>1.514876</td>\n",
       "      <td>0.984929</td>\n",
       "      <td>0.823623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.097886</th>\n",
       "      <td>4847.562838</td>\n",
       "      <td>-405.321162</td>\n",
       "      <td>2395.633459</td>\n",
       "      <td>1591.688181</td>\n",
       "      <td>-1205.604869</td>\n",
       "      <td>167.101411</td>\n",
       "      <td>1176.284323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.330471</th>\n",
       "      <td>4847.567994</td>\n",
       "      <td>-405.322699</td>\n",
       "      <td>2395.633438</td>\n",
       "      <td>1591.688347</td>\n",
       "      <td>-1205.608144</td>\n",
       "      <td>167.100739</td>\n",
       "      <td>1176.284323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.563055</th>\n",
       "      <td>4847.572079</td>\n",
       "      <td>-405.323918</td>\n",
       "      <td>2395.633421</td>\n",
       "      <td>1591.688479</td>\n",
       "      <td>-1205.610740</td>\n",
       "      <td>167.100207</td>\n",
       "      <td>1176.284324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.795639</th>\n",
       "      <td>4847.575318</td>\n",
       "      <td>-405.324883</td>\n",
       "      <td>2395.633408</td>\n",
       "      <td>1591.688583</td>\n",
       "      <td>-1205.612797</td>\n",
       "      <td>167.099785</td>\n",
       "      <td>1176.284324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.028224</th>\n",
       "      <td>4847.577884</td>\n",
       "      <td>-405.325648</td>\n",
       "      <td>2395.633397</td>\n",
       "      <td>1591.688666</td>\n",
       "      <td>-1205.614427</td>\n",
       "      <td>167.099450</td>\n",
       "      <td>1176.284324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             rxrd   pat_count       rsales       rppent  \\\n",
       "negative log(lambda)                                                      \n",
       "-8.997627                0.892316    0.424800     0.842053     0.725879   \n",
       "-8.765043                1.125856    0.535961     1.062429     0.915848   \n",
       "-8.532459                1.420481    0.676185     1.340440     1.155497   \n",
       "-8.299874                1.792144    0.853057     1.691136     1.457798   \n",
       "-8.067290                2.260952    1.076129     2.133482     1.839098   \n",
       "...                           ...         ...          ...          ...   \n",
       " 13.097886            4847.562838 -405.321162  2395.633459  1591.688181   \n",
       " 13.330471            4847.567994 -405.322699  2395.633438  1591.688347   \n",
       " 13.563055            4847.572079 -405.323918  2395.633421  1591.688479   \n",
       " 13.795639            4847.575318 -405.324883  2395.633408  1591.688583   \n",
       " 14.028224            4847.577884 -405.325648  2395.633397  1591.688666   \n",
       "\n",
       "                              emp  gspilltecIV  gspillsicIV  \n",
       "negative log(lambda)                                         \n",
       "-8.997627                0.597987     0.388765     0.325032  \n",
       "-8.765043                0.754468     0.490504     0.410105  \n",
       "-8.532459                0.951864     0.618847     0.517433  \n",
       "-8.299874                1.200849     0.780738     0.652830  \n",
       "-8.067290                1.514876     0.984929     0.823623  \n",
       "...                           ...          ...          ...  \n",
       " 13.097886           -1205.604869   167.101411  1176.284323  \n",
       " 13.330471           -1205.608144   167.100739  1176.284323  \n",
       " 13.563055           -1205.610740   167.100207  1176.284324  \n",
       " 13.795639           -1205.612797   167.099785  1176.284324  \n",
       " 14.028224           -1205.614427   167.099450  1176.284324  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soln_path = pd.DataFrame(soln_array.T,\n",
    "                         columns=D.columns,\n",
    "                         index=-np.log(lambdas))\n",
    "soln_path.index.name = 'negative log(lambda)'\n",
    "\n",
    "soln_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "222ea61d-8649-47d5-9913-dbf843cdde9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path_fig, ax = plt.subplots(figsize=(8,8))\n",
    "soln_path.plot(ax=ax, legend=False)\n",
    "ax.set_xlabel('$-\\log(\\lambda)$', fontsize=20)\n",
    "ax.set_ylabel('Standardized coefficients', fontsize=20)\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "# save figure\n",
    "plt.savefig('ridge_coef.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aba1608",
   "metadata": {},
   "source": [
    "## Cross-Validation plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaa9c25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.698e+11, tolerance: 1.740e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.502e+11, tolerance: 1.701e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.564e+11, tolerance: 1.513e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.116e+11, tolerance: 1.623e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.894e+11, tolerance: 1.579e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.698e+11, tolerance: 1.740e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.501e+11, tolerance: 1.701e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.564e+11, tolerance: 1.513e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.115e+11, tolerance: 1.623e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.894e+11, tolerance: 1.579e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.698e+11, tolerance: 1.740e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.501e+11, tolerance: 1.701e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.564e+11, tolerance: 1.513e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.115e+11, tolerance: 1.623e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.893e+11, tolerance: 1.579e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.697e+11, tolerance: 1.740e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.500e+11, tolerance: 1.701e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.563e+11, tolerance: 1.513e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.115e+11, tolerance: 1.623e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.893e+11, tolerance: 1.579e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.696e+11, tolerance: 1.740e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.500e+11, tolerance: 1.701e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.562e+11, tolerance: 1.513e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.114e+11, tolerance: 1.623e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.892e+11, tolerance: 1.579e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.695e+11, tolerance: 1.740e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.499e+11, tolerance: 1.701e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.562e+11, tolerance: 1.513e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.113e+11, tolerance: 1.623e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.892e+11, tolerance: 1.579e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.694e+11, tolerance: 1.740e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.498e+11, tolerance: 1.701e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.561e+11, tolerance: 1.513e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.112e+11, tolerance: 1.623e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.891e+11, tolerance: 1.579e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.693e+11, tolerance: 1.740e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.497e+11, tolerance: 1.701e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.559e+11, tolerance: 1.513e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.111e+11, tolerance: 1.623e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.889e+11, tolerance: 1.579e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.691e+11, tolerance: 1.740e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.495e+11, tolerance: 1.701e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.558e+11, tolerance: 1.513e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.109e+11, tolerance: 1.623e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.888e+11, tolerance: 1.579e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.689e+11, tolerance: 1.740e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.493e+11, tolerance: 1.701e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.556e+11, tolerance: 1.513e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.107e+11, tolerance: 1.623e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.886e+11, tolerance: 1.579e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.686e+11, tolerance: 1.740e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.491e+11, tolerance: 1.701e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.553e+11, tolerance: 1.513e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.104e+11, tolerance: 1.623e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.883e+11, tolerance: 1.579e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.683e+11, tolerance: 1.740e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.487e+11, tolerance: 1.701e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.550e+11, tolerance: 1.513e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.101e+11, tolerance: 1.623e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.880e+11, tolerance: 1.579e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.679e+11, tolerance: 1.740e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.484e+11, tolerance: 1.701e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.546e+11, tolerance: 1.513e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.097e+11, tolerance: 1.623e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.876e+11, tolerance: 1.579e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.673e+11, tolerance: 1.740e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.479e+11, tolerance: 1.701e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.541e+11, tolerance: 1.513e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.092e+11, tolerance: 1.623e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.872e+11, tolerance: 1.579e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.666e+11, tolerance: 1.740e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.472e+11, tolerance: 1.701e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.534e+11, tolerance: 1.513e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.085e+11, tolerance: 1.623e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.865e+11, tolerance: 1.579e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.658e+11, tolerance: 1.740e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.464e+11, tolerance: 1.701e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.526e+11, tolerance: 1.513e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.077e+11, tolerance: 1.623e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.858e+11, tolerance: 1.579e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.647e+11, tolerance: 1.740e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.455e+11, tolerance: 1.701e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.516e+11, tolerance: 1.513e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.067e+11, tolerance: 1.623e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.848e+11, tolerance: 1.579e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.634e+11, tolerance: 1.740e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.442e+11, tolerance: 1.701e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.503e+11, tolerance: 1.513e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.054e+11, tolerance: 1.623e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.836e+11, tolerance: 1.579e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.617e+11, tolerance: 1.740e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.427e+11, tolerance: 1.701e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.487e+11, tolerance: 1.513e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.038e+11, tolerance: 1.623e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.821e+11, tolerance: 1.579e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.596e+11, tolerance: 1.740e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.408e+11, tolerance: 1.701e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.467e+11, tolerance: 1.513e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.019e+11, tolerance: 1.623e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.802e+11, tolerance: 1.579e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.570e+11, tolerance: 1.740e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.384e+11, tolerance: 1.701e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.443e+11, tolerance: 1.513e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.994e+11, tolerance: 1.623e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.779e+11, tolerance: 1.579e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.538e+11, tolerance: 1.740e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.355e+11, tolerance: 1.701e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.413e+11, tolerance: 1.513e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.963e+11, tolerance: 1.623e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.750e+11, tolerance: 1.579e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.498e+11, tolerance: 1.740e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.213e+11, tolerance: 1.056e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.171e+11, tolerance: 1.057e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.986e+11, tolerance: 9.926e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.719e+11, tolerance: 9.298e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.173e+11, tolerance: 1.051e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.212e+11, tolerance: 1.056e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.170e+11, tolerance: 1.057e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.986e+11, tolerance: 9.926e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.719e+11, tolerance: 9.298e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.173e+11, tolerance: 1.051e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.211e+11, tolerance: 1.056e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.170e+11, tolerance: 1.057e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.985e+11, tolerance: 9.926e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.718e+11, tolerance: 9.298e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.172e+11, tolerance: 1.051e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.211e+11, tolerance: 1.056e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.170e+11, tolerance: 1.057e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.985e+11, tolerance: 9.926e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.718e+11, tolerance: 9.298e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.172e+11, tolerance: 1.051e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.210e+11, tolerance: 1.056e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.169e+11, tolerance: 1.057e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.985e+11, tolerance: 9.926e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.718e+11, tolerance: 9.298e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.171e+11, tolerance: 1.051e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.210e+11, tolerance: 1.056e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.169e+11, tolerance: 1.057e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.984e+11, tolerance: 9.926e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+11, tolerance: 9.298e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.171e+11, tolerance: 1.051e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.210e+11, tolerance: 1.056e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.169e+11, tolerance: 1.057e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.984e+11, tolerance: 9.926e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+11, tolerance: 9.298e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.171e+11, tolerance: 1.051e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.210e+11, tolerance: 1.056e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.169e+11, tolerance: 1.057e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.984e+11, tolerance: 9.926e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+11, tolerance: 9.298e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.171e+11, tolerance: 1.051e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.210e+11, tolerance: 1.056e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.168e+11, tolerance: 1.057e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.984e+11, tolerance: 9.926e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+11, tolerance: 9.298e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.170e+11, tolerance: 1.051e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.209e+11, tolerance: 1.056e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.168e+11, tolerance: 1.057e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.984e+11, tolerance: 9.926e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+11, tolerance: 9.298e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.170e+11, tolerance: 1.051e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.209e+11, tolerance: 1.056e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.168e+11, tolerance: 1.057e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.984e+11, tolerance: 9.926e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+11, tolerance: 9.298e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.170e+11, tolerance: 1.051e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.209e+11, tolerance: 1.056e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.168e+11, tolerance: 1.057e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.984e+11, tolerance: 9.926e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+11, tolerance: 9.298e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.170e+11, tolerance: 1.051e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.209e+11, tolerance: 1.056e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.168e+11, tolerance: 1.057e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.984e+11, tolerance: 9.926e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+11, tolerance: 9.298e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.170e+11, tolerance: 1.051e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.209e+11, tolerance: 1.056e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.168e+11, tolerance: 1.057e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.983e+11, tolerance: 9.926e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e+11, tolerance: 9.298e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.170e+11, tolerance: 1.051e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.209e+11, tolerance: 1.056e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.168e+11, tolerance: 1.057e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.983e+11, tolerance: 9.926e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e+11, tolerance: 9.298e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.170e+11, tolerance: 1.051e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.209e+11, tolerance: 1.056e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.168e+11, tolerance: 1.057e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.983e+11, tolerance: 9.926e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e+11, tolerance: 9.298e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.170e+11, tolerance: 1.051e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.209e+11, tolerance: 1.056e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.168e+11, tolerance: 1.057e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.983e+11, tolerance: 9.926e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e+11, tolerance: 9.298e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.170e+11, tolerance: 1.051e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.209e+11, tolerance: 1.056e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.168e+11, tolerance: 1.057e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.983e+11, tolerance: 9.926e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e+11, tolerance: 9.298e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.170e+11, tolerance: 1.051e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.209e+11, tolerance: 1.056e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.168e+11, tolerance: 1.057e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.983e+11, tolerance: 9.926e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e+11, tolerance: 9.298e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.170e+11, tolerance: 1.051e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.209e+11, tolerance: 1.056e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.168e+11, tolerance: 1.057e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.983e+11, tolerance: 9.926e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e+11, tolerance: 9.298e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.170e+11, tolerance: 1.051e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.209e+11, tolerance: 1.056e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.168e+11, tolerance: 1.057e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.983e+11, tolerance: 9.926e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e+11, tolerance: 9.298e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.170e+11, tolerance: 1.051e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.209e+11, tolerance: 1.056e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.168e+11, tolerance: 1.057e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.983e+11, tolerance: 9.926e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e+11, tolerance: 9.298e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.170e+11, tolerance: 1.051e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.209e+11, tolerance: 1.056e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.168e+11, tolerance: 1.057e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.983e+11, tolerance: 9.926e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e+11, tolerance: 9.298e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.170e+11, tolerance: 1.051e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.209e+11, tolerance: 1.056e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.168e+11, tolerance: 1.057e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.983e+11, tolerance: 9.926e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e+11, tolerance: 9.298e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.170e+11, tolerance: 1.051e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.209e+11, tolerance: 1.056e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.168e+11, tolerance: 1.057e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.983e+11, tolerance: 9.926e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e+11, tolerance: 9.298e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.170e+11, tolerance: 1.051e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.209e+11, tolerance: 1.056e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.168e+11, tolerance: 1.057e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.983e+11, tolerance: 9.926e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e+11, tolerance: 9.298e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.170e+11, tolerance: 1.051e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.209e+11, tolerance: 1.056e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.168e+11, tolerance: 1.057e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.983e+11, tolerance: 9.926e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e+11, tolerance: 9.298e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.170e+11, tolerance: 1.051e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.209e+11, tolerance: 1.056e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.168e+11, tolerance: 1.057e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.983e+11, tolerance: 9.926e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e+11, tolerance: 9.298e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.170e+11, tolerance: 1.051e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.209e+11, tolerance: 1.056e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.168e+11, tolerance: 1.057e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.983e+11, tolerance: 9.926e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e+11, tolerance: 9.298e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.170e+11, tolerance: 1.051e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.209e+11, tolerance: 1.056e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.168e+11, tolerance: 1.057e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.983e+11, tolerance: 9.926e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e+11, tolerance: 9.298e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.170e+11, tolerance: 1.051e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.209e+11, tolerance: 1.056e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.168e+11, tolerance: 1.057e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.983e+11, tolerance: 9.926e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e+11, tolerance: 9.298e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.170e+11, tolerance: 1.051e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.209e+11, tolerance: 1.056e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.168e+11, tolerance: 1.057e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.983e+11, tolerance: 9.926e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e+11, tolerance: 9.298e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.170e+11, tolerance: 1.051e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.209e+11, tolerance: 1.056e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.168e+11, tolerance: 1.057e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.983e+11, tolerance: 9.926e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e+11, tolerance: 9.298e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.170e+11, tolerance: 1.051e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.209e+11, tolerance: 1.056e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.168e+11, tolerance: 1.057e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.983e+11, tolerance: 9.926e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e+11, tolerance: 9.298e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.170e+11, tolerance: 1.051e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.209e+11, tolerance: 1.056e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.168e+11, tolerance: 1.057e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.983e+11, tolerance: 9.926e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e+11, tolerance: 9.298e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.170e+11, tolerance: 1.051e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.209e+11, tolerance: 1.056e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.168e+11, tolerance: 1.057e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.983e+11, tolerance: 9.926e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e+11, tolerance: 9.298e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.170e+11, tolerance: 1.051e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.877e+11, tolerance: 1.272e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 528048475261.1476, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 528028712201.3733, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 528003779853.7872, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 527972328039.55585, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 527932655056.85516, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 527882616831.1157, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 527819512981.9874, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 527739944177.0779, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 527639633910.0223, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 527513206424.5934, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 527353910938.11755, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 527153280678.2027, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 526900713704.603, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 526582961350.8442, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 526183509915.6277, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 525681842822.88916, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 525052575198.462, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 524264462701.0988, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 523279304385.8978, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 522050789253.4084, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 520523382711.05853, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 518631417403.5329, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 516298646118.0012, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 513438630856.7906, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 509956468325.56885, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 505752454308.95483, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 500728304455.72943, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 494796381283.3492, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 487891915369.5767, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 479987377783.83386, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 471107016026.51575, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 461338397088.52405, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 450837160573.1199, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 439821717136.91034, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 417326936099.3899, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 406407524612.5433, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 396035711204.03156, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 386391292764.2608, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 377588098700.65955, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 369676463825.0127, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 362653792964.12823, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 356479216265.63873, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 351088600855.63184, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 346407288032.43677, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 342359261871.9338, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 338872611254.71686, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 335881927139.9824, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 333328639476.0495, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 331160300375.7219, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 329329583248.9241, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 327793440420.2401, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 326512572078.0876, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 325451174874.47906, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 324576862390.36115, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 323860647324.16943, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 323276906376.4171, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 322803285794.5584, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 322420535620.9771, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 322112280500.87134, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 321864745283.44434, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 321666456792.3605, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 321507941514.9297, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 321381434805.5795, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 321280612257.72455, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 321200349295.871, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 321136511341.2756, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 321085774261.93506, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 321045473139.6256, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 321013476475.1238, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 320988082590.7134, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 320967934986.65875, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 320951953618.0829, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 320939279376.3065, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 320929229415.40283, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 320921261318.5991, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 320914944427.2076, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 320909936945.90155, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 320905967689.3468, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 320902821547.4742, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 320900327923.1949, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 320898351542.0104, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 320896785151.3644, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 320895543724.1404, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 320894559858.11847, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 320893780125.83386, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 320893162179.1743, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 320892672453.09174, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 320892284344.8071, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 320891976770.1332, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 320891733019.01526, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 320891539848.2595, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 320891386762.37573, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 320891265443.57776, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 320891169299.97174, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 320891093107.4647, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 320891032725.99866, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 320890984874.5831, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 320890946953.0737, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 320890916900.8732, tolerance: 105624797.09384269\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 528448074352.54614, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 528427023256.1906, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 528400466065.59424, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 528366964687.70917, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 528324706651.54724, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 528271408371.6509, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 528204193844.44086, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 528119442792.71893, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 528012600967.84644, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 527877943822.0877, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 527708283110.30475, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 527494604261.1042, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 527225620756.6161, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 526887230612.8238, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 526461859931.5777, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 525927680333.1277, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 525257692328.4793, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 524418677530.03534, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 523370042128.7293, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 522062606437.23, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 520437445565.906, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 518424959647.8668, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 515944451803.10645, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 512904615742.24835, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 509205467494.5067, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 504742360129.68207, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 499412727894.03046, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 493126014503.15674, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 485816732477.45984, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 477459702431.0634, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 468085302972.58325, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 457791345455.77686, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 446747567214.08594, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 435189385358.10583, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 423399794749.2046, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 411681660508.6588, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 400325849048.0717, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 389582146651.75653, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 379638947727.57336, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 370614745393.61316, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 362560947768.7969, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 355472911563.22363, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 349305034756.4879, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 343986135882.7355, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 339432547580.5959, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 335557722893.6556, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 332278275616.3448, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 329517082133.2898, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 327204364078.7225, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 325277641555.0235, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 323681226790.79376, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 322365650129.9352, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 321287174041.3808, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 320407403965.502, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 319692945566.3684, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 319115056836.1172, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 318649267087.4754, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 318274959992.5095, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 317974934182.2276, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 317734961259.1421, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 317543360222.10895, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 317390602770.00543, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 317268958412.0658, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 317172183309.6808, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 317095252950.44354, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 317034136200.00104, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316985606809.7544, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316947087808.3547, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316916524109.341, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316892278911.45886, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316873049894.24744, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316857801712.4983, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316845711802.20276, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316836126989.19214, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316828528820.82166, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316822505913.719, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316817731927.2277, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316813948036.62396, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316810948998.599, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316808572080.1489, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316806688267.1168, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316805195285.9068, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316804012066.2944, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316803074348.8467, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316802331201.10596, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316801742254.9727, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316801275516.2793, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316800905628.2238, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316800612494.7311, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316800380189.23584, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316800196089.70905, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316800050193.1062, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316799934571.9959, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316799842943.897, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316799770329.9782, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316799712784.55383, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316799667180.7024, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316799631040.3784, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316799602399.75616, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316799579702.53064, tolerance: 105705701.29629055\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 496224986600.4098, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 496205483430.9915, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 496180879003.4755, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 496149840938.634, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 496110689986.6315, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 496061310390.4424, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 495999037480.6409, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 495920516952.20795, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 495821529061.52606, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 495696769590.49835, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 495539577886.29675, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 495341600682.1602, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 495092378905.4019, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 494778843591.30176, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 493889735660.7309, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 493268900421.383, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 492491401369.00775, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 491519592349.6038, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 490307852466.6972, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 488801501847.7192, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 486935925685.1531, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 484636163024.79175, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 481817331611.39325, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 478386383823.75006, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 474245787459.3388, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 469299735751.27167, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 463463318789.9132, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 456674624265.47943, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 448908907999.72864, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 440192844084.81586, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 430615723679.48834, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 420333869024.571, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 409565095646.47437, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 398572108690.56445, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 387636845872.0059, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 377030784428.063, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 366987691583.3198, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 357684456234.36755, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 349232917263.3622, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 341682315799.8093, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 335029500154.01135, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 329232987932.6658, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 324227325738.5381, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 319935310083.5559, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316276934726.40247, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 313175002174.43695, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 310558007527.37164, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 308361167670.9948, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 306526422077.2857, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 305002010165.59644, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 303741968330.2816, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 302705680357.5455, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 301857493473.99133, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 301166367399.2714, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 300605523846.75024, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 300152079950.3474, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 299786664561.76294, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 299493025795.1905, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 299257641896.0869, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 299069347401.27576, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 298918984384.26514, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 298799085551.5159, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 298703592851.4171, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 298627612546.65295, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 298567205612.6084, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 298519210909.2883, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 298481097764.13794, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 298450844272.167, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 298426837629.19275, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 298407793039.61993, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 298392688084.16736, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 298380709825.3931, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 298371212324.08496, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 298363682610.52576, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 298357713487.4239, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 298352981830.81036, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 298349231301.4792, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 298346258585.6534, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 298343902454.12134, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 298342035068.4843, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 298340555076.8617, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 298339382133.15106, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 298338452547.7907, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 298337715837.4362, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 298337131988.3244, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 298336669286.10706, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 298336302595.1166, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 298336011994.1294, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 298335781694.89966, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 298335599184.86536, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 298335454547.6318, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 298335339924.37463, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 298335249086.95166, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 298335177099.56274, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 298335120050.60815, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 298335074840.17255, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 298335039011.6082, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 298335010618.03815, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 298334988116.5913, tolerance: 99259900.83227727\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 464810599896.45087, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 464793248944.3599, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 464771359282.1457, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 464743745231.46216, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 464708912299.84937, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 464664977298.2786, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 464609568120.04706, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 464539698195.30743, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 464451609528.50726, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 464340576943.7874, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 464200664725.12036, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 464024425303.44995, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 463802528141.80493, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 463523305745.13684, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 462731118530.4985, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 462177624567.70447, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 461484070627.82294, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 460616576597.31976, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 459533956330.6653, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 458186645907.33246, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 456515769959.38416, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 454452559853.37103, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 451918441172.80896, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 448826226105.8657, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 445082953945.3695, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 435275733091.1002, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 429056514965.6001, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 421899449009.2604, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 413811417944.61755, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 404856105040.9058, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 395160735594.5588, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 384914151700.114, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 374354369600.08203, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 363746523291.4193, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 353355170277.946, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 343416943320.09064, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 334119451052.6597, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 325590184068.5088, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 317896029116.958, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 311051219264.0425, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 305030072647.7236, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 299780828765.7506, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 295237831707.45074, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 291330618478.0862, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 287989659762.0391, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 285149306799.46454, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 282748856213.29626, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 280732627601.9095, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 279049706436.2962, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 277653700527.2541, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 276502612203.1458, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 275558789940.3094, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 274788881594.73468, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 274163727141.08127, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 273658163603.8505, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 273250745449.65015, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 272923401877.61023, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 272661058881.1206, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 272451252538.23804, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 272283754610.40863, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 272150224978.3077, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 272043899344.33215, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 271959315727.6475, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 271892079752.48126, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 271838666460.20462, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 271796255107.8321, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 271762592874.1055, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 271735883335.48764, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 271714695806.80237, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 271697892027.12494, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 271684567118.49487, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 271674002195.96768, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 271665626429.67087, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 271658986737.10428, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 271653723611.2165, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 271649551867.52618, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 271646245325.2189, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 271643624628.56247, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 271641547571.22223, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 271639901413.12088, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 271638596782.02603, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 271637562834.60263, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 271636743417.80136, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 271636094024.43405, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 271635579379.00717, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 271635171523.58615, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 271634848300.29248, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 271634592148.3221, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 271634389150.34995, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 271634228276.72906, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 271634100786.3789, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 271633999751.98294, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 271633919683.6565, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 271633856230.68973, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 271633805945.17883, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 271633766094.70123, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 271633734513.83478, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 271633709486.50262, tolerance: 92975378.35672489\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 525301147711.6022, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 525281103704.23224, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 525255816918.97766, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 525223917979.2684, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 525183680985.7675, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 525132931373.5039, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 525068930356.60675, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 524988230250.0947, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 524886493707.8172, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 524758268479.14954, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 524596707695.49316, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 524393224033.7979, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 524137064538.2692, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 523814791725.0607, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 523409656382.71454, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 522900849085.8078, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 522262622225.7143, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 521463284378.8002, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 520464087008.6203, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 519218053774.1407, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 517668849923.09174, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 515749858422.83264, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 513383724044.3558, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 510482744685.9554, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 506950617287.7621, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 502686149632.5061, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 497589565085.6275, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 491571857999.71405, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 484567190093.43774, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 476547476356.84705, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 467537148423.8904, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 457624897377.5301, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 446968545937.3337, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 435789736487.481, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 424357193694.17426, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 412960531183.66077, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 401879706287.51886, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 391356808311.0815, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 381576070446.9056, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 372655219803.94714, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 364647866256.41864, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 357553995189.92377, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 351334510979.3379, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 345926085410.1604, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 341253718481.08026, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 337239788704.96814, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 333809526177.61835, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 330893588419.35187, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 328428730675.2572, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 326357518668.32117, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 324627772068.48505, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 323192104831.1432, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 322007663582.5347, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 321036012065.2327, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 320243061470.459, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 319598963566.3247, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 319077924137.76794, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 318657931428.97186, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 318320417550.4367, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 318049880283.31525, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 317833492658.004, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 317660722649.13605, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 317522978640.6069, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 317413289921.7065, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 317326026279.58093, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 317256656993.96765, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 317201547103.4444, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 317157787435.8938, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 317123054289.6646, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 317095494558.7486, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 317073632313.3988, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 317056293231.3007, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 317042543726.2156, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 317031642080.089, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 317022999316.27167, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 317016147938.5145, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 317010716996.50073, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 317006412224.1675, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 317003000235.5371, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 317000295959.7698, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316998152658.17615, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316996453996.834, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316995107754.17334, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316994040828.00507, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316993195274.67456, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316992525167.6508, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316991994106.4376, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316991573241.433, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316991239708.0435, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316990975385.35114, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316990765912.1365, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316990599906.94055, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316990468349.87195, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316990364092.65015, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316990281470.27295, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316990215993.257, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316990164103.718, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316990122982.0697, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316990090393.818, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: UserWarning: Coordinate descent without L1 regularization may lead to unexpected results and is discouraged. Set l1_ratio > 0 to add L1 regularization.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 316990064568.1554, tolerance: 105075546.26559137\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.877e+11, tolerance: 1.272e+08 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# Using K-fold CV w/ K=5\n",
    "K = 5\n",
    "kfold = skm.KFold(K,\n",
    "                  random_state=0,\n",
    "                  shuffle=True)\n",
    "\n",
    "scaler = StandardScaler(with_mean=True,  with_std=True)\n",
    "ridge = lm.ElasticNet(alpha=lambdas[59], l1_ratio=0)\n",
    "pipe = Pipeline(steps=[('scaler', scaler), ('ridge', ridge)])\n",
    "\n",
    "param_grid = {'ridge__alpha': lambdas}\n",
    "\n",
    "grid = skm.GridSearchCV(pipe,\n",
    "                        param_grid,\n",
    "                        cv=kfold,\n",
    "                        scoring='neg_mean_squared_error') \n",
    "grid.fit(X, Y)\n",
    "grid.best_params_['ridge__alpha']\n",
    "grid.best_estimator_\n",
    "\n",
    "ridgeCV = lm.ElasticNetCV(alphas=lambdas,\n",
    "                           l1_ratio=0,\n",
    "                           cv=kfold)\n",
    "pipeCV = Pipeline(steps=[('scaler', scaler),\n",
    "                         ('ridge', ridgeCV)])\n",
    "pipeCV.fit(X, Y)\n",
    "\n",
    "tuned_ridge = pipeCV.named_steps['ridge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bc1025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "ridge_fig, ax = plt.subplots(figsize=(8,8))\n",
    "ax.errorbar(-np.log(lambdas),\n",
    "            -grid.cv_results_['mean_test_score'],\n",
    "            yerr=grid.cv_results_['std_test_score'] / np.sqrt(K))\n",
    "ax.axvline(-np.log(tuned_ridge.alpha_), c='k', ls='--')\n",
    "#ax.set_ylim([80000000,220000000])\n",
    "ax.set_xlabel('$-\\log(\\lambda)$', fontsize=20)\n",
    "ax.set_ylabel('Cross-validated MSE', fontsize=20)\n",
    "\n",
    "# save figure\n",
    "plt.savefig('ridge_cv.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b490865a",
   "metadata": {},
   "source": [
    "# LASSO Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2be136",
   "metadata": {},
   "outputs": [],
   "source": [
    "lassoCV = lm.ElasticNetCV(n_alphas=100,\n",
    "                           l1_ratio=1,\n",
    "                           cv=kfold)\n",
    "pipeCV = Pipeline(steps=[('scaler', scaler),\n",
    "                         ('lasso', lassoCV)])\n",
    "pipeCV.fit(X, Y)\n",
    "tuned_lasso = pipeCV.named_steps['lasso']\n",
    "tuned_lasso.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47176817",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas, soln_array = lm.Lasso.path(Xs,\n",
    "                                    Y,\n",
    "                                    l1_ratio=1,\n",
    "                                    n_alphas=100)[:2]\n",
    "soln_path = pd.DataFrame(soln_array.T,\n",
    "                         columns=D.columns,\n",
    "                         index=-np.log(lambdas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2afef1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_fig, ax = plt.subplots(figsize=(10,5))\n",
    "soln_path.plot(ax=ax, legend=False)\n",
    "ax.legend(loc='upper left')\n",
    "ax.set_xlabel('$-\\log(\\lambda)$', fontsize=20)\n",
    "ax.set_ylabel('Standardized coefficiients', fontsize=20)\n",
    "\n",
    "# save figure\n",
    "plt.savefig('lasso_coef.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974f5c50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5180e80",
   "metadata": {},
   "source": [
    "## Cross-Validation plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1f1fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lassoCV_fig, ax = plt.subplots(figsize=(8,8))\n",
    "ax.errorbar(-np.log(tuned_lasso.alphas_),\n",
    "            tuned_lasso.mse_path_.mean(1),\n",
    "            yerr=tuned_lasso.mse_path_.std(1) / np.sqrt(K))\n",
    "ax.axvline(-np.log(tuned_lasso.alpha_), c='k', ls='--')\n",
    "#ax.set_ylim([50000,250000])\n",
    "ax.set_xlabel('$-\\log(\\lambda)$', fontsize=20)\n",
    "ax.set_ylabel('Cross-validated MSE', fontsize=20)\n",
    "\n",
    "# save figure\n",
    "plt.savefig('lasso_cv.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b75988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing lambdas\n",
    "\n",
    "# tuned alphas\n",
    "print(\"LASSO: \", tuned_lasso.alpha_)\n",
    "print(\"Ridge: \", tuned_ridge.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3baffa1e-9741-4994-945d-015423124e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(-np.log(tuned_lasso.alpha_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7d9b6b-1ad0-4d57-ac8f-897ca16dfcee",
   "metadata": {},
   "source": [
    "# Regression Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffeb132-3aaf-4c21-bd39-1a0010f835f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting sample\n",
    "(X_train,\n",
    " X_test,\n",
    " y_train,\n",
    " y_test) = skm.train_test_split(X,\n",
    "                                df['rmkvaf'],\n",
    "                                test_size=0.3,\n",
    "                                random_state=0)\n",
    "feature_names = list(D.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada53644-59b1-48d7-a3ae-a28d1735227d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = DTR(max_depth=3)\n",
    "reg.fit(X_train, y_train)\n",
    "ax = plt.subplots(figsize=(12,12))[1]\n",
    "plot_tree(reg,\n",
    "          feature_names=feature_names,\n",
    "          ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54d3d71-4eee-469d-8950-450d5145c57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best pruning for tree\n",
    "ccp_path = reg.cost_complexity_pruning_path(X_train, y_train)\n",
    "kfold = skm.KFold(5,\n",
    "                  shuffle=True,\n",
    "                  random_state=10)\n",
    "grid = skm.GridSearchCV(reg,\n",
    "                        {'ccp_alpha': ccp_path.ccp_alphas},\n",
    "                        refit=True, # retrains on best alpha\n",
    "                        cv=kfold,\n",
    "                        scoring='neg_mean_squared_error')\n",
    "G = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5188d5-2c25-4f27-a6fc-190d4ae450c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get prediction error\n",
    "best_ = grid.best_estimator_\n",
    "tree_mse = np.mean((y_test - best_.predict(X_test))**2)\n",
    "tree_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6c2481-aa18-457f-a9a1-27259aea898d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output pruned Regression Tree\n",
    "ax = plt.subplots(figsize=(12,12))[1]\n",
    "plot_tree(G.best_estimator_,\n",
    "          feature_names=feature_names,\n",
    "          ax=ax);\n",
    "plt.savefig(\"pruned_tree.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3747128-9922-488c-9dfa-12e96b229624",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc80acc-02f1-49f6-944a-f2e5827b4160",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_tree = RF(max_features=3, # Random forest model\n",
    "               random_state=0).fit(X_train, y_train)\n",
    "y_hat_RF = RF_tree.predict(X_test)\n",
    "rf_mse = np.mean((y_test - y_hat_RF)**2)\n",
    "rf_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67960627-6d72-410c-8d6a-a1901ec6d5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.DataFrame(\n",
    "    {'importance':RF_tree.feature_importances_},\n",
    "    index=feature_names) # Must include feature importance in report\n",
    "feature_imp = feature_imp.sort_values(by='importance', ascending=False)\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f163025-fb68-4c6d-b8af-7ba3d15d1593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(feature_imp.sort_values(by='importance', ascending=False).to_latex()) # print latex output\n",
    "\n",
    "# plot importance values\n",
    "fig = plt.figure(figsize=(7.5,5))\n",
    "\n",
    "plt.bar(feature_imp.index, feature_imp.importance, color ='darkblue', \n",
    "        width = 0.4)\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Importance of Random Forest Regressors for Firm Market Value')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec7ebdd-af00-4928-a015-4d2ebd4e752b",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466f8c68-ccdd-49f6-8504-b67e067e42cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = RF(max_features=X_train.shape[1], random_state=0)\n",
    "bag.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09cbe84-2c6a-4584-9218-44dd31228cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplots(figsize=(8,8))[1]\n",
    "y_hat_bag = bag.predict(X_test)\n",
    "ax.scatter(y_hat_bag, y_test)\n",
    "bag_mse = np.mean((y_test - y_hat_bag)**2)\n",
    "bag_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954c9684-f038-4369-82c1-d56d2e81d11e",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365151ed-46e6-49e6-8335-fbdabde150ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "boost = GBR(n_estimators=5000, # Gradient Boosting Regressor\n",
    "                   learning_rate=0.001,\n",
    "                   max_depth=3,\n",
    "                   random_state=0)\n",
    "boost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8112cd-eb77-409f-bd3d-3555d401f00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_error = np.zeros_like(boost.train_score_)\n",
    "for idx, y_ in enumerate(boost.staged_predict(X_test)):\n",
    "   test_error[idx] = np.mean((y_test - y_)**2)\n",
    "\n",
    "plot_idx = np.arange(boost.train_score_.shape[0])\n",
    "ax = plt.subplots(figsize=(8,8))[1]\n",
    "ax.plot(plot_idx,\n",
    "        boost.train_score_,\n",
    "        'b',\n",
    "        label='Training')\n",
    "ax.plot(plot_idx,\n",
    "        test_error,\n",
    "        'r',\n",
    "        label='Test')\n",
    "ax.legend();\n",
    "\n",
    "boost_mse = min(test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84442aec-7647-410a-9f3e-676e2057043b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XG Boost\n",
    "y = df['rmkvaf']\n",
    "# Convert the data into XGBoost's DMatrix format\n",
    "dtrain = xgb.DMatrix(X, label=y)\n",
    "\n",
    "# Define the parameters for the XGBoost model\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'eta': 0.1,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Train the XGBoost model with the optimal number of boosting rounds\n",
    "model = xgb.train(params, dtrain, num_boost_round= 10)\n",
    "\n",
    "# Make predictions \n",
    "y_pred = model.predict(dtrain)\n",
    "\n",
    "# Calculate and print the Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Prev. MSE: 40865396.0\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y, y_pred, c='grey', alpha=0.3)\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=2)\n",
    "plt.xlabel('True Y')\n",
    "plt.ylabel('Predicted Y')\n",
    "plt.title('Y vs Predicted Y (Y hat)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb857974-d09b-4241-8bfa-6d6bac1c6adf",
   "metadata": {},
   "source": [
    "# Comparing Test Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eecd93-a25d-470b-a91e-a121cea264f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree\n",
    "print('Tree: ', tree_mse)\n",
    "# Bag\n",
    "print('Bag: ', bag_mse)\n",
    "# Random Forest\n",
    "print('Random Forest: ', rf_mse)\n",
    "# Boost\n",
    "print('Boost: ', boost_mse)\n",
    "\n",
    "# Make table\n",
    "error_tbl = {\n",
    "    'model' : ['Tree', 'Bag', 'Random Forest', 'Boost'],\n",
    "    'MSE' : [tree_mse, bag_mse, rf_mse, boost_mse]\n",
    "}\n",
    "error_tbl = pd.DataFrame(data=error_tbl)\n",
    "print(error_tbl.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5400d0-4f99-4c11-b548-8d3c3648a1f4",
   "metadata": {},
   "source": [
    "# Predicting Market value of spillovers across years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dff34c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Optimal LASSO coefficients - remember to rescale from their standardization back to unit values.\n",
    "print(x_vars.columns[1],': ',tuned_lasso.coef_[0]) # index 0 for x_vars is constant term\n",
    "print(x_vars.columns[2],': ',tuned_lasso.coef_[1]) # so 1st variable is at index 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c697a390-1f24-4821-a943-9e16da9d6057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescaling lasso coefficients\n",
    "coef_tec = tuned_lasso.coef_[0]/df['gspilltecIV'].std()\n",
    "coef_sic = tuned_lasso.coef_[1]/df['gspillsicIV'].std() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7615d301-c511-430d-a2db-2869e63855d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['firmval_tec'] = df['gspilltecIV']*coef_tec\n",
    "df['firmval_sic'] = df['gspillsicIV']*coef_sic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e9621a-9efd-40b1-9f36-1c1b45389142",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['rmkvaf','firmval_tec','firmval_sic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f01af06-eb37-4951-a1e9-6adc1b239424",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['rmkvaf'].sum())\n",
    "print(df['firmval_tec'].sum())\n",
    "# Generate predictions for each firm\n",
    "\n",
    "# Aggregate across years"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d937715-bc35-41dd-89b6-3139b370c84c",
   "metadata": {},
   "source": [
    "# Impact of spillovers on firm value over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b5a3fc-da96-4a20-940c-03d155fd1c92",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Include confidence intervals. Use 2 or 5 year intervals if need more statistical power\n",
    "# Try with PLR DML to compare results - separate bar i.e. for each year, one OLS bar and one DML bar\n",
    "# Separate plots for tech/product market spillovers\n",
    "\n",
    "# build year-spillover interaction terms\n",
    "years = df.year.sort_values().unique()\n",
    "years = years[1:] # remove first year as ref category\n",
    "\n",
    "spillovers = ['gspilltecIV','gspillsicIV']\n",
    "\n",
    "for spillover in spillovers:\n",
    "    for year in years:\n",
    "        col_name = f\"{spillover}X{year}\"\n",
    "        x_vars[col_name] = x_vars[spillover]*x_vars[year]\n",
    "\n",
    "# drop reference year dummy\n",
    "#x_vars = x_vars.drop(columns=['1981'])\n",
    "#fixed_effects.remove('1981')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1451932-16b5-45cb-ae75-c2c0afa2e331",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Estimate effect of spillovers on firm value, OLS w/o firm FE's. Estimate spillovers separately, then together.\n",
    "\n",
    "# Full model\n",
    "year_model1 = sm.OLS(y_var,x_vars).fit()\n",
    "year_model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650d2db3-e371-4728-b906-7120bba05230",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tech spillovers model, no firm FE's\n",
    "drop_columns = [col for col in x_vars.columns if 'gspillsicIV' in col]\n",
    "x_vars_nofe = x_vars.drop(columns=fixed_effects)\n",
    "x_vars_nofe = x_vars_nofe.drop(columns=drop_columns)\n",
    "\n",
    "year_model2 = sm.OLS(y_var,x_vars_nofe).fit()\n",
    "year_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de709391-2187-4eb9-b53d-163e32e529f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tech spillovers model, firm FE's\n",
    "x_vars_fe = x_vars.drop(columns=drop_columns)\n",
    "\n",
    "year_model3 = sm.OLS(y_var,x_vars_fe).fit()\n",
    "year_model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463a2c1d-c69d-40df-b0bf-6307c004953c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tech spillovers, all FE's, 5 year intervals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db840de-c87c-4b76-8a30-c3cd1c80f6af",
   "metadata": {},
   "source": [
    "Results highly depend on the firm FE's. Wrong sign for tech, insignificant for product market. Unobserved firm-related variables play a role?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad88ded-6932-4961-82f2-53719a5b2d75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Product spillovers model, no firm FE's\n",
    "drop_columns = [col for col in x_vars.columns if 'gspilltecIV' in col]\n",
    "x_vars_nofe = x_vars.drop(columns=fixed_effects)\n",
    "x_vars_nofe = x_vars_nofe.drop(columns=drop_columns)\n",
    "\n",
    "year_model4 = sm.OLS(y_var,x_vars_nofe).fit()\n",
    "year_model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc5fbf8-de34-465f-8097-71775a7443d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Product spillovers model, firm FE's\n",
    "x_vars_fe = x_vars.drop(columns=drop_columns)\n",
    "\n",
    "year_model5 = sm.OLS(y_var,x_vars_fe).fit()\n",
    "year_model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e1e02b-ecc4-4c15-9dc5-06de70045c47",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Product Spillovers, all FE's, 5-year intervals\n",
    "\n",
    "# Create 5-year intervals\n",
    "#years = np.append(years,'1980')\n",
    "\n",
    "df['1980_84'] = df['year'].isin(['1980','1981','1982','1983','1984'])\n",
    "df['1985_89'] = df['year'].isin(['1985','1986','1987','1988','1989'])\n",
    "df['1990_94'] = df['year'].isin(['1990','1991','1992','1993','1994'])\n",
    "df['1995_99'] = df['year'].isin(['1995','1996','1997','1998','1999'])\n",
    "\n",
    "x_vars = ['gspilltecIV','gspillsicIV','pat_count','rsales','rppent','emp','rxrd']\n",
    "intervals = ['1980_84','1985_89','1990_94','1995_99']\n",
    "years = df.year.sort_values().unique()\n",
    "\n",
    "for year in years:\n",
    "    try:\n",
    "        fixed_effects.remove(year)\n",
    "    except ValueError:\n",
    "        continue\n",
    "\n",
    "for interval in intervals:\n",
    "    fixed_effects.append(interval)\n",
    "\n",
    "for col in fixed_effects:\n",
    "    x_vars.append(col)\n",
    "\n",
    "x_vars = df[x_vars]\n",
    "x_vars = sm.add_constant(x_vars)\n",
    "x_vars = x_vars.astype(float) # converts categorical booleans to floats\n",
    "\n",
    "for spillover in spillovers:\n",
    "    for interval in intervals:\n",
    "        col_name = f\"{spillover}X{interval}\"\n",
    "        x_vars[col_name] = x_vars[spillover]*x_vars[interval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65980327-e301-4cde-bbed-9044886b47be",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "drop_columns = [col for col in x_vars.columns if 'gspilltecIV' in col]\n",
    "\n",
    "x_vars_fe = x_vars.drop(columns=drop_columns)\n",
    "x_vars_fe = x_vars.drop(columns='1980_84') # drop ref category\n",
    "\n",
    "int_modelsic = sm.OLS(y_var,x_vars_fe).fit()\n",
    "int_modelsic.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1bc40f-530f-4b46-932d-e4875b95ce02",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Graphing Product Market Spillovers over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "53302809-0a50-4ee7-94f1-b72c77140e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# grab estimates. Add non-interactive term to each year coefficient\n",
    "# Build Dataframe of year, coefficient, conf intervals\n",
    "\n",
    "# use years to interate through\n",
    "# years = np.append(years, '1981')\n",
    "# years = years.sort_values()\n",
    "\n",
    "ref_year = '1980'\n",
    "time_coefs_sic = {\n",
    "    'year': np.append(years,ref_year),\n",
    "    'coef': [np.nan for i in range(0,len(years)+1)],\n",
    "    'CI_l': [np.nan for i in range(0,len(years)+1)],\n",
    "    'CI_h': [np.nan for i in range(0,len(years)+1)],\n",
    "    'se': [np.nan for i in range(0,len(years)+1)]\n",
    "}\n",
    "\n",
    "time_coefs_sic = pd.DataFrame(time_coefs_sic)\n",
    "time_coefs_sic = time_coefs_sic.sort_values(by='year').reset_index(drop=True)\n",
    "\n",
    "conf_intervals = year_model5.conf_int(alpha=0.05, cols=None)\n",
    "s_errors = year_model5.HC0_se\n",
    "\n",
    "# grab coefficients and confidence intervals\n",
    "ref_year = '1980'\n",
    "coef_ref = year_model5.params['gspillsicIV'] # coef for ref year category\n",
    "l_ref = conf_intervals.loc[conf_intervals.index == 'gspillsicIV',0].values[0] # conf interval for ref cat\n",
    "h_ref = conf_intervals.loc[conf_intervals.index == 'gspillsicIV',1].values[0]\n",
    "\n",
    "for year in time_coefs_sic['year'].unique():\n",
    "    if year == ref_year:\n",
    "        coef = coef_ref\n",
    "        ci_l = 0 \n",
    "        ci_h = 0\n",
    "        \n",
    "        time_coefs_sic.loc[time_coefs_sic['year'] == year, 'coef'] = coef\n",
    "        time_coefs_sic.loc[time_coefs_sic['year'] == year, 'CI_l'] = ci_l\n",
    "        time_coefs_sic.loc[time_coefs_sic['year'] == year, 'CI_h'] = ci_h\n",
    "        \n",
    "    else:\n",
    "        col_name = f\"gspillsicIVX{year}\"\n",
    "        coef = year_model5.params[col_name] + coef_ref\n",
    "        ci_l = conf_intervals.loc[conf_intervals.index == col_name,0].values[0] + coef_ref\n",
    "        ci_h = conf_intervals.loc[conf_intervals.index == col_name,1].values[0] + coef_ref\n",
    "        \n",
    "        time_coefs_sic.loc[time_coefs_sic['year'] == year, 'coef'] = coef\n",
    "        time_coefs_sic.loc[time_coefs_sic['year'] == year, 'CI_l'] = ci_l\n",
    "        time_coefs_sic.loc[time_coefs_sic['year'] == year, 'CI_h'] = ci_h\n",
    "\n",
    "\n",
    "time_coefs_sic['upper'] = time_coefs_sic['CI_h'] - time_coefs_sic['coef']\n",
    "time_coefs_sic['lower'] = time_coefs_sic['coef'] - time_coefs_sic['CI_l']\n",
    "time_coefs_sic.loc[time_coefs_sic['year'] == ref_year, ['upper','lower']] = 0\n",
    "\n",
    "cis = time_coefs_sic[['lower','upper']].T\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.errorbar(x=time_coefs_sic['year'],y=time_coefs_sic['coef'],yerr=cis, capsize=5, marker='o')\n",
    "plt.axhline(y=coef_ref, linestyle='dashed', color='r')\n",
    "plt.axhline(y=l_ref, linestyle='dotted', color='r')\n",
    "plt.axhline(y=h_ref, linestyle='dotted', color='r')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.title('Effect of Product Market Spillovers Over Time')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583f2b0f-aead-47c9-a0a9-ade24ef15858",
   "metadata": {},
   "source": [
    "## Tech Spillovers over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "620daffe-ce4c-4423-8e2b-08b236e23f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ref_year = '1980'\n",
    "time_coefs_tec = {\n",
    "    'year': np.append(years,ref_year),\n",
    "    'coef': [np.nan for i in range(0,len(years)+1)],\n",
    "    'CI_l': [np.nan for i in range(0,len(years)+1)],\n",
    "    'CI_h': [np.nan for i in range(0,len(years)+1)],\n",
    "    'se': [np.nan for i in range(0,len(years)+1)]\n",
    "}\n",
    "\n",
    "time_coefs_tec = pd.DataFrame(time_coefs_tec)\n",
    "time_coefs_tec = time_coefs_tec.sort_values(by='year').reset_index(drop=True)\n",
    "\n",
    "conf_intervals = year_model3.conf_int(alpha=0.05, cols=None)\n",
    "s_errors = year_model3.HC0_se\n",
    "\n",
    "# grab coefficients and confidence intervals\n",
    "ref_year = '1980'\n",
    "coef_ref = year_model3.params['gspilltecIV'] # coef for ref year category\n",
    "l_ref = conf_intervals.loc[conf_intervals.index == 'gspilltecIV',0].values[0] # conf interval for ref cat\n",
    "h_ref = conf_intervals.loc[conf_intervals.index == 'gspilltecIV',1].values[0]\n",
    "\n",
    "for year in time_coefs_tec['year'].unique():\n",
    "    if year == ref_year:\n",
    "        coef = coef_ref\n",
    "        ci_l = 0 \n",
    "        ci_h = 0\n",
    "        \n",
    "        time_coefs_tec.loc[time_coefs_tec['year'] == year, 'coef'] = coef\n",
    "        time_coefs_tec.loc[time_coefs_tec['year'] == year, 'CI_l'] = ci_l\n",
    "        time_coefs_tec.loc[time_coefs_tec['year'] == year, 'CI_h'] = ci_h\n",
    "        \n",
    "    else:\n",
    "        col_name = f\"gspilltecIVX{year}\"\n",
    "        coef = year_model3.params[col_name] + coef_ref\n",
    "        ci_l = conf_intervals.loc[conf_intervals.index == col_name,0].values[0] + coef_ref\n",
    "        ci_h = conf_intervals.loc[conf_intervals.index == col_name,1].values[0] + coef_ref\n",
    "        \n",
    "        time_coefs_tec.loc[time_coefs_tec['year'] == year, 'coef'] = coef\n",
    "        time_coefs_tec.loc[time_coefs_tec['year'] == year, 'CI_l'] = ci_l\n",
    "        time_coefs_tec.loc[time_coefs_tec['year'] == year, 'CI_h'] = ci_h\n",
    "\n",
    "\n",
    "time_coefs_tec['upper'] = time_coefs_tec['CI_h'] - time_coefs_tec['coef']\n",
    "time_coefs_tec['lower'] = time_coefs_tec['coef'] - time_coefs_tec['CI_l']\n",
    "time_coefs_tec.loc[time_coefs_tec['year'] == ref_year, ['upper','lower']] = 0\n",
    "\n",
    "cis = time_coefs_tec[['lower','upper']].T\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.errorbar(x=time_coefs_tec['year'],y=time_coefs_tec['coef'],yerr=cis, capsize=5, marker='o')\n",
    "plt.axhline(y=coef_ref, linestyle='dashed', color='r')\n",
    "plt.axhline(y=l_ref, linestyle='dotted', color='r')\n",
    "plt.axhline(y=h_ref, linestyle='dotted', color='r')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.title('Effect of Technology Spillovers Over Time')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb59ca5-5fca-4adf-bdd6-f013ae965e66",
   "metadata": {},
   "source": [
    "# DAG model and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "938b1200-939b-4733-b44d-d4fd27e5ed2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DAG3 = \"\"\"graph [\n",
    "directed 1\n",
    "\n",
    "node [\n",
    "    id 0\n",
    "    label \"rmkvaf\"\n",
    "    ]\n",
    "\n",
    "node [\n",
    "    id 1\n",
    "    label \"rxrd\"\n",
    "    ]\n",
    "    \n",
    "node [\n",
    "    id 2\n",
    "    label \"rsales\"\n",
    "    ]\n",
    "\n",
    "node [\n",
    "    id 3\n",
    "    label \"gspilltecIV\"\n",
    "    ]\n",
    "\n",
    "node [\n",
    "    id 4\n",
    "    label \"gspillsicIV\"\n",
    "    ]\n",
    "\n",
    "node [\n",
    "    id 5\n",
    "    label \"pat_count\"\n",
    "    ]\n",
    "\n",
    "node [\n",
    "    id 7\n",
    "    label \"rppent\"\n",
    "    ]\n",
    "\n",
    "edge [\n",
    "    source 5\n",
    "    target 0\n",
    "    ]\n",
    "\n",
    "edge [\n",
    "    source 5\n",
    "    target 7\n",
    "    ]\n",
    "\n",
    "\n",
    "edge [\n",
    "    source 3\n",
    "    target 1\n",
    "    ]\n",
    "\n",
    "\n",
    "edge [\n",
    "    source 4\n",
    "    target 1\n",
    "    ]\n",
    "\n",
    "\n",
    "edge [\n",
    "    source 4\n",
    "    target 2\n",
    "    ]\n",
    "\n",
    "\n",
    "edge [\n",
    "    source 1\n",
    "    target 7\n",
    "    ]\n",
    "\n",
    "\n",
    "edge [\n",
    "    source 1\n",
    "    target 5\n",
    "    ]\n",
    "\n",
    "\n",
    "edge [\n",
    "    source 7\n",
    "    target 2\n",
    "    ]\n",
    "\n",
    "\n",
    "edge [\n",
    "    source 2\n",
    "    target 0\n",
    "    ]\n",
    "\n",
    "edge [\n",
    "    source 7\n",
    "    target 0\n",
    "    ]\n",
    "\n",
    "]\n",
    "    \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9ff4fa94-6a7f-44b4-8c2d-1c2592fa852d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = CausalModel(\n",
    "    data=df,\n",
    "    treatment='gspilltecIV',\n",
    "    outcome='rmkvaf',\n",
    "    graph=DAG3)\n",
    "\n",
    "model.view_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5750d61e-8f45-4335-a771-e7279042f911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimand type: EstimandType.NONPARAMETRIC_ATE\n",
      "\n",
      "### Estimand : 1\n",
      "Estimand name: backdoor\n",
      "Estimand expression:\n",
      "      d                  \n",
      "(E[rmkvaf])\n",
      "d[gspilltecIV]           \n",
      "Estimand assumption 1, Unconfoundedness: If U{gspilltecIV} and Urmkvaf then P(rmkvaf|gspilltecIV,,U) = P(rmkvaf|gspilltecIV,)\n",
      "\n",
      "### Estimand : 2\n",
      "Estimand name: iv\n",
      "No such variable(s) found!\n",
      "\n",
      "### Estimand : 3\n",
      "Estimand name: frontdoor\n",
      "Estimand expression:\n",
      "                 d                                                          \n",
      "E(rmkvaf)([pat_count  rppent\n",
      " d[pat_count  rppent  rsales  rxrd]         [gspilltecIV]                   \n",
      "\n",
      "                \n",
      "  rsales  rxrd])\n",
      "                \n",
      "Estimand assumption 1, Full-mediation: pat_count,rppent,rsales,rxrd intercepts (blocks) all directed paths from gspilltecIV to r,m,k,v,a,f.\n",
      "Estimand assumption 2, First-stage-unconfoundedness: If U{gspilltecIV} and U{pat_count,rppent,rsales,rxrd} then P(pat_count,rppent,rsales,rxrd|gspilltecIV,U) = P(pat_count,rppent,rsales,rxrd|gspilltecIV)\n",
      "Estimand assumption 3, Second-stage-unconfoundedness: If U{pat_count,rppent,rsales,rxrd} and Urmkvaf then P(rmkvaf|pat_count,rppent,rsales,rxrd, gspilltecIV, U) = P(rmkvaf|pat_count,rppent,rsales,rxrd, gspilltecIV)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# identify estimand\n",
    "estimand = model.identify_effect()\n",
    "print(estimand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "006f5b87-4a1f-471e-b67a-12b1b9ffc9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12296998685320659\n"
     ]
    }
   ],
   "source": [
    "# obtain estimates\n",
    "estimate = model.estimate_effect(\n",
    "    identified_estimand=estimand,\n",
    "    method_name='backdoor.linear_regression')\n",
    "\n",
    "print(estimate.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f27e0e80-ebcb-4543-b1b5-8eedafa7ac0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refute: Use a subset of data\n",
      "Estimated effect:0.12296998685320659\n",
      "New effect:0.12347458135323676\n",
      "p value:0.9199999999999999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# refutation test\n",
    "refute_subset = model.refute_estimate(\n",
    "    estimand=estimand,\n",
    "    estimate=estimate,\n",
    "    method_name=\"data_subset_refuter\",\n",
    "    subset_fraction=0.4)\n",
    "\n",
    "print(refute_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755e48a0-25a6-4faf-8a5a-2db6ba5e8635",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39600fbc-c968-438a-b2d4-1758b578a563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e0c591-95c7-42e6-b42f-8d3ba9b0f447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1c3ef64-ca2f-4b0e-ae15-74b57b958650",
   "metadata": {},
   "source": [
    "# Scrap Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ce3ff2-b571-4e3c-9b57-c7c6210b0ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56cc964a-8741-4ebf-8c7c-ea8c06631143",
   "metadata": {},
   "source": [
    "X_spills = df[['gspilltecIV', 'gspillsicIV']]\n",
    "\n",
    "(X_trainsp,\n",
    " X_testsp,\n",
    " y_trainsp,\n",
    " y_testsp) = skm.train_test_split(X_spills,\n",
    "                                df['rmkvaf'],\n",
    "                                test_size=0.3,\n",
    "                                random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1704c099-cfef-4cc6-8905-38615eb18d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Try a neural network\n",
    "# one_layers = [\n",
    "#     (1),\n",
    "#     (2),\n",
    "#     (3),\n",
    "#     (4),\n",
    "#     (5)\n",
    "# ]\n",
    "\n",
    "# two_layers = [\n",
    "#     (1,1),(1,2),(1,3),\n",
    "#     (2,1),(2,2),(2,3),(2,4),\n",
    "#     (3,1),(3,2),(3,3),(3,4),(3,5),\n",
    "#     (4,1),(4,2),(4,3),(4,4),(4,5),\n",
    "#     (5,1),(5,2),(5,3),(5,4),(5,5)\n",
    "# ]\n",
    "\n",
    "# # Use DML with a PLR equation, keeping spillovers entering linearly\n",
    "# # Use Random Forest as the ML model\n",
    "\n",
    "# # Specify doubleML data model\n",
    "\n",
    "# x_vars = ['pat_count','rsales','rppent','emp','rxrd']\n",
    "# data_dml_tec = dml.DoubleMLData(df,\n",
    "#                                  y_col='rmkvaf',\n",
    "#                                  d_cols='gspilltec',\n",
    "#                                  x_cols=x_vars)\n",
    "\n",
    "# RF_DML = RF(max_features=3, random_state=0)\n",
    "\n",
    "# # Implement PLR DML estimation with gspilltec linear\n",
    "\n",
    "# dml_plr_tec = dml.DoubleMLPLR(data_dml_tec,\n",
    "#                                 ml_l = RF_DML,\n",
    "#                                 ml_m = RF_DML,\n",
    "#                                 n_folds = 3)\n",
    "\n",
    "# dml_plr_tec.fit(store_predictions=True)\n",
    "# print(dml_plr_tec.summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
